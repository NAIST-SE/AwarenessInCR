Number,Owner,Dis,Commenter,Link,Domain,Target,Intention,Internal or External,Project210637,5280,"Patch Set 1:

Look at opened ec2 bug list in Launchpad:

https://bugs.launchpad.net/nova/+bugs?field.searchtext=&orderby=-importance&field.status%3Alist=NEW&field.status%3Alist=CONFIRMED&field.status%3Alist=TRIAGED&field.status%3Alist=INPROGRESS&field.status%3Alist=INCOMPLETE_WITH_RESPONSE&field.status%3Alist=INCOMPLETE_WITHOUT_RESPONSE&assignee_option=any&field.assignee=&field.bug_reporter=&field.bug_commenter=&field.subscriber=&field.structural_subscriber=&field.tag=ec2+&field.tags_combinator=ANY&field.has_cve.used=&field.omit_dupes.used=&field.omit_dupes=on&field.affects_me.used=&field.has_patch.used=&field.has_branches.used=&field.has_branches=on&field.has_no_branches.used=&field.has_no_branches=on&field.has_blueprints.used=&field.has_blueprints=on&field.has_no_blueprints.used=&field.has_no_blueprints=on&search=Search

It's empty, because all triaged bugs were recently transfered to won't fix status:

https://bugs.launchpad.net/nova/+bugs?field.searchtext=&orderby=-date_last_updated&field.status%3Alist=NEW&field.status%3Alist=WONTFIX&field.status%3Alist=CONFIRMED&field.status%3Alist=TRIAGED&field.status%3Alist=INPROGRESS&field.status%3Alist=INCOMPLETE_WITH_RESPONSE&field.status%3Alist=INCOMPLETE_WITHOUT_RESPONSE&assignee_option=any&field.assignee=&field.bug_reporter=&field.bug_commenter=&field.subscriber=&field.structural_subscriber=&field.tag=ec2+&field.tags_combinator=ANY&field.has_cve.used=&field.omit_dupes.used=&field.omit_dupes=on&field.affects_me.used=&field.has_patch.used=&field.has_branches.used=&field.has_branches=on&field.has_no_branches.used=&field.has_no_branches=on&field.has_blueprints.used=&field.has_blueprints=on&field.has_no_blueprints.used=&field.has_no_blueprints=on&search=Search

So it looks like not each bug should be fixed in Nova EC2 now, but only critical ones.

I don't know if OpenStack community reopens old bugs. But for me it's more reasonlable to file a new bug to process it separately.

You could ask a core reviewer (like Sean Dague for example), is it a good idea to fix the bugm, and what would be better: to file a new bug in Launchpad or to reopen the old one.

PS. Why do you not use stackforge/ec2-api? We need feedbacks to make it better.",10224,https://bugs.launchpad.net/nova/+bugs?field.searchtext=&orderby=-date_last_updated&field.status%3Alist=NEW&field.status%3Alist=WONTFIX&field.status%3Alist=CONFIRMED&field.status%3Alist=TRIAGED&field.status%3Alist=INPROGRESS&field.status%3Alist=INCOMPLETE_WITH_RESPONSE&field.status%3Alist=INCOMPLETE_WITHOUT_RESPONSE&assignee_option=any&field.assignee=&field.bug_reporter=&field.bug_commenter=&field.subscriber=&field.structural_subscriber=&field.tag=ec2+&field.tags_combinator=ANY&field.has_cve.used=&field.omit_dupes.used=&field.omit_dupes=on&field.affects_me.used=&field.has_patch.used=&field.has_branches.used=&field.has_branches=on&field.has_no_branches.used=&field.has_no_branches=on&field.has_blueprints.used=&field.has_blueprints=on&field.has_no_blueprints.used=&field.has_no_blueprints=on&search=Search,bugs.launchpad.net,Bug report,Clarifying,Internal,OpenStack293757,10267,"Patch Set 2: Code-Review-1

(1 comment)

Actually I'm not sure about this approach. I doubt that introducing new table will be less racy. We already have a couple of patches to deal with ha networks https://bugs.launchpad.net/neutron/+bug/1548285 and https://review.openstack.org/#/c/282876/ one of them.",7249,https://bugs.launchpad.net/neutron/+bug/1548285,bugs.launchpad.net,Bug report,Clarifying,Internal,OpenStack352955,5441,"Patch Set 1: Code-Review-1

actually we never use compute_api layer policy checks for v2.1 API. We skip the comptue_api layer policy checks when we still call the new API as v3 https://review.openstack.org/#/c/149520/5/nova/api/openstack/compute/plugins/v3/attach_interfaces.py

So do we have policy upgrade support now?",5754,https://review.openstack.org/#/c/149520/5/nova/api/openstack/compute/plugins/v3/attach_interfaces.py,review.openstack.org,Code,Clarifying,Internal,OpenStack216329,14819,"Patch Set 2:

method live_migration cleanup_flags is used in 2 cases:
in _post_live_migration:
https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L5190
in _rollback_live_migration:
https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L5340
For _post_live_migration it could trigger driver's cleanup method. here is list of drivers:
- libvirt - implemented (https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L838)
- hyperv - not implemented(https://github.com/openstack/nova/blob/master/nova/virt/hyperv/driver.py#L100)
- ironic - not implemented
- vmware - not implemented (https://github.com/openstack/nova/blob/master/nova/virt/vmwareapi/driver.py#L257)
- xenapi - not implemented (https://github.com/openstack/nova/blob/master/nova/virt/xenapi/driver.py#L253)

so only for libvirt this method seems to be valuable.

for _rollback_live_migration it calls rollback_live_migration_at_destination.
https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L5357 - this code teardown networks for nova-network and calls
drivers  rollback_live_migration_at_destination method:
- libvirt - implemented (https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L6112)
- hyperv - implemented(https://github.com/openstack/nova/blob/master/nova/virt/hyperv/driver.py#L163)
- ironic - not implemented
- vmware - implemented (https://github.com/openstack/nova/blob/master/nova/virt/vmwareapi/driver.py#L323)
- xenapi - not implemented (https://github.com/openstack/nova/blob/master/nova/virt/xenapi/driver.py#L545)

It seems to be more valuable for rollback, rather then post method.
The reason to move this method to drivers is that it works with hypervisor-specific dict. 
these flags: https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L5099-L5102 are valid only for libvirt,
while this check is applied to all hypervisors. This code works and doesn't cause problems only by some amount of luck. 
But, I agree that default implementation in driver superclass should be rewritten.",14819,https://github.com/openstack/nova/blob/master/nova/virt/hyperv/driver.py#L100,github.com,Code,Clarifying,Internal,OpenStack43213,8495,"Patch Set 1: I would prefer that you didn't merge this

(1 inline comment)

This code was present in the scheduler driver in Folsom, its not new in Havana.

This code has been moved from the scheduler because its complexity that is ""task specific"", and moved to the generic ""select_hosts"" call.

I think the better question, is how should this check be done? I think we can probably remove the check, because the scheduler method we call should take all this into account:
https://github.com/openstack/nova/blob/master/nova/scheduler/manager.py#L284",782,https://github.com/openstack/nova/blob/master/nova/scheduler/manager.py#L284,github.com,Code,Clarifying,Internal,OpenStack346831,11418,"Patch Set 5: Code-Review-2

This is unnecessary.  If everything went OK in these operations returning update dictionaries like you are doing would create unnecessary additional DB updates on those volumes.

The volume manager is already updating the resources.

Here's an example of how the manager updates it correctly after calling driver's create_consistencygroup_from_src: https://github.com/openstack/cinder/blob/master/cinder/volume/manager.py#L2597",9535,https://github.com/openstack/cinder/blob/master/cinder/volume/manager.py#L2597,github.com,Code,Clarifying,Internal,OpenStack356963,5754,"Patch Set 1: Code-Review-1

(1 comment)

This feels like the wrong place.

I think we should warn if *any* rule includes the user_id

Maybe we could do that here:
https://github.com/openstack/nova/blob/master/nova/policy.py#L58",782,https://github.com/openstack/nova/blob/master/nova/policy.py#L58,github.com,Code,Clarifying,Internal,OpenStack273982,16658,"Patch Set 3:

No, I did not. But judging by the code ... on the database layer does not очкур interaction with the store, so metadata_encryption_key does not affect the removal from the store. Removing the locations of the store https://github.com/openstack/glance/blob/master/glance/location.py#L382-L389",16658,https://github.com/openstack/glance/blob/master/glance/location.py#L382-L389,github.com,Code,Clarifying,Internal,OpenStack133083,7461,"Patch Set 2: Code-Review-1

(1 comment)

To address Sylvain's question, I worked on something similar and it was recommended to keep the object clean of specialized use cases (like aggregating metadata) which is how this very similar code came about:


https://github.com/openstack/nova/blob/a22cece560c1c6c2b58dddbcd9528ed0a7cab6fc/nova/availability_zones.py#L78-L83


The AggregateList interface returns only aggregates, and the caller can manipulate those as needed.


My tentative -1 is about the unit tests.",4690,https://github.com/openstack/nova/blob/a22cece560c1c6c2b58dddbcd9528ed0a7cab6fc/nova/availability_zones.py#L78-L83,github.com,Code,Clarifying,Internal,OpenStack565284,5367,"Patch Set 3:

I moved get_port_binding_by_status_and_host to https://review.openstack.org/#/c/414251/73/neutron/common/utils.py. So there is no conflict anymore of this patch with https://review.openstack.org/#/c/414251",4694,https://review.openstack.org/#/c/414251/73/neutron/common/utils.py,review.openstack.org,Code,Clarifying,Internal,OpenStack529184,6873,"Patch Set 1:

Some questions, in the test, ""self.context"" seems to be admin_context generated using https://github.com/openstack/nova/blob/stable/pike/nova/tests/functional/db/test_request_spec.py#L101
and you didn't change the parameter passed to the function you modified here:https://github.com/openstack/nova/blob/stable/pike/nova/objects/request_spec.py#L577
so isn't the test not testing what you expected?",15888,https://github.com/openstack/nova/blob/stable/pike/nova/tests/functional/db/test_request_spec.py#L101,github.com,Code,Clarifying,Internal,OpenStack336496,14762,"Patch Set 1:

In addition, do code paths like this one still make sense?

https://github.com/openstack/nova/blob/faeede297/nova/objects/request_spec.py#L157-159",15334,https://github.com/openstack/nova/blob/faeede297/nova/objects/request_spec.py#L157-159,github.com,Code,Clarifying,Internal,OpenStack152284,7111,"Patch Set 12:

This change should also allow some code cleanup since encrypted volume types can be modified even when there are existing volumes of that type (see http://git.openstack.org/cgit/openstack/cinder/tree/cinder/api/contrib/volume_type_encryption.py#n87). I'd expect to see this cleanup as part of this change or in a dependent change.",6802,http://git.openstack.org/cgit/openstack/cinder/tree/cinder/api/contrib/volume_type_encryption.py#n87,git.openstack.org,Code,Clarifying,Internal,OpenStack114188,1247,"Patch Set 1: Code-Review+2

Looks clear and sensible to me, and was discussed at http://lists.openstack.org/pipermail/openstack-dev/2014-August/042728.html",1812,http://lists.openstack.org/pipermail/openstack-dev/2014-August/042728.html,lists.openstack.org,Communication channel,Clarifying,Internal,OpenStack641908,28706,"Patch Set 1: Code-Review-2

This definitely would need a blueprint I think and some design discussion for alternatives, like what I have posted in the mailing list:

http://lists.openstack.org/pipermail/openstack-discuss/2019-March/003839.html

I'll add this to the PTG agenda for Train:

https://etherpad.openstack.org/p/nova-ptg-train",6873,http://lists.openstack.org/pipermail/openstack-discuss/2019-March/003839.html,lists.openstack.org,Communication channel,Clarifying,Internal,OpenStack545490,27654,"Patch Set 6: Code-Review-1

I agree with slawek that we need an extension. At the same time I want to avoid the proliferation of extensions. To that end, why don't we group this patch (and others similar to it) under the effort to address https://bugs.launchpad.net/neutron/+bug/1749820, that we discussed in Dublin. In fact, one of the comments in Dublin was that the new filter behavior should be discoverable

Having said this, looking at the ML thread about API filters that you started as a follow up to Dublin, it seems that cdent indicates that the current behavior is flat out wrong and we just should fix it: http://lists.openstack.org/pipermail/openstack-dev/2018-March/128023.html. However, we don't know how many user scripts we are going to break if we just do that. So I wonder if the new extensions should be configurable also. What do you guys think? I can ask him tomorrow in the API WG meeting. I will let you know what he says",4694,http://lists.openstack.org/pipermail/openstack-dev/2018-March/128023.html,lists.openstack.org,Communication channel,Clarifying,Internal,OpenStack116196,9200,"Patch Set 1:

Here it is.

http://paste.openstack.org/show/100867/

On whether this patch fixes exceptions, it's half true and half false. An exception will happen if another bind_router call is made from auto_schedule_routers.

The real problem is the DBDuplicateEntry handling isn't quite useful when called from auto_schedule_routers (from a loop and with an enclosing transaction).",9200,http://paste.openstack.org/show/100867/,paste.openstack.org,Memo,Clarifying,Internal,OpenStack605250,4690,"Patch Set 2:

> I must be missing something here. With https://review.openstack.org/#/q/4f01f4ff88de571218a36ba7c4e998296a7b52a4
 > merged, surely deprecating the service is correct and all we need
 > to do is remove the usage of the consoleauth service from the VNC
 > service?

Yeah... unfortunately, it seems we have to do this :(

I discussed it with mriedem on IRC yesterday [1] and because it's not possible to _not_ run nova-consoleauth in Rocky [2], the correct thing to do is un-deprecate the service in Rocky. Unfortunately, we have to two-step it to backport the un-deprecation to Rocky, and then redo the deprecation in Stein, then remove the TODO calls to nova-consoleauth in compute/api, then it will no longer be necessary to run the nova-consoleauth service.

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2018-09-25.log.html#t2018-09-25T22:00:54
[2] https://github.com/openstack/nova/blob/b79a21a/nova/compute/api.py#L3709",4690,https://review.openstack.org/#/q/4f01f4ff88de571218a36ba7c4e998296a7b52a4,review.openstack.org,Patch,Clarifying,Internal,OpenStack456292,9236,"Patch Set 6: Code-Review-1

(1 comment)

not sure why it needs to be in nova as this job is broadly used by cinder, glance etc.

should not it be on openstack/devstack-plugin-ceph? so that it can be maintained by ceph plugin which know better what all test to disable. 

https://github.com/openstack/devstack-plugin-ceph/tree/master/devstack",8556,https://github.com/openstack/devstack-plugin-ceph/tree/master/devstack,github.com,Patch,Clarifying,Internal,OpenStack224845,6681,"Patch Set 3: Code-Review-2

What if I tell you that the feature is already implemented in oslo.reports, and we merely need to integrate with the library, and that this was actually my original plan for the cycle, among other things, that I spectacularly failed, and that we even have an abandoned old patch to adopt it? :)

https://github.com/openstack/oslo.reports/blob/master/oslo_reports/generators/threading.py

http://specs.openstack.org/openstack/neutron-specs/specs/liberty/adopt-oslo-guru-reports.html

https://review.openstack.org/#/c/119008/

I put -2 since such a patch in current form won't be allowed in, and the proper way is to pull in oslo.reports into neutron. If you are interested to help me with actually getting it in M, please ping me on IRC.",9656,https://review.openstack.org/#/c/119008/,review.openstack.org,Patch,Clarifying,Internal,OpenStack133484,8124,"Patch Set 12:

(1 comment)

A parent change[1] explains that redirected packets are not local packets in general. So setting host=127.0.0.1 will disallow direct queries but also redirected ones.


[1]https://review.openstack.org/141045",8124,https://review.openstack.org/141045,review.openstack.org,Patch,Clarifying,Internal,OpenStack143169,9077,"Patch Set 82:

@Swami, I don't think this patch should be based on https://review.openstack.org/#/c/275653/ as they are actually orthogonal",5948,https://review.openstack.org/#/c/275653/,review.openstack.org,Patch,Clarifying,Internal,OpenStack312488,15847,"Patch Set 21:

> I don't think https://review.openstack.org/#/c/277670/ means we
 > want to piggyback on privsep from os-brick, you could make the same
 > argument that you could re-use the privsep helper from os-vif
 > (which uses privsep and no rootwrap). https://review.openstack.org/#/c/277670/
 > was meant for things that were used in rootwrap filters before
 > privsep that were shared by nova/cinder/os-brick and now use
 > privsep, not as a means to start using privsep for new things in
 > Nova that aren't in os-brick.
 > 
 > So I'm a bit torn on this one. One the one hand I don't really want
 > to hold this up, but on the other this feels like a slippery slope
 > where if we never enforce using privsep properly in Nova, it's not
 > going to ever happen, and this would set precedent. So I can't +2
 > this as-is right now.

I see your concern, Matt. From my side I can assure you that we commit ourselves to switch to using privsep as soon as necessary stuff lays down in Nova, thus it's not going to be a precedent.",12408,https://review.openstack.org/#/c/277670/,review.openstack.org,Patch,Clarifying,Internal,OpenStack564351,14070,"Patch Set 6: Code-Review-1

(3 comments)

So.. posting these comments, but I spent a few hours this afternoon writing a patch that basically removes the need for this patch (and hopefully will line you up nice and straight for the meaty patch that adds the merge candidates stuff).

I had a difficult time trying to explain what felt wrong about this patch. I write inline that something just feels weird about it; like you're coupling something incorrectly in the AllocationRequest object.

That weird feeling led me to this patch, which places all of the ""state"" that needs to be kept in various iterations of the matching logic into a MatchSpec object. This MatchSpec object is constructed from a list of RequestGroup objects and has methods to extract particular pieces of information about sharing providers and various maps/lookups for ID to name translation.

https://review.openstack.org/566166",7,https://review.openstack.org/566166,review.openstack.org,Patch,Clarifying,Internal,OpenStack377663,22793,"Patch Set 5:

> Why do you have 3 of the same patches?
 > 
 > [1]: https://review.openstack.org/#/c/377663/
 > [2]: https://review.openstack.org/#/c/377667/
 > [3]: https://review.openstack.org/#/c/377661/

Hi Gábor,

Thanks for the review.

The patch for replacing uuid with uuidsentinel is containing a lot of files to be changed. In order to avoid more merge conflicts and to make the patch easy for review, I have broken down one big patch into small patches.",22793,https://review.openstack.org/#/c/377667/,review.openstack.org,Patch,Clarifying,Internal,OpenStack4443,1427,"Patch Set 3: I would prefer that you didn't submit this

Hi Reynolds,

Thanks for the patch.

We had some debate around whether disk and container formats should be mandatory or defaulted.

The outcome from:

  https://review.openstack.org/#change,4272

was to make both formats mandatory, and to ensure consistency by enforcing this requirement within the API layer, so that we'd get the same result regardless of whether the image was added via the CLI or the python/REST APIs.

This approach turned out to be over-restrictive, as in some cases the image is simply being ""reserved"" by the initial POST and the disk/container formats aren't known until the image content is provided via a subsequent PUT. This led to a loosening of the restriction, such that the disk/container formats need not be supplied when an image is added without any image content initially:

  https://review.openstack.org/#change,4330

Now I'm not sure there's a great deal of value in duplicating this policy in the CLI, but at the very least you'd need to be consistent by checking for both disk & conatiner formats, only enforcing in the cases where the image data is provided on the initial add (i.e. 'glance add < /path/to/image' or 'glance add location=URI' or 'glance add copy_from=URI').

There would be further complication where the image was initially created with neither image content nor disk/container formats specified. The CLI would have to detect this and enforce the requirement for the formats to be present in a subsequent 'glance update location=URI'.

The other option would be for the CLI to simply pass through wharever formats the user provided (as it does now) and allow the cases where a required format is missing to be detected and rejected within the API layer.

Cheers,
Eoghan",2284,https://review.openstack.org/#change,review.openstack.org,Patch,Clarifying,Internal,OpenStack69622,1653,"Patch Set 15:

If the race-induced exceptions are still being thrown, then the error-handling here is definitely reasonable. My question is, hasn't the root cause of https://bugs.launchpad.net/nova/+bug/1266580 been addressed by https://review.openstack.org/#/c/54096/ (""upload images to temporary
directory"")?",8027,https://review.openstack.org/#/c/54096/,review.openstack.org,Patch,Clarifying,Internal,OpenStack332425,8873,"Patch Set 3:

I found about this during cleanup [1], so yes.

[1] https://review.openstack.org/#/c/331999/",748,https://review.openstack.org/#/c/331999/,review.openstack.org,Patch,Clarifying,Internal,OpenStack124946,5196,"Patch Set 4:

I think we should take https://review.openstack.org/99965 and prototype it in the Neutron tree. Once we get it working here we can re-propose it back to oslo.db. Hopefully Ilya will be OK with us taking over the code (with attribution of course).",6524,https://review.openstack.org/99965,review.openstack.org,Patch,Clarifying,Internal,OpenStack363841,21722,"Patch Set 1: Code-Review+2

See prior discussion on https://review.openstack.org/#/c/344362/

The negative vote on that patch was an objection to the formatting.  The formatting issue was fixed by https://github.com/openstack/glance/commit/45003b0209d6d336bc99e10e38fff970ee546f99 , so I believe that the objection no longer applies.

The content and formatting of this patch look good to me.",5314,https://review.openstack.org/#/c/344362/,review.openstack.org,Patch,Clarifying,Internal,OpenStack252979,14305,"Patch Set 20:

Did CI fail because it needs snapshot functions in patch https://review.openstack.org/#/c/253111/?",6491,https://review.openstack.org/#/c/253111/,review.openstack.org,Patch,Clarifying,Internal,OpenStack405448,8788,"Patch Set 1: Code-Review+1

(1 comment)

i've confirmed this fixes the issue seen on networking-midonet.
https://review.openstack.org/#/c/405527/",6854,https://review.openstack.org/#/c/405527/,review.openstack.org,Patch,Clarifying,Internal,OpenStack98724,2861,"Patch Set 9: Code-Review-2

Adding glance v2 support to nova is a blueprint not a bug, and there is a nova-spec in progress for this: https://review.openstack.org/#/c/84887/",1849,https://review.openstack.org/#/c/84887/,review.openstack.org,Patch,Clarifying,Internal,OpenStack95684,4428,"Patch Set 1: Code-Review-1

I agree with Joe here. This should match the current scheduler configuration and not blindly assume ram_allocation_ratio to be correct. This used to work before live migration moved out of the scheduler. Back then, the filter_scheduler used to override this with its own check.

To add to the brokenness of this piece of code, if you do live-migration and let the scheduler decide on destination, this check is not involved anymore and instead checks are purely based on scheduler filters (memory, core, type etc.) in the case of filter_scheduler or no checks at all in case of chance scheduler.

A previous attempt at fixing this while also adding checks for things like scheduler hints involved adding a validate_host call to the scheduler where the scheduler could be asked if a host would pass checks. This can be found at https://review.openstack.org/45450",6450,https://review.openstack.org/45450,review.openstack.org,Patch,Clarifying,Internal,OpenStack51293,1849,"Patch Set 1:

lifeless, excellent question.

the modeline isn't enabled by default on ubuntu or debian (https://review.openstack.org/#/c/51293/1,publish) which covers many users.  Also the modeline is only present in 828 out of 1213 python files in nova (68%), so if someone is relying on this today they are in trouble.",1849,https://review.openstack.org/#/c/51293/1,review.openstack.org,Patch,Clarifying,Internal,OpenStack623420,29256,"Patch Set 1:

> As I mentioned here https://review.openstack.org/#/c/623415/1/neutron_lib/api/validators/__init__.py@602,
 > I think similar test cases are needed in neutron-lib to test the
 > validator itself independent of neutron.

Thanks much for the comments!
I have added test cases in neutron-lib.",29256,https://review.openstack.org/#/c/623415/1/neutron_lib/api/validators/__init__.py@602,review.openstack.org,Patch,Clarifying,Internal,OpenStack567687,6873,"Patch Set 2:

Does this actually need to be based on https://review.openstack.org/#/c/567682/ ?

I know this refers to it, but that review will exist and be relevant even if it never lands.",14070,https://review.openstack.org/#/c/567682/,review.openstack.org,Patch,Clarifying,Internal,OpenStack531524,14237,"Patch Set 6: Code-Review-1

(4 comments)

There are some specific problems in this patch which would need to be addressed at a minimum. However, I think it would be much better to consider resurrecting this patch series:

https://review.openstack.org/#/q/project:openstack/nova+branch:master+topic:bp/virt-rescue-stable-disk-devices

It previously came very close to landing, and I'm sure lyarwood would be happy to restore the patches and have you work on them. The older series tackles this problem considerably more thoroughly, as it also handles multiple attached volumes, and instances with local ephemeral disks.",9555,https://review.openstack.org/#/q/project:openstack/nova+branch:master+topic:bp/virt-rescue-stable-disk-devices,review.openstack.org,Patch,Clarifying,Internal,OpenStack302500,17714,"Patch Set 1:

It looks like some of the files aren't getting updated when I did this last run and uploaded it.

This one is correct:

https://review.openstack.org/#/c/302500/1/api-ref/source/servers/GET_list_servers_v2.1_tenant_id_servers.rst",17714,https://review.openstack.org/#/c/302500/1/api-ref/source/servers/GET_list_servers_v2.1_tenant_id_servers.rst,review.openstack.org,Patch,Clarifying,Internal,OpenStack606676,2472,"Patch Set 1:

Yes, the pep8 change isn't as easy as it looks, I actually started to fix some things it noticed in other patches last Friday, but the astroid failures requiring a newer pylint will need some work (i couldn't figure it out yet).

And I actually had created a change for the cover job last Friday as well, https://review.openstack.org/#/c/606205/ - that was actually pretty trivial.",1131,https://review.openstack.org/#/c/606205/,review.openstack.org,Patch,Clarifying,Internal,OpenStack45103,6802,"Patch Set 8:

[Nova] FFE Request: Encrypt Cinder volumes
We request that volume encryption [1] be granted an exception to the feature freeze for Havana-3.  Volume encryption [2] provides a usable layer of protection to user data as it is transmitted through a network and when it is stored on disk. The main patch [2] has been under review since the end of May and had received two +2s in mid-August.  Subsequently, support was requested for booting from encrypted volumes and integrating a working key manager [3][4] as a stipulation for acceptance, and both these requests have been satisfied within the past week. The risk of disruption to deployments from this exception is minimal because the volume encryption feature is unused by default.  Note that the corresponding Cinder support for this feature has already been approved, so acceptance into Nova will keep this code from becoming abandoned.   Thank you for your consideration.

The APL Development Team

[1] https://blueprints.launchpad.net/nova/+spec/encrypt-cinder-volumes
 
[2] https://review.openstack.org/#/c/30976/ Change I358813b3: Add encryption support for volumes to libvirt

[3] https://review.openstack.org/#/c/45103/ Change Ia6f4c69e: Add key manager implementation with static key

[4] https://review.openstack.org/#/c/45123/ Change Ie9ab9578: Synchronize the key manager interface with Cinder",6804,https://review.openstack.org/#/c/45103/,review.openstack.org,Patch,Clarifying,Internal,OpenStack293104,11564,"Patch Set 109:

miguel, should also have said for reference here's the devstack bits: https://review.openstack.org/#/c/342362/",11564,https://review.openstack.org/#/c/342362/,review.openstack.org,Patch,Clarifying,Internal,OpenStack501510,6062,"Patch Set 3:

Wait - I've attempted this before [1] and mriedem suggested it couldn't go in yet. Might want to talk to him about that and see if the rationale still makes sense. I'd imagine it does

[1] https://review.openstack.org/#/c/397835/",15334,https://review.openstack.org/#/c/397835/,review.openstack.org,Patch,Clarifying,Internal,OpenStack45029,7494,"Patch Set 1: Do not merge

I am opposed to this one for the same reason I was opposed to your first attempt in:

https://review.openstack.org/#/c/44964/

I understand that evacuate may have some special requirements on this process, but simply reverting the change that broke evacuate (but fixed rebuild) is not the proper way to go.",4393,https://review.openstack.org/#/c/44964/,review.openstack.org,Patch,Clarifying,Internal,OpenStack173985,6062,"Patch Set 4: Code-Review-1

Yea, agree with Jay, the is 500 return code before, so we needn't microversion bump. And there is description for it at line 223 https://review.openstack.org/#/c/177778/9/doc/source/devref/api_microversions.rst , Although the microversion bump guideline didn't merge yet, but 500 case already get some agreement.

And the exceed quota return code should be 403, as the description in API-WG guideline https://github.com/openstack/api-wg/blob/master/guidelines/http.rst",5754,https://github.com/openstack/api-wg/blob/master/guidelines/http.rst,github.com,Software homepage,Clarifying,Internal,OpenStack15229,1030,"Patch Set 6: I would prefer that you didn't merge this

We're currently trying to remove functionality out of nova-manage and replace it with REST APIs instead. 

https://blueprints.launchpad.net/nova/+spec/apis-for-nova-manage

So this would be sort of a backward step. I see there is also a changeset with a REST API so is this addition to nova-manage really needed. Or could it be added to the nova client using the REST API instead?",5292,https://blueprints.launchpad.net/nova/+spec/apis-for-nova-manage,blueprints.launchpad.net,Specification,Clarifying,Internal,OpenStack218645,14753,"Patch Set 11:

Also, I see that the CloudByte CI is responding to comments here in the review, which also doesn't seem right.  

http://docs.openstack.org/infra/system-config/third_party.html#posting-result-to-gerrit",5997,http://docs.openstack.org/infra/system-config/third_party.html#posting-result-to-gerrit,docs.openstack.org,Tutorial or article,Clarifying,Internal,OpenStack61168,2035,"Patch Set 10:

The latest patch addresses Salvatore's comment and ensures that notifications are sent to enabled agents regardless of status.

Note that copyright notices are no longer required for empty files: http://docs.openstack.org/developer/hacking/#openstack-licensing",2035,http://docs.openstack.org/developer/hacking/#openstack-licensing,docs.openstack.org,Tutorial or article,Clarifying,Internal,OpenStack30379,2874,"Patch Set 1:

I filed one doc bug for it: https://bugs.launchpad.net/openstack-manuals/+bug/1184500",2874,https://bugs.launchpad.net/openstack-manuals/+bug/1184500,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack198437,6635,"Patch Set 2: Code-Review-1

(1 comment)

John, I believe you are looking for the issue in wrong place.
As I see _get_subnetpool_id always returned  default_ipv4_subnet_pool or default_ipv6_subnet_pool if they were set in config (independently from cidr).
And this behavior was not changed during [1].
Probably issue you described in ticket [2] may have other causes, which require investigation.

[1] https://review.openstack.org/#/c/197090/ 
[2] https://bugs.launchpad.net/neutron/+bug/1471316",13768,https://bugs.launchpad.net/neutron/+bug/1471316,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack116835,11447,"Patch Set 7:

raise bug in openstack-manuals
https://bugs.launchpad.net/openstack-manuals/+bug/1364221",11447,https://bugs.launchpad.net/openstack-manuals/+bug/1364221,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack333029,5314,"Patch Set 2:

Filed https://bugs.launchpad.net/glance/+bug/1597126 about the schemas responses.

We should probably merge this with the current content, which reflects the current responses, and update the api-ref when/if the above bug is addressed.",5314,https://bugs.launchpad.net/glance/+bug/1597126,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack23905,2667,"Patch Set 2: Looks good to me, but someone else must approve

Good catch.  Though this shows that there's not enough Tempest coverage on evacuate yet, so would you mind opening a bug over at https://bugs.launchpad.net/tempest or contributing a test?",5441,https://bugs.launchpad.net/tempest,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack117994,8873,"Patch Set 17: -Code-Review

Perhaps this patch makes:

https://bugs.launchpad.net/neutron/+bug/1383391

Manifests itself more often. Shall we wait for Maru to get to the bottom of it with:

https://review.openstack.org/#/c/129720/

I'd be tempted to err on the side of caution here.",748,https://bugs.launchpad.net/neutron/+bug/1383391,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack130733,13101,"Patch Set 8: Workflow-1

Tempest cert tests:
https://bugs.launchpad.net/cinder/+bug/1388090

TODO:
- more unit tests",13101,https://bugs.launchpad.net/cinder/+bug/1388090,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack1879,1801,"Patch Set 5:

I just filed an openstack-ci bug about this: https://bugs.launchpad.net/openstack-ci/+bug/901027",321,https://bugs.launchpad.net/openstack-ci/+bug/901027,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack587234,21907,"Patch Set 1:

Could you confirm this patch won't cause regression on this bug: https://bugs.launchpad.net/neutron/+bug/1404823 ?",27654,https://bugs.launchpad.net/neutron/+bug/1404823,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack220802,17922,"Patch Set 2:

Yes, I have reported a bug for neutron. 
https://bugs.launchpad.net/neutron/+bug/1493662",17922,https://bugs.launchpad.net/neutron/+bug/1493662,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack159198,748,"Patch Set 3: Code-Review+1

We shouldn't apply additional code analysis because other projects don't? That's like saying that we need to drop the functional testing because most other projects don't do that either.

Pylint has value over pep8 as has been demonstrated by these bugs, all found by something that pep8 missed:
https://bugs.launchpad.net/neutron/+bug/1423774
https://bugs.launchpad.net/neutron/+bug/1423775
https://bugs.launchpad.net/neutron/+bug/1423777

Mark, please reconsider or at least give concrete and specific reasons why pylint should not be made voting.",8873,https://bugs.launchpad.net/neutron/+bug/1423775,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack105855,7448,"Patch Set 18: Code-Review-1

Here is a link in the openstack-manuals for dvr https://bugs.launchpad.net/openstack-manuals/+bug/1342962",10971,https://bugs.launchpad.net/openstack-manuals/+bug/1342962,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack459649,17947,"Patch Set 9: Code-Review+2

Looks like a bug was filed against checking for the minimum pyxcli version.  I believe that can be done in a separate patch.

https://bugs.launchpad.net/cinder/+bug/1696470",5997,https://bugs.launchpad.net/cinder/+bug/1696470,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack169124,8347,"Patch Set 3: Code-Review+1

Jenkins is broken temporarily in tempest tests (dsvm). See https://bugs.launchpad.net/horizon/+bug/1438543
So when it is fixed again you can recheck.",14271,https://bugs.launchpad.net/horizon/+bug/1438543,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack54245,7701,"Patch Set 2: I would prefer that you didn't merge this

(1 inline comment)

I have a question for this bug, and put it in https://bugs.launchpad.net/glance/+bug/1245775 . Thanks.",6549,https://bugs.launchpad.net/glance/+bug/1245775,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack48475,7817,"Patch Set 2:

@zhiyan, see bug https://bugs.launchpad.net/glance/+bug/1229569",6484,https://bugs.launchpad.net/glance/+bug/1229569,bugs.launchpad.net,Bug report,Elaborating,Internal,OpenStack301316,10267,"Patch Set 1:

I've added Kevin and Assaf to review this change. Probably we can move discussion for bug report. 

Kevin's idea of having 'ALLOCATING' status is an alternative of having transactions in create_ and update_router methods. Please, see comments https://review.openstack.org/#/c/230481/13/neutron/db/l3_hamode_db.py L405, so I'm not sure that moving creation of resources will have the same effect. But I haven't check this.",7249,https://review.openstack.org/#/c/230481/13/neutron/db/l3_hamode_db.py,review.openstack.org,Code,Elaborating,Internal,OpenStack513143,15439,"Patch Set 12: Code-Review-1

(4 comments)

Thanks for updating the config options. Please mark the deprecated ones so that is reflected in the config file using the oslo.config options like here:

https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/lvm.py#L68",11904,https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/lvm.py#L68,github.com,Code,Elaborating,Internal,OpenStack289868,10206,"Patch Set 1: Code-Review-1

(1 comment)

Hi, Madhuri, we need fix for Nova new API (v2.1 API) also, it is at https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/hypervisors.py#L131",5754,https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/hypervisors.py#L131,github.com,Code,Elaborating,Internal,OpenStack315750,4523,"Patch Set 2: Code-Review-1

(2 comments)

Maybe you can start using pre-defined fake_constants in fake UUIDs?

You can see an example:
https://review.openstack.org/#/c/297375/6/cinder/tests/unit/volume/drivers/emc/scaleio/test_consistencygroups.py",14907,https://review.openstack.org/#/c/297375/6/cinder/tests/unit/volume/drivers/emc/scaleio/test_consistencygroups.py,review.openstack.org,Code,Elaborating,Internal,OpenStack63975,8759,"Patch Set 10: I would prefer that you didn't merge this

Yes Arnaud you need rebase this again, sorry for that. Since you know we have a agreement at here https://review.openstack.org/#/c/59149/4/nova/virt/libvirt/imagehandler.py Line #67

Thanks for your patience.",6549,https://review.openstack.org/#/c/59149/4/nova/virt/libvirt/imagehandler.py,review.openstack.org,Code,Elaborating,Internal,OpenStack66987,7494,"Patch Set 2:

@Michael, the logic of prune is as following:
1) Get old compute node stats and new compute node stats
2) If old compute node stat metrics in new compute node stats, then pop out the old metrics and update it with new value
3) If set prune as true, then delete the metrics in the left old compute node stats.

So current logic already make sure duplicate values can be updated. This patch just want to make sure that admin can make some configuration to decide if to prune the old metrics or not.

You can refer to https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L637 for more detail.",7494,https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L637,github.com,Code,Elaborating,Internal,OpenStack241652,9284,"Patch Set 9:

i have a patch submitted to enable vhost-user support in the os-vif ovs plugin.

https://review.openstack.org/#/c/285613/

if the opencontrail vrouter is run as a vm on top of ovs with dpdk that patch should enable it to function once os-vif is integrated with nova.

if the OpenContrail vRouter uses network backend other then the reference backends (ovs,linuxbridge) then a os vif plugin should be created in https://github.com/Juniper/contrail-neutron-plugin

this would be done by cloning the subtree for either of the reference plugins  (https://github.com/openstack/os-vif/tree/master/vif_plug_linux_bridge or https://github.com/openstack/os-vif/tree/master/vif_plug_ovs)  and registering it as a stevadore entreypoint in the contrail-neutron-plugin

https://github.com/openstack/os-vif/blob/master/setup.cfg#L58-L61",11604,https://github.com/openstack/os-vif/blob/master/setup.cfg#L58-L61,github.com,Code,Elaborating,Internal,OpenStack347870,12171,"Patch Set 2:

> Ah, so this is because of a bug in the ComputeNode object having
 > cpu_info as nullable, which is a mismatch from the schema. It's not
 > supposed to be allowed to set cpu_info = None. But we can't fix
 > that until ComputeNode version 2.0
@melanie,
I can add a comment that this is a workaround until we fix the TheComputeNode.cpu_info not to be None.
And then we can fix the ironic driver
https://github.com/openstack/nova/blob/master/nova/virt/ironic/driver.py#L329 so that cpu_info=""{}"" instead of None",12171,https://github.com/openstack/nova/blob/master/nova/virt/ironic/driver.py#L329,github.com,Code,Elaborating,Internal,OpenStack281541,18997,"Patch Set 7: Code-Review-1

Hi Matan,

Take a look of the following examples on deprecating a config option.  Thanks.

https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/emc/emc_vnx_cli.py#L75

https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/hpe/hpe_3par_common.py#L85",6491,https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/hpe/hpe_3par_common.py#L85,github.com,Code,Elaborating,Internal,OpenStack337236,17973,"Patch Set 2:

@Andrey: Yes, currently you need to restart nova if you change the whitelist.

This is how it is handled in the PciTracker today.
See https://github.com/openstack/nova/blob/master/nova/pci/manager.py#L67

The network API is instantiated in the ComputeManager on init:
https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L496",17973,https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L496,github.com,Code,Elaborating,Internal,OpenStack290061,10577,"Patch Set 6:

The fake driver is created with libvirt version 10002001 and then the exception raised because it's lower than min_libvirt_other_arch (1002012 in case of ppc64*).

The exception raised is:
https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L496

# Libvirt version to match MIN_LIBVIRT_VERSION in driver.py
FAKE_LIBVIRT_VERSION = 1002001
https://github.com/openstack/nova/blob/master/nova/tests/unit/virt/libvirt/fakelibvirt.py#L154

which matches x86 min libvirt version:
MIN_LIBVIRT_VERSION = (1, 2, 1)
https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L198

MIN_LIBVIRT_KVM_PPC64_VERSION = (1, 2, 12)
https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L272 

The patch for checking min levels for ppc* libvirt/qemu is:
https://review.openstack.org/#/c/226555

The exception happens in the test_init_host function which creates a fake libvirt object:
https://github.com/openstack/nova/blob/master/nova/tests/unit/virt/libvirt/test_driver.py#L1508

This patch just mocks 'has_min_version' to be true ignoring FAKE_LIBVIRT_VERSION (which matches the x86_64 levels / hardcoded at driver.py anyway).

Note: this mock for has_min_version is already used in many other tests at nova/tests/unit/virt/libvirt/test_driver.py.

So instead of skipping the tests for non-x86 architectures, we run the tests for all architectures.

There are two tests affected by test_init_host using FAKE_LIBVIRT_VERSION:
nova.tests.unit.virt.libvirt.test_driver.LibvirtConnTestCase.test_lifecycle _event_registration nova.tests.unit.virt.test_virt_drivers.LibvirtConnTestCase.test_init_host

This patch is not reducing coverage. It just mocks what the hardcoded FAKE_LIBVIRT_VERSION is supposed to do (matches the min required levels for libvirt). And this approach is being used in many other tests already.

Please let me know if any further questions. 

--rfolco",8175,https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L496,github.com,Code,Elaborating,Internal,OpenStack318906,2750,"Patch Set 2: -Code-Review

> mriedem suggested this change, so I think we're good.

For historical reasons: http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2016-05-19.log.html#t2016-05-19T19:18:44",11303,http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2016-05-19.log.html#t2016-05-19T19:18:44,eavesdrop.openstack.org,Communication channel,Elaborating,Internal,OpenStack397800,14511,"Patch Set 2:

Link to discussion for reference: http://lists.openstack.org/pipermail/openstack-operators/2016-November/012085.html",14511,http://lists.openstack.org/pipermail/openstack-operators/2016-November/012085.html,lists.openstack.org,Communication channel,Elaborating,Internal,OpenStack555961,2472,"Patch Set 1:

Updated based on http://lists.openstack.org/pipermail/openstack-dev/2018-April/129056.html",2472,http://lists.openstack.org/pipermail/openstack-dev/2018-April/129056.html,lists.openstack.org,Communication channel,Elaborating,Internal,OpenStack389338,6167,"Patch Set 4:

Oh, I got the reason from I714caa085fa35cb4aac3b65c73a7de6d4807d04d

    Update hacking requirement to blacklist 0.13.0

    Per the thread on openstack-dev [1], hacking 0.13.0 that was released is
    in very sorry shape. Hacking may yet see other 0.13.x releases but
    0.13.0 should not be allowed at all.

    Further, very few projects have adopted newer versions of hacking, and
    this update won't be auto-pushed out to projects since hacking itself is
    blacklisted from those updates. With that in mind, merely raising the
    cap and blacklisting the bad version will cause no problems (even if a
    project updates their own requirement).

    [1]:
    http://lists.openstack.org/pipermail/openstack-dev/2016-December/108463.html

I will update the commit message anyways.",6167,http://lists.openstack.org/pipermail/openstack-dev/2016-December/108463.html,lists.openstack.org,Communication channel,Elaborating,Internal,OpenStack35178,5313,"Patch Set 8:

Here is the ci link I forgot in previous comment: http://lists.openstack.org/pipermail/openstack-dev/2013-November/019366.html",5313,http://lists.openstack.org/pipermail/openstack-dev/2013-November/019366.html,lists.openstack.org,Communication channel,Elaborating,Internal,OpenStack590041,7,"Patch Set 4:

Chris tested this in his perf harness yesterday [1] and the slow-down with this split-out was negligible (<0.5%, which may even be within the bounds of normal variance).

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-placement/%23openstack-placement.2018-08-09.log.html#t2018-08-09T16:10:43",14070,http://eavesdrop.openstack.org/irclogs/%23openstack-placement/%23openstack-placement.2018-08-09.log.html#t2018-08-09T16:10:43,eavesdrop.openstack.org,Communication channel,Elaborating,Internal,OpenStack42795,4690,"Patch Set 1:

Related ML threads:

http://lists.openstack.org/pipermail/openstack-dev/2013-August/013417.html
http://lists.openstack.org/pipermail/openstack-dev/2013-August/013718.html",4690,http://lists.openstack.org/pipermail/openstack-dev/2013-August/013718.html,lists.openstack.org,Communication channel,Elaborating,Internal,OpenStack38820,2835,"Patch Set 1:

""Requirement psutil does not match openstack/requirements value psutil<1.0""

Prolly just need to add the <1.0 and this patch will be good. If for some reason a higher version is needed, check out changing it here:
https://wiki.openstack.org/wiki/Requirements
https://github.com/openstack/requirements/blob/master/test-requirements.txt",177,https://github.com/openstack/requirements/blob/master/test-requirements.txt,github.com,Memo,Elaborating,Internal,OpenStack237785,8873,"Patch Set 4: Code-Review-1

I am having second thoughts: I am thinking that this might still be not enough as it assume internals of the agent. What if it doesn't have a tunnel ip, but it still works with l2pop? For instance, if I look at [1], it might be best to look into l2_population=True? Isn't that the ultimate check we want to do?

The patch that triggered this issue was to support OVS agents on ESX, and it does rely on a tunnel ip, but wouldn't the latter be a more appropriate fix?

[1] http://paste.openstack.org/show/476934/
[2] https://github.com/openstack/networking-vsphere/blob/master/networking_vsphere/agent/ovsvapp_agent.py#L402",748,http://paste.openstack.org/show/476934/,paste.openstack.org,Memo,Elaborating,Internal,OpenStack407728,14611,"Patch Set 1: Code-Review-1

Derek, Something similar needs to be done in setUp() of neutron/tests/unit/plugins/ml2/test_port_binding.py.
Here is the traceback: http://paste.openstack.org/show/591964/",22776,http://paste.openstack.org/show/591964/,paste.openstack.org,Memo,Elaborating,Internal,OpenStack195795,12924,"Patch Set 50:

John, appologies for the trouble configuring... I had put together instructions for folks testing this (thingee and hemna both successfully used them so hopefully they are still valid) and apparently forgot to actually post them on the review and not just in IRC once. https://etherpad.openstack.org/p/cinder-generic-image-volume-cache",12924,https://etherpad.openstack.org/p/cinder-generic-image-volume-cache,etherpad.openstack.org,Memo,Elaborating,Internal,OpenStack350953,19554,"Patch Set 3:

@Kevin Benton
Dear Mr.Kevin,
As last conversation [1]. I think the patch set [2] which used stored procedure is not look good so much, so we should change this solution as your comment. Would you mind giving me some advices what we should do now?

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-neutron/%23openstack-neutron.2016-07-21.log.html#t2016-07-21T09:04:18
[2] https://review.openstack.org/#/c/314054/",19554,http://eavesdrop.openstack.org/irclogs/%23openstack-neutron/%23openstack-neutron.2016-07-21.log.html#t2016-07-21T09:04:18,eavesdrop.openstack.org,Memo,Elaborating,Internal,OpenStack394946,22584,"Patch Set 3:

Ideally we want to verify the API->Registry call, which is where I think things fall over.



Something based on the v2 functional image tests which use the v2 registry [1], a bit like this (not tested):

 http://paste.openstack.org/show/588408/

might be one way to do it.


[1] glance/glance/tests/functional/v2/test_images.py",455,http://paste.openstack.org/show/588408/,paste.openstack.org,Memo,Elaborating,Internal,OpenStack8591,2271,"Patch Set 1:

Hi Micheal,

I'm seeing some errors when running this branch:

 column ""instance_uuid"" of relation ""instance_info_caches"" does not exist.

See line 356 of this paste for more information:

http://paste.openstack.org/show/18542/",360,http://paste.openstack.org/show/18542/,paste.openstack.org,Memo,Elaborating,Internal,OpenStack636855,10518,"Patch Set 3:

(2 comments)

Hi  Rodolfo,
I use a test script to test kill and wait. please check: https://etherpad.openstack.org/p/jesse-eventlet-wsgi-test

After server.kill(), ongoing requests do not stop until they got response from server, then server.wait() will raise greenlet.GreenletExit exception.
It seems it's not clear for the doc: http://eventlet.net/doc/modules/greenthread.html#eventlet.greenthread.GreenThread.kill

@Yulong
I also test this pool.resize(0), It seems if there is no pool.resize(0), after server.kill(), the new requests do not work.
I'm curious about this pool.resize(0)...",10518,https://etherpad.openstack.org/p/jesse-eventlet-wsgi-test,etherpad.openstack.org,Memo,Elaborating,Internal,OpenStack103818,167,"Patch Set 3: Code-Review-2

code_cleanup_batching

This patch will be merged the week after end of milestone (24th July)

See https://wiki.openstack.org/wiki/CinderCodeCleanupPatches for details, and feel free to join #openstack-cinder if you feel this patch should be merged sooner",1207,https://wiki.openstack.org/wiki/CinderCodeCleanupPatches,wiki.openstack.org,Others,Elaborating,Internal,OpenStack24794,221,"Patch Set 1:

@Brian: Thanks for the point.

Main feature has been described in the following wiki. 
Also, blueprint description was updated little bit.
https://wiki.openstack.org/wiki/GeneralBareMetalProvisioningFramework

Now, PXE+IPMI back-end has been set for bare-metal driver.
Through this patch, [non-PXE+PDU] tilera back-end is being added for provisioning tilera machines.

Do you want me to add documents to this patch set (like https://review.openstack.org/#/c/16608/15/nova/virt/baremetal/doc/tilera-bm-installation.rst and https://review.openstack.org/#/c/16608/15/nova/virt/baremetal/doc/tilera-bm-instance-creation.rst), add more detailed log, or more detailed description on blueprint? Plz let me know. I appreciate your help.",221,https://wiki.openstack.org/wiki/GeneralBareMetalProvisioningFramework,wiki.openstack.org,Others,Elaborating,Internal,OpenStack206614,6773,"Patch Set 1: Code-Review-2

I am a bit worried about the upgrade impact of this. 

Note you will need a nova blueprint to track the nova parts of the iroinc blueprint.

-2 is procedural ...

Sorry, you need to get a nova blueprint approved before we can merge this feature code.
Unfortunately, as we have also now past the non-priority feature freeze for Liberty, you will need to submit this blueprint for Mitaka.
For more details on our process, please see:
https://wiki.openstack.org/wiki/Nova/Liberty_Release_Schedule
Any questions, please email me or find me on IRC johnthetubaguy",782,https://wiki.openstack.org/wiki/Nova/Liberty_Release_Schedule,wiki.openstack.org,Others,Elaborating,Internal,OpenStack157616,8940,"Patch Set 1:

Do email me if you need help on moving forward with this.

Its look late for liberty, but we can work to get this into mitaka.

For more details on our process, please see:
https://wiki.openstack.org/wiki/Nova/Liberty_Release_Schedule
Any questions, please email me or find me on IRC johnthetubaguy",782,https://wiki.openstack.org/wiki/Nova/Liberty_Release_Schedule,wiki.openstack.org,Others,Elaborating,Internal,OpenStack53746,1313,"Patch Set 5:

Please stop just using ""recheck no bug""

and instead use the bug id of the corresponding transient failure. You can see failures which are commonly causing problems in the gate here:

http://status.openstack.org/rechecks

Otherwise have a look through the appropriate bug tracker or submit a new bug report. Accurate tracking of transient failures in the gate helps us make the CI system more reliable",5292,http://status.openstack.org/rechecks,status.openstack.org,Others,Elaborating,Internal,OpenStack117407,12175,"Patch Set 1: Code-Review-2

Yes, the changed file will be removed soon.
and the gate(http://status.openstack.org/zuul/) is very busy now. so we need to avoid this kind of change for smooth development.

Please remove the dependency from the other patch.",6167,http://status.openstack.org/zuul/,status.openstack.org,Others,Elaborating,Internal,OpenStack338308,14305,"Patch Set 4: Code-Review-1

Hey Yuriy, thanks for cleaning this up! I didn't realize that there was work being done on this file. This file (test_netapp_nfs.py) along with test_netapp.py hosts a bunch of redundant and vestigial tests, that sometimes just provide fake line coverage. I worked on a patch to remove these files and rewrite some tests into the places where we'd host these tests: https://review.openstack.org/#/c/346093

Could you please take a look? I would be happy to take your changes along and work with you as co-author, since my team has a bunch of dependent patches that we're working on, for the NetApp drivers, in terms of features.",16643,https://review.openstack.org/#/c/346093,review.openstack.org,Patch,Elaborating,Internal,OpenStack63254,5280,"Patch Set 1: I would prefer that you didn't merge this

please refer the wikipage firstly if you want to implement this bp: https://wiki.openstack.org/wiki/VirtDriverGuestCPUTopology

and also an implementation is here: https://review.openstack.org/56510

In addition, your rules to set vcpu topology is invalid, you defines vcpu topology in the extra_specs of flavor, but users may use a flavor to boot different instance by different images, the os in images may support different topologies(espically number of sockets supported by windows), so your topology defined in extra_specs may be invalid.

This bp is in discussion, and waiting for the responses of other virt driver maintainers, we should implement this bp based on their voices.",4468,https://review.openstack.org/56510,review.openstack.org,Patch,Elaborating,Internal,OpenStack25165,1561,"Patch Set 1:

This is done in oslo-incubator as of:

commit 229b815fb72dccf998b18a0ad019cc61ccb888d8
Author: Matthew Sherborne <msherborne@gmail.com>
Date:   Sun Mar 10 11:06:38 2013 +1000

    Improves Logging for for rpc method timeouts
    
    This patch moves the traceback for an rpc timeout from inside an
    iterator, which gave a useless traceback, into the main flow of the
    program.
    
    It also adds the rpc method being called and the topic used to the
    exception's message.
    
    When the caller logs the message higher up the stack, the log
    information and traceback will be more useful.
    
    Finally it removes the timeout logging in the amqp.py module, in the
    spirit of bug #1137994 and https://review.openstack.org/#/c/23295/
    
    Works towards: bug #1148516
    
    Change-Id: I29a3b1b97c6114c4479e2b71c1257c4d72131535",1561,https://review.openstack.org/#/c/23295/,review.openstack.org,Patch,Elaborating,Internal,OpenStack144131,10674,"Patch Set 13:

Thanks for your comment, Mr yang. I reflected your comment into my patch.

And, I checked following review-boards to confirm namespace change for oslo which i used in this patch.

oslo.config=>https://review.openstack.org/147656
oslo.utils=>https://review.openstack.org/148018
oslo.concurrency=>https://review.openstack.org/143222/
oslo.serialization=>https://review.openstack.org/149426",10674,https://review.openstack.org/149426,review.openstack.org,Patch,Elaborating,Internal,OpenStack595399,20190,"Patch Set 2:

OK, I saw that you are trying to add it in https://review.openstack.org/#/c/593984/ I think you should
do this in that one.",15888,https://review.openstack.org/#/c/593984/,review.openstack.org,Patch,Elaborating,Internal,OpenStack328131,20733,"Patch Set 3: Code-Review-1

I think you needn't modify the translation file which are under ""nova/locale"". There will be rebot will propose translation change when the string changed in the code, like this https://review.openstack.org/#/c/209780/7",5754,https://review.openstack.org/#/c/209780/7,review.openstack.org,Patch,Elaborating,Internal,OpenStack19561,5638,"Patch Set 2:

Gary,

Yes, i will do that in a little bit today (add the configuration variables to the quantum.conf configuration file).

My plan is to get all the servers to listen on ipv6 first and then attack the clients. You can see the other reviews here - https://review.openstack.org/#/dashboard/5638 (you should see a list of reviews for ipv6 and ssl)",5638,https://review.openstack.org/#/dashboard/5638,review.openstack.org,Patch,Elaborating,Internal,OpenStack312113,16308,"Patch Set 5:

> Nice work. You should add a gate job, use this patch as an example
 > for infra https://review.openstack.org/#/c/313015/. Then your docs
 > will publish to developer.openstack.org.

Sure.
As discussed,I will add in next patch..
Thanks for review..",16308,https://review.openstack.org/#/c/313015/,review.openstack.org,Patch,Elaborating,Internal,OpenStack536630,5314,"Patch Set 6:

Let's skip the failing py35 test so we at least have *some* functional test coverage.  I put up patch https://review.openstack.org/536939 for that (with associated bug https://bugs.launchpad.net/glance/+bug/1745003 ).  We can merge that patch and then recheck this one.",5314,https://review.openstack.org/536939,review.openstack.org,Patch,Elaborating,Internal,OpenStack277126,11131,"Patch Set 3: Code-Review-2

(1 comment)

The constraints on mock in test-requirements is being reverted as it broke a lot of other projects. https://review.openstack.org/#/c/278814/

It would have been just matter of time before we got affected (check inline comment). Thanks to browne (Eric Brown) for the heads-up on the infra channel. 

Let's hold off until the revert kicks in.",7575,https://review.openstack.org/#/c/278814/,review.openstack.org,Patch,Elaborating,Internal,OpenStack349471,21239,"Patch Set 2:

As N353 will be used by [1], we should switch it to N354, I think. 

[1]: https://review.openstack.org/#/c/334844",18602,https://review.openstack.org/#/c/334844,review.openstack.org,Patch,Elaborating,Internal,OpenStack204138,17116,"Patch Set 2: Code-Review+1

I am also finding the same issue with the metadefs controllers (e.g. namespaces)

So, after looking at https://review.openstack.org/#/c/203688 and this, I think we can generically fix this issue by checking whether the request body is a JSON object that we expect in openstack.common.wsgi.JsonRequestDeserializer https://github.com/openstack/glance/blob/master/glance/common/wsgi.py#L789.


What do you think ?",7575,https://review.openstack.org/#/c/203688,review.openstack.org,Patch,Elaborating,Internal,OpenStack231062,1297,"Patch Set 2:

Svg @ https://review.openstack.org/cat/231062%2C2%2Cdoc/source/images/create_vm_states.svg%5E0",1297,https://review.openstack.org/cat/231062%2C2%2Cdoc/source/images/create_vm_states.svg%5E0,review.openstack.org,Patch,Elaborating,Internal,OpenStack315495,10343,"Patch Set 1: Code-Review+2 Workflow+1

There is a fix up for this https://review.openstack.org/#/c/315201/3 but it's on a stack of dependencies. Let's just get the fix in now.",5441,https://review.openstack.org/#/c/315201/3,review.openstack.org,Patch,Elaborating,Internal,OpenStack153033,7,"Patch Set 10:

Hi Walter,

The spec hasn't been re-approved for Liberty yet. See https://review.openstack.org/#/c/179104/ 

Cheers,
Gibi",9708,https://review.openstack.org/#/c/179104/,review.openstack.org,Patch,Elaborating,Internal,OpenStack17441,2874,"Patch Set 3:

quantum subnet-update a4d5ee98-d64b-4b25-930e-7ca2ed8a5207 --host_routes list=true type=dict destination=9.0.1.0/24,nexthop=9.0.1.1
the command below will reset the host_routes: quantum subnet-update a4d5ee98-d64b-4b25-930e-7ca2ed8a5207 --host_routes
client pathc is at: https://review.openstack.org/17436",2874,https://review.openstack.org/17436,review.openstack.org,Patch,Elaborating,Internal,OpenStack221326,18173,"Patch Set 2:

Because of I execute 'git review' failure in this branch, I can only build new branch to upload code! 

New modifying url is https://review.openstack.org/#/c/222699/",18173,https://review.openstack.org/#/c/222699/,review.openstack.org,Patch,Elaborating,Internal,OpenStack474892,16688,"Patch Set 2:

Hello reviewers:

With this patch I'm trying to solve a problem in os-vif [1]. The OVS datapath information is needed to set the correct type in the OVS bridge.

There are four patches related to this bug:
Nova: https://review.openstack.org/#/c/474892/
Neutron: https://review.openstack.org/#/c/474588/
Neutron-lib: https://review.openstack.org/#/c/474248/ (this one)
os-vif: https://review.openstack.org/#/c/474914/

These are the changes made:
1) Neutron will add to VIF details the datapath type to the vif details dict. If this information is not given in the config file, the default parameter written will be OVS_DATAPATH_SYSTEM, which is the default value.
2) Nova will receive this information (if given in the dict), getting the value stored in vif['details']. If the key is not set, the default datapath will be None. So Nova is protected in case the dict doesn't have this information.
3) The change in neutron-lib (this patch) is needed for Neutron to keep the same dict key name (matching the name set in nova.network.model)
4) Finally, os-vif will receive the VIF information given by Nova. If the datapath_type is not given in the variable (dict), the default value, OVS_DATAPATH_SYSTEM, will be set.

As you can see, it's indeed an API change, but the projects affected are protected in case the information expected in the variable passed is not present.

[1] https://bugs.launchpad.net/os-vif/+bug/1632372",16688,https://review.openstack.org/#/c/474588/,review.openstack.org,Patch,Elaborating,Internal,OpenStack469978,8864,"Patch Set 1:

Submitted [1] to test this, since we don't really test with memcache in the gate

[1] https://review.openstack.org/#/c/469980/",8864,https://review.openstack.org/#/c/469980/,review.openstack.org,Patch,Elaborating,Internal,OpenStack240858,9708,"Patch Set 4:

https://review.openstack.org/#/c/242008/6 is the reno patch, it's in the gate now. After that lands we should build a release note for this.",2750,https://review.openstack.org/#/c/242008/6,review.openstack.org,Patch,Elaborating,Internal,OpenStack385364,7730,"Patch Set 2:

(1 comment)

Thanks for your review on that serie Alexander. You might want to look at the spec too: https://review.openstack.org/#/c/284094/",7730,https://review.openstack.org/#/c/284094/,review.openstack.org,Patch,Elaborating,Internal,OpenStack34642,7018,"Patch Set 12:

I've run this change with the Nexus+OVS configuration on the Cisco plugin and it works fine there too. I also ran with your client side patch [1] as well.

[1] https://review.openstack.org/#/c/36756/",105,https://review.openstack.org/#/c/36756/,review.openstack.org,Patch,Elaborating,Internal,OpenStack126546,11554,"Patch Set 16:

[2]: https://review.openstack.org/#/c/155374/",8788,https://review.openstack.org/#/c/155374/,review.openstack.org,Patch,Elaborating,Internal,OpenStack123738,13161,"Patch Set 2:

Thanks for your interest Fei! I've just added more unit tests to the glanceclient review - https://review.openstack.org/#/c/123739/ which is strictly related to this one. Do you think that's enough or should I work at something else too in the glance project?

This bug is more about the way how the glanceclient communicate with glanceAPI, and how it's preparing data for it. I've checked current tests in glance and it seems they cover all the scenarios.",13161,https://review.openstack.org/#/c/123739/,review.openstack.org,Patch,Elaborating,Internal,OpenStack123667,5511,"Patch Set 1: Code-Review+1

regardless of an argument about if these should be unit tests, this does seem to match what we did here: https://review.openstack.org/#/c/37419/",782,https://review.openstack.org/#/c/37419/,review.openstack.org,Patch,Elaborating,Internal,OpenStack327345,4187,"Patch Set 1:

@Ilya, just to be clear, this patch should be abandoned and the server CRUD patch [1] should be make dependent upon your patch here [2]?

[1] https://review.openstack.org/#/c/320092/
[2] https://review.openstack.org/#/c/323518/",16800,https://review.openstack.org/#/c/323518/,review.openstack.org,Patch,Elaborating,Internal,OpenStack280539,8213,"Patch Set 6:

(1 comment)

Sure, there's a blueprint for this. I haven't added it yet to the commit message: https://review.openstack.org/#/c/289405/",8213,https://review.openstack.org/#/c/289405/,review.openstack.org,Patch,Elaborating,Internal,OpenStack523257,333,"Patch Set 34:

that's right.
So how about the following patch for neutron-lib to add priority?
Is this a way to go?
https://review.openstack.org/#/c/541766/",333,https://review.openstack.org/#/c/541766/,review.openstack.org,Patch,Elaborating,Internal,OpenStack282214,13689,"Patch Set 2:

Thank you for reviewing.

As Matt mentions, it would be better to modify description in documents.
I submitted a patch for documentation.
https://review.openstack.org/#/c/288242/",13689,https://review.openstack.org/#/c/288242/,review.openstack.org,Patch,Elaborating,Internal,OpenStack640797,9531,"Patch Set 13: Code-Review-1

(3 comments)

-1 for how the deprecation logging is happening.  I also think an upgrade check - similar to what Slawek is doing in neutron-fwaas [1] would be advisable given the potential operator impact.

[1] https://review.openstack.org/#/c/637203/",13995,https://review.openstack.org/#/c/637203/,review.openstack.org,Patch,Elaborating,Internal,OpenStack270001,7448,"Patch Set 4:

PS2 == PS4  Sorry for the mistake.  I was trying to update the other patch [1] and got my change ids mixed up.

[1] https://review.openstack.org/#/c/212669/",7448,https://review.openstack.org/#/c/212669/,review.openstack.org,Patch,Elaborating,Internal,OpenStack267694,19136,"Patch Set 5: Code-Review-1

I don't believe this is the way it should be done. If you're making some tests compatible with Python 3 add them to the list in tests-py3.txt, so tests will be run in gate-cinder-python34 check. That's the only way we'll prevent further regression in this matter. Please refer to the way Victor is doing his patches [1]. For example [2]

[1] https://review.openstack.org/#/q/owner:%22Victor+Stinner+%253Cvictor.stinner%2540enovance.com%253E%22
[2] https://review.openstack.org/#/c/249398/",11600,https://review.openstack.org/#/q/owner:%22Victor+Stinner+%253Cvictor.stinner%2540enovance.com%253E%22,review.openstack.org,Patch,Elaborating,Internal,OpenStack34150,6072,"Patch Set 1: I would prefer that you didn't merge this

I would prefer to not change the quotes style here, that should be a separate patch.  Although IMHO, I don't think its worth changing the quotes style at all, at least until we can automatically enforce that requirement (if we want it).

On a related note: https://review.openstack.org/#/c/34483/",1849,https://review.openstack.org/#/c/34483/,review.openstack.org,Patch,Elaborating,Internal,OpenStack528028,6873,"Patch Set 3:

Issue is with force detach where we do not have the connector info.

See:
https://review.openstack.org/#/c/471861/
https://review.openstack.org/#/c/477422/
https://review.openstack.org/#/c/459856/
https://review.openstack.org/#/c/473877/
https://review.openstack.org/#/c/478563/",11904,https://review.openstack.org/#/c/471861/,review.openstack.org,Patch,Elaborating,Internal,OpenStack274023,14885,"Patch Set 8:

> Armando pushed the change to project-config and to Neutron to make
 > sure of this patch:
 > 
 > https://review.openstack.org/#/c/304324/
 > https://review.openstack.org/#/c/304321/

There's also:

https://review.openstack.org/#/c/303621/

Which is meant to go in as soon as we've gone past all the bumps.",748,https://review.openstack.org/#/c/304324/,review.openstack.org,Patch,Elaborating,Internal,OpenStack243656,13900,"Patch Set 1:

Thanks John! I found out that Cinder locale files are imported from Transifex

    https://www.transifex.com/openstack/cinder/

They are modified by OpenStack Proposal Bot, for example

    https://review.openstack.org/#/c/94136/

So, no need to modify them here.",13900,https://review.openstack.org/#/c/94136/,review.openstack.org,Patch,Elaborating,Internal,OpenStack503596,18940,"Patch Set 3:

There was a release note for Pike:
https://review.openstack.org/#/c/460640/12/releasenotes/notes/new-nova-config-section-2a7a51a0572e7064.yaml
Also DocImpact flag was added to the above commit.

The docstring here also refers to the new config group:
https://review.openstack.org/#/c/460640/12/cinder/scheduler/filters/instance_locality_filter.py

So the new options are documented at least as the options which are to be removed now. Also they're more intuitive, I guess everyone who configured a service must be familiar with the keystone_authtoken like config groups.",18940,https://review.openstack.org/#/c/460640/12/cinder/scheduler/filters/instance_locality_filter.py,review.openstack.org,Patch,Elaborating,Internal,OpenStack74423,4120,"Patch Set 6: -Code-Review

Removing my -1, found the spec https://review.openstack.org/#/c/99006/",7166,https://review.openstack.org/#/c/99006/,review.openstack.org,Patch,Elaborating,Internal,OpenStack5872,144,"Patch Set 1:

Fix is here: https://review.openstack.org/5893",67,https://review.openstack.org/5893,review.openstack.org,Patch,Elaborating,Internal,OpenStack127057,7770,"Patch Set 1:

Thanks for pointing that out. However, I don't think that patch is removing oslo-incubator middleware. Like the deprecation notice here:
https://review.openstack.org/#/c/126003/17/nova/openstack/common/middleware/request_id.py
Am I missing something?",7770,https://review.openstack.org/#/c/126003/17/nova/openstack/common/middleware/request_id.py,review.openstack.org,Patch,Elaborating,Internal,OpenStack34535,24,"Patch Set 2: I would prefer that you didn't merge this

Hi,
Something is fishy. Chuck updated https://review.openstack.org/#/c/34539/ (which was approved) but this file no loner exists.
Please see https://github.com/openstack/requirements.
Thanks
Gary",1653,https://github.com/openstack/requirements,github.com,Software homepage,Elaborating,Internal,OpenStack168876,7730,"Patch Set 1:

Although current driver implementations all have flaws, especially in their implementations of get_all() I think separation of concerns is the right way forward here, not the other way around. There is no reason for mc/zk drivers to make any db calls at all, only the db driver should do that. Therefore I don't think we should mix this with objects.

Long term, i think this effort is where we should go:
https://blueprints.launchpad.net/nova/+spec/tooz-for-service-groups

Short term, we could fix up the api in preparation for tooz by getting rid of the service param from its methods. There have been work in that direction that didn't made it all the way in kilo:
https://blueprints.launchpad.net/nova/+spec/servicegroup-api-is-up-host-topic

Fixing the implementations of get_all() could be done, but I'm not sure it is worth the effort if tooz is close.",6450,https://blueprints.launchpad.net/nova/+spec/servicegroup-api-is-up-host-topic,blueprints.launchpad.net,Specification,Elaborating,Internal,OpenStack55134,8895,"Patch Set 6:

Hi!

Does anyone still watch this patch?

I filed https://blueprints.launchpad.net/cinder/+spec/create-snapshot-task-flow .
Would you add this reference to your commit message?


Or does any other problems remain?
If you have any problem in this blueprint, could you tell me about?",8922,https://blueprints.launchpad.net/cinder/+spec/create-snapshot-task-flow,blueprints.launchpad.net,Specification,Elaborating,Internal,OpenStack199588,14562,"Patch Set 28:

This is bp:
https://blueprints.launchpad.net/neutron/+spec/keep-dns-nameserver-orderconsistency",14562,https://blueprints.launchpad.net/neutron/+spec/keep-dns-nameserver-orderconsistency,blueprints.launchpad.net,Specification,Elaborating,Internal,OpenStack34559,7781,"Patch Set 3:

I registered the blueprint: 
https://blueprints.launchpad.net/nova/+spec/consistency-securitygroup-api-nova-neutron",7781,https://blueprints.launchpad.net/nova/+spec/consistency-securitygroup-api-nova-neutron,blueprints.launchpad.net,specification,Elaborating,Internal,OpenStack570008,11975,"Patch Set 8:

> i think this should be removed as well...
 > 
 > https://github.com/openstack/neutron/blob/fab6bcbdcdf655b5f1eb0c804ed82e09403159a3/lower-constraints.txt#L64

I'm not sure if it should be removed from lower-constraints. This file contains many requirements which are not in neutron requirements file in fact (or test-requirements as well). For example in keystoneauth repo which already switched to stestr, it's not removed from lower-constraints: https://github.com/openstack/keystoneauth/blob/master/lower-constraints.txt#L41",11975,https://github.com/openstack/keystoneauth/blob/master/lower-constraints.txt#L41,github.com,Specification,Elaborating,Internal,OpenStack54994,7156,"Patch Set 1:

See use case in blueprint: https://blueprints.launchpad.net/cinder/+spec/attachment-notifications

Notifications sent by Nova are instance centric. I need a volume centric point of view as volumes have a life of their own outside Nova. Without those notifications, samples collected by Ceilometer for Cinder do not reflect changes in volume state.

Furthermore, I do not want to have to crosscheck Nova and Cinder samples to track the lifecycle/changes of a volume. (volume creation/resize in Cinder but attach/detach in Nova...)",7156,https://blueprints.launchpad.net/cinder/+spec/attachment-notifications,blueprints.launchpad.net,Specification,Elaborating,Internal,OpenStack181663,12053,"Patch Set 1:

Hi，ChangBo Guo：
It is better to explicitly import CONF.host like https://github.com/openstack/nova/blob/master/nova/compute/manager.py#L249. Is is suggested in http://docs.openstack.org/developer/oslo.config/cfgfilter.html",12053,http://docs.openstack.org/developer/oslo.config/cfgfilter.html,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack18462,6450,"Patch Set 16: I would prefer that you didn't merge this

I like the direction of this, especially how the utilization based scheduling is optional and enabled by enabling specific filters.

The naming of the two new filters can be confusing (as per above comments).  With this addition I think it makes sense to rename the ram filter.  Perhaps ram_static_filter vs ram_dynamic_filter?  or ram_usage_filter vs ram_predicative_filter?

Also, can you update the devref with the changes. (http://docs.openstack.org/developer/nova/devref/filter_scheduler.html#filtering  https://github.com/openstack/nova/blob/master/doc/source/devref/filter_scheduler.rst)

Also your copyright date says 2012",1849,http://docs.openstack.org/developer/nova/devref/filter_scheduler.html#filtering,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack37843,7494,"Patch Set 3:

This actually uploaded a new (broken) changeset to my patch.

Please use:
git review -R

See:
https://wiki.openstack.org/wiki/Gerrit_Workflow",782,https://wiki.openstack.org/wiki/Gerrit_Workflow,wiki.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack248989,15888,"Patch Set 93:

(2 comments)

> This has now hit too many issues to get this merged by friday.
 > Sorry this is so close but so far.
 > 
 > Sorry, we have now hit the Non-Priority Feature Freeze for Mitaka.
 > For more details please see: http://docs.openstack.org/releases/schedules/mitaka.html#m-nova-npff
 > and http://docs.openstack.org/developer/nova/process.html#non-priority-feature-freeze
 > --johnthetubaguy 2016.02.03

Hi, Thanks for your review, but those changes seems not really hard to change, and I can fix them really quick, could you please have a check again? I really hope we can merge this one for this release.",15888,http://docs.openstack.org/developer/nova/process.html#non-priority-feature-freeze,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack255015,11903,"Patch Set 2:

Please add a release note describing the new functionality:

http://docs.openstack.org/developer/reno/usage.html#creating-new-release-notes",11904,http://docs.openstack.org/developer/reno/usage.html#creating-new-release-notes,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack341345,22100,"Patch Set 4:

We need to see CI reporting on this patch.  Also please create a wiki page for your CI here:

https://wiki.openstack.org/wiki/ThirdPartySystems",6491,https://wiki.openstack.org/wiki/ThirdPartySystems,wiki.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack206788,4428,"Patch Set 1: Code-Review-1

The first line should be limited to 50 characters. https://wiki.openstack.org/wiki/GitCommitMessages#Summary_of_Git_commit_message_structure",16883,https://wiki.openstack.org/wiki/GitCommitMessages#Summary_of_Git_commit_message_structure,wiki.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack379767,14611,"Patch Set 1: -Workflow

Ready for review. According to Armando [1] deprecated code, should be removed ASAP, after fulfilling requirements of being at least 3 months old [2]

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-neutron/%23openstack-neutron.2016-10-17.log.html#t2016-10-17T22:16:43
[2] https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html#requirements",14611,https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html#requirements,governance.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack177778,5754,"Patch Set 3:

Thanks all the English tuning from Eli and Matthew :)

@Matthew, actually I'm not going to describe what is back-compatible or not in this devref. I'm going to describe what can be changed by Microversion.

Thanks for good point on confuse with https://wiki.openstack.org/wiki/APIChangeGuidelines

But Microversion can be used both for back-compatible and back-incompatible changes. The goal of microverion is enable us improve our API. So you are right, looks like we create another guideline. Let us resolve those confuse.

I'm ok discussion this in the nova api meeting.

Thanks
Alex",5754,https://wiki.openstack.org/wiki/APIChangeGuidelines,wiki.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack661522,29071,"Patch Set 4: Code-Review-1

(2 comments)

Many test cases get failed, you can follow this guide to run unit test and functional test loally:
https://docs.openstack.org/neutron/latest/contributor/testing/testing.html",9531,https://docs.openstack.org/neutron/latest/contributor/testing/testing.html,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack85211,8759,"Patch Set 12:

Also https://review.openstack.org/#/c/119957/ is probably useful (click on the svg files and download them and view them in a browser) that shows exactly what the transitions are (the http://docs.openstack.org/developer/taskflow/states.html is mostly right, that review just slightly updates it to be more accurate).",1297,http://docs.openstack.org/developer/taskflow/states.html,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack34968,2874,"Patch Set 2:

http://docs.openstack.org/developer/nova/devref/threading.html

When you have something like osapi_compute_workers set to a number >0, this will fork workers in their own process, same code space, separate data space.

But I might still be hallucinating...it's pretty hot on the west coast these days...",748,http://docs.openstack.org/developer/nova/devref/threading.html,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack28868,1994,"Patch Set 3:

Yes, you should only update lockutils. See https://wiki.openstack.org/wiki/Oslo#Syncing_Code_from_Incubator",1247,https://wiki.openstack.org/wiki/Oslo#Syncing_Code_from_Incubator,wiki.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack187571,11303,"Patch Set 7: Code-Review-1

(1 comment)

So I am loving this, its awesome:
http://docs-draft.openstack.org/71/187571/7/check/gate-nova-docs/75c4c21//doc/build/html/bugs.html

But I think some of the details should go here:
http://docs.openstack.org/infra/manual/developers.html#working-on-bugs

Maybe we need more details on the Nova specific bits, although we could add those later.",782,http://docs.openstack.org/infra/manual/developers.html#working-on-bugs,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack75839,10374,"Patch Set 3: I would prefer that you didn't merge this

Like mentioned in previous review, if 'import' is removed and there is no code/comment/docstring, the license header should be removed as well.  Please refer to: http://docs.openstack.org/developer/hacking/#openstack-licensing",2759,http://docs.openstack.org/developer/hacking/#openstack-licensing,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack654277,9414,"Patch Set 2:

The release note can be updated by only updating the file in that branch, please check [1] for more information.

[1] https://docs.openstack.org/ironic/latest/contributor/faq.html#update-a-release-note",9414,https://docs.openstack.org/ironic/latest/contributor/faq.html#update-a-release-note,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack421722,24456,"Patch Set 1: Code-Review-2

Please see http://docs.openstack.org/developer/glance/contributing/minor-code-changes.html",5314,http://docs.openstack.org/developer/glance/contributing/minor-code-changes.html,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack174854,7730,"Patch Set 19: Code-Review-2

Sorry, we have now hit the Non-Priority Feature Freeze for Mitaka. For more details please see: http://docs.openstack.org/releases/schedules/mitaka.html#m-nova-npff and http://docs.openstack.org/developer/nova/process.html#non-priority-feature-freeze
--johnthetubaguy 2016.01.31",782,http://docs.openstack.org/releases/schedules/mitaka.html#m-nova-npff,docs.openstack.org,Tutorial or article,Elaborating,Internal,OpenStack64014,7653,"Patch Set 16: I would prefer that you didn't merge this

This may have been fixed here already:
https://bugs.launchpad.net/cinder/+bug/1242942
https://review.openstack.org/#/c/61088/

As winston-d said, this also doesn't feel like the right way to fix this.",4523,https://bugs.launchpad.net/cinder/+bug/1242942,bugs.launchpad.net,Bug report,Explaining Necessity,Internal,OpenStack460987,7634,"Patch Set 7:

This whole feature is going away soon. No need to put lipstick on the pig :) https://bugs.launchpad.net/nova/+bug/1682020/",15334,https://bugs.launchpad.net/nova/+bug/1682020/,bugs.launchpad.net,Bug report,Explaining Necessity,Internal,OpenStack570270,11975,"Patch Set 3: Code-Review-1

Then more reason to remove it because this patch [1] moved disable_ipv6() from BridgeDevice to base IPDevice class

[1] https://github.com/openstack/neutron/commit/fc8ebae0351f5b6596951cdfc5cb4259501d84f2",19307,https://github.com/openstack/neutron/commit/fc8ebae0351f5b6596951cdfc5cb4259501d84f2,github.com,Github activity,Explaining Necessity,Internal,OpenStack25107,616,"Patch Set 1: Abandoned

John has a change proposed to fix this test here:

https://review.openstack.org/#/c/25188/",616,https://review.openstack.org/#/c/25188/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack574178,27615,"Abandoned

https://review.openstack.org/#/c/576479/",27615,https://review.openstack.org/#/c/576479/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack105675,8290,"Patch Set 4:

Note this conflicts with both https://review.openstack.org/#/c/102408/ and https://review.openstack.org/#/c/102725/ which predates this patch. Perhaps you could work out if there are any unique bits?",5292,https://review.openstack.org/#/c/102408/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack22928,261,"Patch Set 2: I would prefer that you didn't merge this

Why not simply remove the validation of the network_type in the core, and let each plugin validate this based on the types it supports? Does the core have any need to know this list other than to do this validation? Last I looked, existing plugins that implement the provider extension already do this validation and return an appropriate error if the network_type isn't supported. Note that the supported network types can depend on configuration (i.e. enable_tunneling in openvswitch or the set of TypeDrivers loaded in ml2). The WIP ml2 patch at https://review.openstack.org/#/c/20105/ changes the network_type validation in the core to simply validate a string. Is anything more really needed?",1689,https://review.openstack.org/#/c/20105/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack564090,11904,"Patch Set 3:

Better list solution in https://review.openstack.org/#/c/565788/1",11904,https://review.openstack.org/#/c/565788/1,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack506686,26955,"Abandoned

This work was done in [1].

[1] https://review.opendev.org/#/c/611974/",14070,https://review.opendev.org/#/c/611974/,review.opendev.org,Patch,Explaining Necessity,Internal,OpenStack33914,5292,"Patch Set 2:

Problems identified in patch set 1 (action names + some other stuff) are addressed in https://review.openstack.org/#/c/35451/",5292,https://review.openstack.org/#/c/35451/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack106952,9323,"Patch Set 1:

This approach was used by sahid before in 

https://review.openstack.org/#/c/61830/

Daniel, please clarify here whether this is the best
way to do it.

Thanks",12348,https://review.openstack.org/#/c/61830/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack325204,12299,"Patch Set 1:

Mitaka is not affected, this piece of code was merged in Newton, so we will not need a backport there:

https://review.openstack.org/#/c/250365",12299,https://review.openstack.org/#/c/250365,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack191968,8124,"Abandoned

superseded by:

https://review.openstack.org/#/c/190342/",748,https://review.openstack.org/#/c/190342/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack27648,7170,"Patch Set 2:

This change effectively makes use of VXLAN ports in the upstream Linux kernel. I'm curious if you've looked at the overlap with this review here:

https://review.openstack.org/#/c/26516/

This adds support for the same thing into the Linux Bridge plugin. I think you should contact the author of that patch and see if you can reuse some of what is done there to enable the same functionality (making use of VXLAN ports in the upstream kernel as ports on an OVS bridge) with your patch here.

In addition, OVS 1.10 was just released with VXLAN support natively inside of it. There is a blueprint here I had opened a while back to add this support into the OVS plugin, and I'm getting started on that this week in fact. This will utilize the VXLAN implementation inside of OVS instead of the Linux kernel VXLAN ports.

https://blueprints.launchpad.net/quantum/+spec/ovs-vxlan-lisp-tunnel",105,https://review.openstack.org/#/c/26516/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack28750,6495,"Patch Set 2: I would prefer that you didn't merge this

There's a couple ways we could go with this:

1) Add another cells option that is cell_type=api or cell_type=compute, and choose the right class based on that.

2) If #1 is unacceptable for some reason, we could compromise by using Python entrypoints, which we're migrating over to using elsewhere.  They can include support for ""short name"" aliases.  That way we don't have Python paths/class names in the configuration, but it's still pluggable if you insist and know what you're doing (and accept that it's not necessarily a stable interface).

Here is a similar patch in progress:

https://review.openstack.org/#/c/28267/",1561,https://review.openstack.org/#/c/28267/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack320564,21813,"Abandoned

https://review.openstack.org/#/c/323677/",21813,https://review.openstack.org/#/c/323677/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack63273,9645,"Patch Set 1: I would prefer that you didn't merge this

duplicated with: https://review.openstack.org/#/c/54477/",4468,https://review.openstack.org/#/c/54477/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack84620,1849,"Patch Set 3: I would prefer that you didn't merge this

I did not notice this review when I started on https://review.openstack.org/84608

Your change is better than mine, although I think you are missing some things in test_linux_dhcp.py. Take a look at my proposed changes:  https://review.openstack.org/#/c/84608/3/neutron/tests/unit/test_linux_dhcp.py",6524,https://review.openstack.org/#/c/84608/3/neutron/tests/unit/test_linux_dhcp.py,review.openstack.org,Code,Explaining Necessity,Internal,OpenStack56511,2711,"Patch Set 1: (1 inline comment)

Hi Yuuichi, I have replied your comment, I think there is no need to write the MAX_HEADER_LINE value in the configuration file.
I just did the same update with the following patch:
https://review.openstack.org/#/c/33362/1/nova/wsgi.py
https://review.openstack.org/#/c/39882/1/keystone/common/environment/__init__.py
could you help me to have a look this patch again ? many thanks.",2711,https://review.openstack.org/#/c/33362/1/nova/wsgi.py,review.openstack.org,Code,Explaining Necessity,Internal,OpenStack108174,6951,"Patch Set 20: Code-Review-1

Soon to be abandoned.  New branch review: https://review.openstack.org/#/c/123491/",10980,https://review.openstack.org/#/c/123491/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack233334,6876,"Abandoned

Looks like https://review.openstack.org/#/c/240677 supersedes this.",7448,https://review.openstack.org/#/c/240677,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack106154,167,"Patch Set 1:

this is already covered by other work in progess that the team has agreed to defer until a more opportune time in the cycle [1]

[1] https://review.openstack.org/#/c/99580/",2592,https://review.openstack.org/#/c/99580/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack63511,2472,"Patch Set 1: Abandoned

dupe of https://review.openstack.org/#/c/63495/",2472,https://review.openstack.org/#/c/63495/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack193228,748,"Abandoned

Duplicate of https://review.openstack.org/191826",6524,https://review.openstack.org/191826,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack15095,1653,"Patch Set 1:

Gary:

If the latest version of SQLAlchemy is causing issues... would this be preferable:

https://review.openstack.org/#/c/15097/",360,https://review.openstack.org/#/c/15097/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack130879,10257,"Patch Set 1: Code-Review-1

Sridhar, Xu Hang's review https://review.openstack.org/#/c/123671/ is addressing this issue already.",6685,https://review.openstack.org/#/c/123671/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack331463,1653,"Patch Set 1: Code-Review-1

Hey,
I think you should abandon this change for some reason. The most important one is the following: This change was already finished [1], and merged to the master [2]. And for another reason, this whole sentence is being rewritten in [3].

[1]: https://review.openstack.org/#/c/328131/
[2]: https://github.com/openstack/nova/blob/master/nova/virt/hardware.py#L1260
[3]: https://review.openstack.org/#/c/338261",18602,https://review.openstack.org/#/c/328131/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack195558,5638,"Abandoned

Abandoning in favor of https://review.openstack.org/#/c/198484/",5638,https://review.openstack.org/#/c/198484/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack165821,11904,"Patch Set 1: Code-Review-1

There are already patches under review to handle proper marker functions and to change LOG.warn to LOG.warning, so as discussed you should only address the further cleanups e.g., ""%"" -> "","" to eliminate the duplicate work.
Please refer:
1. https://review.openstack.org/#/c/164692/
2. https://review.openstack.org/#/c/164697/
3. https://review.openstack.org/#/c/164702/

Thanks you!",10485,https://review.openstack.org/#/c/164697/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack555169,26297,"Patch Set 1: Code-Review-1

This patch is duplicate of https://review.openstack.org/#/c/556024/ .
The URLs have already been fixed.",7634,https://review.openstack.org/#/c/556024/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack261441,15054,"Abandoned

Thanks, already have the same patch: https://review.openstack.org/#/c/259963/",15054,https://review.openstack.org/#/c/259963/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack131145,6638,"Patch Set 15:

I just discovered an alternative approach that appears to be a little more direct here:  https://review.openstack.org/#/c/198908/.  It be great to bring them together somehow.",7448,https://review.openstack.org/#/c/198908/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack213692,15967,"Patch Set 3: Code-Review-1

@Vikas, The fix isn't LGTM also.

I think the key problem is: In instance_claim, we set the instance.host to this host. But after instance booting failed, the instance still keep that host, then when that host update its resource, the host still count that instance.

So I think we can set the host to None when the booting failed.

And then...I got some memory there is similar fix:
https://review.openstack.org/#/c/161069/5

Thanks
Alex",5754,https://review.openstack.org/#/c/161069/5,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack123427,2750,"Patch Set 4:

Reviewers, please see an alternate idea from me on this bug: https://review.openstack.org/#/c/123521/

Not necessarily exclusive of Sean's solutions in this patch series...",7,https://review.openstack.org/#/c/123521/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack132563,8866,"Patch Set 4: Code-Review-1

Sorry for -1 but I feel many few people started such initiative to fix spelling or grammatical mistakes. I feel we should create a generic bug which covers entire neutron and start fixing it directory wise starting from agent directory under neutron.

Few patch-set addressing the same:
https://review.openstack.org/#/c/122580/
https://review.openstack.org/#/c/123676/",10370,https://review.openstack.org/#/c/123676/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack124082,5367,"Patch Set 1: Code-Review-1

(1 comment)

This pulled in an unnecessary piece and should probably just be abandoned in favor of: https://review.openstack.org/#/c/121663/",67,https://review.openstack.org/#/c/121663/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack351327,17120,"Abandoned

It is no longer needed Henry suggested better solution in https://review.openstack.org/#/c/348562/",17120,https://review.openstack.org/#/c/348562/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack264797,19213,"Patch Set 3:

@Szymon Borkowski

Hi, this patch is the same with the patch set https://review.openstack.org/#/c/263001/ which is submitted at Jan 3. Thanks!",14274,https://review.openstack.org/#/c/263001/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack253641,6788,"Patch Set 17:

Should abandon this patch for https://review.openstack.org/#/c/351368/ or vice versa",18332,https://review.openstack.org/#/c/351368/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack301268,4523,"Abandoned

https://review.openstack.org/#/c/296344/",4523,https://review.openstack.org/#/c/296344/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack255237,10267,"Patch Set 28: Workflow-1

Change [1]is for same issue. I prefer [1] over this patch. I will abandon this change once [1] get merged.


[1] https://review.openstack.org/#/c/323314/",10267,https://review.openstack.org/#/c/323314/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack204221,16929,"Abandoned

squashed into https://review.openstack.org/#/c/204219",16929,https://review.openstack.org/#/c/204219,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack307124,12171,"Patch Set 1:

same work as my patch:
https://review.openstack.org/#/c/154365/

you implement is different, great. before we move on, we should align which way is prefer.

thanks Moshe Levi.",7543,https://review.openstack.org/#/c/154365/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack571327,17120,"Patch Set 2: Code-Review-1

(1 comment)

There is already patch which tries to fix this issue: https://review.openstack.org/#/c/571301/",11975,https://review.openstack.org/#/c/571301/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack589567,10135,"Patch Set 3:

I threw this up as a possible alternative: https://review.openstack.org/590253",9555,https://review.openstack.org/590253,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack15276,4411,"Patch Set 4: I would prefer that you didn't merge this

I have taken a different approach in https://review.openstack.org/#/c/16574/. It is a more general solution to the problem because it more generally adapts the output from any store.get() to be suitable for store.add().",616,https://review.openstack.org/#/c/16574/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack208181,16053,"Patch Set 2:

I think you can do this work in one patch. 

https://review.openstack.org/#/c/208211/  is needless.",15054,https://review.openstack.org/#/c/208211/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack46283,1390,"Patch Set 6: I would prefer that you didn't merge this

This patch in itself is good but since the policies patch (https://review.openstack.org/#/c/48076/12) got merged already, it is out of sync.",8158,https://review.openstack.org/#/c/48076/12,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack90888,6549,"Patch Set 1: Code-Review+1

(1 comment)

Thanks for making this change. It's irritating to have to modify code locally to get testing to work. I'll abandon https://review.openstack.org/#/c/94114/.",9608,https://review.openstack.org/#/c/94114/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack195228,8124,"Patch Set 2: Code-Review-1

Submitted earlier: https://review.openstack.org/#/c/195218/",5948,https://review.openstack.org/#/c/195218/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack117448,8874,"Patch Set 1: Code-Review-1

There's a more broad solution here: https://review.openstack.org/127918",1561,https://review.openstack.org/127918,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack250040,8124,"Patch Set 2:

Is this needed with https://review.openstack.org/#/c/261227?",8873,https://review.openstack.org/#/c/261227,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack476079,1736,"Abandoned

https://review.openstack.org/#/c/475400/ is merged",1736,https://review.openstack.org/#/c/475400/,review.openstack.org,Patch,Explaining Necessity,Internal,OpenStack15831,5586,"Patch Set 9:

Thanks to Dan smith for giving me many help about what is agent? When I document it, I find much information about agent on wiki. I think it is enough. Maybe I just need explain it as a comment.

what is agent?
  The agent it's talking about is a ""guest agent"" which is a piece of software that runs inside the guest. The host can use this for things like accessing files on the disk, configuring networking, or running other applications/scripts in the guest while it is running. Typically this uses some hypervisor-specific transport to avoid being dependent on a working network configuration. Xen, VMware, and VirtualBox have guest agents, although the Xen driver is the only one with an implementation for managing them in openstack. KVM doesn't really have a concept of a guest agent (although one could be written).

Why need this patch update agent?
You can find the design in this link:http://wiki.openstack.org/AgentUpdate. And you can find the code in nova.virt.xenapi.vmops.VMOps._boot_new_instance.

You can find more information about the design of the GuestAgent in the following link:
http://wiki.openstack.org/GuestAgent
http://wiki.openstack.org/GuestAgentXenStoreCommunication",5586,http://wiki.openstack.org/GuestAgentXenStoreCommunication,wiki.openstack.org,Tutorial or article,Explaining Necessity,Internal,OpenStack261555,12661,"Abandoned

squashed into https://review.openstack.org/261558",12661,https://review.openstack.org/261558,review.openstack.org,Patch,Informing Splitted Patches,Internal,OpenStack476484,21239,"Patch Set 1: Code-Review+1

I don't see much value in this at this point, but the patch is OK.  Please merge it with your other patch https://review.openstack.org/#/c/476482",9535,https://review.openstack.org/#/c/476482,review.openstack.org,Patch,Informing Splitted Patches,Internal,OpenStack105904,10383,"Abandoned

This patch was broken into 3 smaller patch sets:
https://review.openstack.org/#/c/111441 (DB);
https://review.openstack.org/#/c/111455 (API); and
https://review.openstack.org/#/c/111483 (Seed)",10383,https://review.openstack.org/#/c/111455,review.openstack.org,Patch,Informing Splitted Patches,Internal,OpenStack215102,14594,"Patch Set 14:

Please be aware that I took over from Alex and also split this up
into 3 reviews:

* https://review.openstack.org/#/c/275800/
* https://review.openstack.org/#/c/215102/
* https://review.openstack.org/#/c/275801/",11303,https://review.openstack.org/#/c/215102/,review.openstack.org,Patch,Informing Splitted Patches,Internal,OpenStack31133,7677,"Patch Set 4: I would prefer that you didn't merge this

I think this approach is much better, however, you have mixed refactoring of existing code (the replacement of CONF.libvirt_type usage with driver.hypervisor_type), with the addition of new features (support for 'auto').

Per the GIT guidelines, it is is strongly preferred to submit refactoring & new features in separate changesets, as a patch series.

https://wiki.openstack.org/wiki/GitCommitMessages#Structural_split_of_changes

Could you split this change in 2.",1779,https://wiki.openstack.org/wiki/GitCommitMessages#Structural_split_of_changes,wiki.openstack.org,Tutorial or article,Informing Splitted Patches,Internal,OpenStack333590,17714,"Abandoned

https://review.openstack.org/#/c/380810",17714,https://review.openstack.org/#/c/380810,review.openstack.org,Patch,Others,Internal,OpenStack299492,17455,"Abandoned

re-submit https://review.openstack.org/315896",17455,https://review.openstack.org/315896,review.openstack.org,Patch,Others,Internal,OpenStack295480,9064,"Patch Set 2: Code-Review-1

Instead of doing this for individual drivers, can we just put this in the flow manager layer so it applies to all drivers?

http://git.openstack.org/cgit/openstack/cinder/tree/cinder/volume/flows/manager/create_volume.py#n439

In addition, we need to remove the extend call from drivers that are already doing this.",170,http://git.openstack.org/cgit/openstack/cinder/tree/cinder/volume/flows/manager/create_volume.py#n439,git.openstack.org,Code,Proposing Improvement,Internal,OpenStack666654,16688,"Patch Set 1:

I'd like to see this tested and it's a tiny change... just remove the timestamp argument from one of the three calls to test_create_or_update_agent_existing_entry [1] and make sure the test continues to pass.  Especially if this will be used bu stadium projects.

[1] https://opendev.org/openstack/neutron/src/branch/master/neutron/tests/unit/db/test_agents_db.py#L135-L147",13995,https://opendev.org/openstack/neutron/src/branch/master/neutron/tests/unit/db/test_agents_db.py#L135-L147,opendev.org,Code,Proposing Improvement,Internal,OpenStack12311,5319,"Patch Set 1:

actually authors file isn't necessary any more. I am curious as to what you are planning on adding to HostAPI. Also the code for louding the compute api is incorrect, since it happens at import time.  This makes it hard to change the flag for config option, etc. The compute api loading code and the new hostapi loading code (and network api loading code for that matter) should follow the method that the volume api loading code uses here:

https://github.com/openstack/nova/blob/master/nova/volume/__init__.py#L19",67,https://github.com/openstack/nova/blob/master/nova/volume/__init__.py#L19,github.com,Code,Proposing Improvement,Internal,OpenStack251738,18051,"Patch Set 32:

Please also rebase on top of https://review.openstack.org/#/c/275790/ that I sent into gate now since we rename get_by_id into get_object.",9656,https://review.openstack.org/#/c/275790/,review.openstack.org,Patch,Proposing Improvement,Internal,OpenStack245548,11418,"Patch Set 3: Code-Review-1

I forgot about one thing.  Please add a release note describing the new functionality:
http://docs.openstack.org/developer/reno/usage.html#creating-new-release-notes

Looks good to me other than that.",6491,http://docs.openstack.org/developer/reno/usage.html#creating-new-release-notes,docs.openstack.org,Tutorial or article,Proposing Improvement,Internal,OpenStack57224,6536,"Patch Set 1:

Hi Christopher,

Please refer the proposed solutions in comment below:
https://bugs.launchpad.net/nova/+bug/1227575/comments/9

I think it is not be possible to split this change up into two as, it will enforce us to go ahead with solution 1 (to store console sessions in memory) which creates issues as eventlet module is monkeypatched.

Please suggest if there are any possible solution or workaround.",6536,https://bugs.launchpad.net/nova/+bug/1227575/comments/9,bugs.launchpad.net,Bug report,Proposing Improvement,Internal,OpenStack349071,8726,"Patch Set 3: Code-Review-1

(1 comment)

Please remove https://github.com/openstack/neutron/blob/master/neutron/db/migration/models/head.py#L35",7715,https://github.com/openstack/neutron/blob/master/neutron/db/migration/models/head.py#L35,github.com,Code,Proposing Improvement,Internal,OpenStack379333,22484,"Patch Set 2: Code-Review-1

There are some more typos in the same file. Please fix them in the same patch.

https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L7544
https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L7486",22793,https://github.com/openstack/nova/blob/master/nova/virt/libvirt/driver.py#L7544,github.com,Code,Proposing Improvement,Internal,OpenStack604859,9555,"Patch Set 1: Code-Review-1

The NotificationSampleTestBase class has the '_wait_for_notification' method.
It raises an exception when an expected verstioned notification cannot be recieved.

https://github.com/openstack/nova/blob/eb26f1b719395f5e14f75550872e589879b79f92/nova/tests/functional/notification_sample_tests/notification_sample_base.py#L237-L242

So move the '_wait_for_notification' method to a common base class
(InstanceHelperMixin class in nova/tests/functional/integrated_helpers.py)
and call it in the test cases.",7634,https://github.com/openstack/nova/blob/eb26f1b719395f5e14f75550872e589879b79f92/nova/tests/functional/notification_sample_tests/notification_sample_base.py#L237-L242,github.com,Code,Proposing Improvement,Internal,OpenStack224780,7787,"Patch Set 1: Code-Review-1

I'm with change, but please, update test_branches and remove https://github.com/openstack/neutron/blob/master/neutron/tests/functional/db/test_migrations.py#L273-L277.",7249,https://github.com/openstack/neutron/blob/master/neutron/tests/functional/db/test_migrations.py#L273-L277,github.com,Code,Proposing Improvement,Internal,OpenStack444030,9656,"Patch Set 3:

> The default quotas also needs to be updated in the functional tests
 > [1].
 > 
 > [1] https://github.com/openstack/neutron/blob/master/neutron/tests/functional/pecan_wsgi/test_controllers.py#L162-L164

Anindita, please reconsider the vote, the fix for functional job went into the dependency patch.",9656,https://github.com/openstack/neutron/blob/master/neutron/tests/functional/pecan_wsgi/test_controllers.py#L162-L164,github.com,Code,Proposing Improvement,Internal,OpenStack323807,19554,"Patch Set 5: Code-Review-1

I think we should avoid using non-portable things like triggers as almost every DB backend has its' own language for them.

And I think it is possible to achieve the same results in a more portable way. E.g. instead of running those 'select's in triggers you could use 'select-for-update' and/or check-and-set in [1].

[1] https://review.openstack.org/#/c/323807/5/neutron/db/l3_db.py@359",21273,https://review.openstack.org/#/c/323807/5/neutron/db/l3_db.py@359,review.openstack.org,Code,Proposing Improvement,Internal,OpenStack527425,935,"Patch Set 2:

https://github.com/openstack/glance/blob/master/setup.cfg#L30 also need to be removed",13861,https://github.com/openstack/glance/blob/master/setup.cfg#L30,github.com,Code,Proposing Improvement,Internal,OpenStack432432,8726,"Patch Set 2:

We can also use the same approach that refstack uses[1] at least to warranties that the current percentage is no decreased, although this is  simpler.

[1] https://github.com/openstack/refstack/blob/master/tools/cover.sh#L72",8726,https://github.com/openstack/refstack/blob/master/tools/cover.sh#L72,github.com,Code,Proposing Improvement,Internal,OpenStack267931,8556,"Patch Set 1: Code-Review-1

You should update https://github.com/openstack/nova/blob/master/nova/test.py#L141-L157 to avoid the same mistake in the future.",9708,https://github.com/openstack/nova/blob/master/nova/test.py#L141-L157,github.com,Code,Proposing Improvement,Internal,OpenStack274021,18289,"Patch Set 15: Code-Review-1

IMO, the right approach is still to disallow to create a port with network:router-gateway and to force users to set router gateway by updating router external_gateway_info ... which implies to validate the device_owner provided in APIs[1].

It would avoid this ""magic"" tenant_id.

[1] https://github.com/openstack/neutron/blob/4f4a40689dddfddf3e8157200f64a411e2051284/neutron/api/v2/attributes.py#L738-L741",8124,https://github.com/openstack/neutron/blob/4f4a40689dddfddf3e8157200f64a411e2051284/neutron/api/v2/attributes.py#L738-L741,github.com,Code,Proposing Improvement,Internal,OpenStack555945,4690,"Patch Set 3: Code-Review-1

(2 comments)

A couple of nits inline.

Before we do this, there are some other changes we should line up in 3 different repos:

1. tempest runs legacy-tempest-dsvm-multinode-live-migration in it's experimental queue, so you should add the new job to tempest's .zuul.yaml and make that patch depend on this one.

2. update https://github.com/openstack-infra/project-config/blob/master/zuul.d/projects.yaml and remove references to legacy-tempest-dsvm-multinode-live-migration and make the project-config patch depend on the nova and tempest patch.

3. Finally, remove the legacy-tempest-dsvm-multinode-live-migration job definition from openstack-zuul-jobs, and that patch will depend on the project-config patch.

Otherwise if we don't have those lined up, we'll be running both the old and new job in nova until it's all done, which is (1) a waste of resources and (2) increases our chances of random failures.

We'll also need to backport this job definition to stable branches when the project-config change merges, otherwise we'll lose the live migration job test coverage in stable.",6873,https://github.com/openstack-infra/project-config/blob/master/zuul.d/projects.yaml,github.com,Code,Proposing Improvement,Internal,OpenStack621827,9414,"Patch Set 1: Code-Review-1

Sorry. The following comment should be fixed.

https://github.com/openstack/nova/blob/3ce9aa01924bb2d8da077342eb61a437cbd728ee/nova/db/sqlalchemy/migrate_repo/versions/272_add_keypair_type.py#L23",7634,https://github.com/openstack/nova/blob/3ce9aa01924bb2d8da077342eb61a437cbd728ee/nova/db/sqlalchemy/migrate_repo/versions/272_add_keypair_type.py#L23,github.com,Code,Proposing Improvement,Internal,OpenStack86038,9172,"Patch Set 8:

@Zhu There is another way to implement the console log feature with additional network service (virtual serial port concentrator), please see: https://blueprints.launchpad.net/nova/+spec/vmware-console-log

Each method has pros and cons, so any feedback is welcome.",9172,https://blueprints.launchpad.net/nova/+spec/vmware-console-log,blueprints.launchpad.net,Memo,Proposing Improvement,Internal,OpenStack37131,7448,"Patch Set 1:

Overall, I prefer you approach from mine (https://review.openstack.org/#/c/37131/) and Li's (https://review.openstack.org/#/c/36487/). However, It would be great if neutron.wsgi.Service could use an instance of neutron.openstack.common.service.ProcessLauncher as self._server. Although you'd add the complexity of creating a simple proxy server object to pass to ProcessLauncher, you'd be able to remove all of the fickle signalling and forking logic. Moreover, you'd benefit from the subtle details covered in ProcessLauncher, like reseeding the random number generator. My 2 cents :-)",7500,https://review.openstack.org/#/c/37131/,review.openstack.org,Patch,Proposing Improvement,Internal,OpenStack469189,9656,"Patch Set 1:

Solution for dstat: https://review.openstack.org/#/c/470032",9656,https://review.openstack.org/#/c/470032,review.openstack.org,Patch,Proposing Improvement,Internal,OpenStack203035,11433,"Patch Set 2: Code-Review-2

Given:

https://review.openstack.org/#/c/175569/

Get this change into os-brick:

https://review.openstack.org/#/c/203026/

Then get a release of os-brick with your fix and then raise the minimum required version of os-brick in https://github.com/openstack/requirements/blob/master/global-requirements.txt which will then sync that to nova and we'll pull in the fix via os-brick.",6873,https://review.openstack.org/#/c/175569/,review.openstack.org,Patch,Proposing Improvement,Internal,OpenStack266687,19226,"Patch Set 10: Code-Review-1

(1 comment)

If it is a new feature including microversion then I think this needs at least a blueprint but maybe a spec as well. See https://wiki.openstack.org/wiki/Blueprints and https://github.com/openstack/nova-specs.",9708,https://github.com/openstack/nova-specs,github.com,Software homepage,Proposing Improvement,Internal,OpenStack571301,13995,"Patch Set 2: Code-Review-1

i think you should add oslotest as the requirement in this file https://github.com/openstack/neutron/blob/master/doc/requirements.txt because after the new PTI, doc requirements are moved here; rather than modifying tox.ini.",25587,https://github.com/openstack/neutron/blob/master/doc/requirements.txt,github.com,Specification,Proposing Improvement,Internal,OpenStack2572,1297,"Patch Set 6:

One other thing ... the commit message needs to be updated a bit.  I would start by just removing the first 2 lines completely and go back to having ""Re-adds ssl to kombu ..."" as the first line.  Try to follow the guidance here: http://wiki.openstack.org/GerritWorkflow",1561,http://wiki.openstack.org/GerritWorkflow,wiki.openstack.org,Tutorial or article,Proposing Improvement,Internal,OpenStack7301,1669,"Patch Set 1: I would prefer that you didn't merge this

Hi Julien,

If the goal is to share this logic with nova, the correct approach IMO would be to:

1. Promote this code to openstack-common: http://wiki.openstack.org/CommonLibrary

2. Pending an openstack-common release, copy the shared code into both nova and glance via the update.py script

Cheers,
Eoghan",2284,http://wiki.openstack.org/CommonLibrary,wiki.openstack.org,Tutorial or article,Proposing Improvement,Internal,OpenStack39904,2711,"Patch Set 6:

Jenkins error is not caused by my change, I have opened a bug to track it.
https://bugs.launchpad.net/neutron/+bug/1207953",2711,https://bugs.launchpad.net/neutron/+bug/1207953,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack87730,9361,"Patch Set 42: Code-Review-1

please refrain from merging further dvr changes until existing regressions are settled.
https://bugs.launchpad.net/neutron/+bug/1343750",6854,https://bugs.launchpad.net/neutron/+bug/1343750,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack331348,20246,"Patch Set 1:

cfg.register_opts(opts) works .
this patch provides a centralized place for config options and their registrations. 
It is for https://bugs.launchpad.net/neutron/+bug/1563069
Please refer Line 292 to 334 https://review.openstack.org/#/c/295543/9/specs/categorized-configuration-options.rst",20246,https://bugs.launchpad.net/neutron/+bug/1563069,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack71456,7163,"Patch Set 3:

I've created a bug for this here: https://bugs.launchpad.net/nova/+bug/1286992",7163,https://bugs.launchpad.net/nova/+bug/1286992,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack142843,8873,"Patch Set 1:

I tried playing around with sysctl, disabling allow_ra and autoconf, and those flags don't appear to do anything on Fedora 20 with my kernel. I tried setting them on individual interfaces, in 'all' and in 'default', and one of them removed the IPv6 LLADDR from existing interfaces or prevented the configuration of it for new interfaces.

At this point I'm forced to manage the LLADDR in keepalived notification scripts, but in order to do that I first have to solve:
https://bugs.launchpad.net/neutron/+bug/1402010",8873,https://bugs.launchpad.net/neutron/+bug/1402010,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack281143,5754,"Patch Set 16: Workflow-1

Mark as WIP for take a look at why this test passed https://github.com/openstack/nova/blob/10da208f02fee532171d1d9e4667d0b71c455b8a/nova/tests/functional/regressions/test_bug_1541691.py",5754,https://github.com/openstack/nova/blob/10da208f02fee532171d1d9e4667d0b71c455b8a/nova/tests/functional/regressions/test_bug_1541691.py,github.com,Code,Providing Context,Internal,OpenStack309362,20184,"Patch Set 4:

https://github.com/openstack/nova/blob/5b31a0dac89aab262f2a660195a1fd284c802e62/nova/tests/functional/api_sample_tests/test_servers.py#L54",782,https://github.com/openstack/nova/blob/5b31a0dac89aab262f2a660195a1fd284c802e62/nova/tests/functional/api_sample_tests/test_servers.py#L54,github.com,Code,Providing Context,Internal,OpenStack62310,6167,"Patch Set 16:

@Chris Behrens

I have a question about Cells API validation.
Current cells API does not allow cell name contain '.' with https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/plugins/v3/cells.py#L195
Current validation code has been implemented since the first implementation of cell API.

Are there any special reasons of it?
Now I am trying to apply common name validation pattern to v3 cell API with https://github.com/openstack/nova/blob/master/nova/api/validation/parameter_types.py#L52

The common name pattern is shared between nova APIs and it will make nova APIs more consistent, but the common name pattern allows '.'. so I'd like to know the reason
to distinguish whether we can change the validation or cannot.",6167,https://github.com/openstack/nova/blob/master/nova/api/validation/parameter_types.py#L52,github.com,Code,Providing Context,Internal,OpenStack519573,25943,"Patch Set 11:

@Slawek Kaplonski 
It is my testing result
 http://paste.openstack.org/show/628703/",25943,http://paste.openstack.org/show/628703/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack607008,27654,"Patch Set 3: Workflow-1

> pep8 failures here http://logs.openstack.org/08/607008/3/check/openstack-tox-pep8/6c9a3e1/job-output.txt.gz#_2018-11-02_23_42_37_935877.
 > All look to be either line length or import ordering, should be
 > easy fixes. It's good to see success on all the other voting jobs
 > though.

Right, I will fix them. Just want to wait for this patch to merge: https://review.openstack.org/#/c/615655/ and try to make another release.",27654,https://review.openstack.org/#/c/615655/,review.openstack.org,Patch,Providing Context,Internal,OpenStack3650,2140,"Patch Set 2: I would prefer that you didn't submit this

So i ran into this issue as well.  Now I see that the filter runs on all commands, not just ones that start with kill.  I made a bug/test/fix here:

https://review.openstack.org/3778",67,https://review.openstack.org/3778,review.openstack.org,Patch,Providing Context,Internal,OpenStack96438,7249,"Patch Set 8: Code-Review-1

When I try this healing in devstack I get the following error:

http://paste.openstack.org/show/84315/",6524,http://paste.openstack.org/show/84315/,paste.openstack.org,Patch,Providing Context,Internal,OpenStack535786,10343,"Patch Set 4: Code-Review+1

(1 comment)

I'm basically good with this, although am wondering why one of the fields changed... at least it does not stand out to me at a glance.

Anyway, We've tested this in Ironic's CI jobs, and it enables ironic's multinode grenade to work again. https://review.openstack.org/#/c/535596/ is dependent upon this patch in Ironic, which restores ironic's multinode grenade job to voting status.

For the record, we are working on adding better microversion negotiation to python-ironicclient and those changes are on track to be in the library for this cycle.",11655,https://review.openstack.org/#/c/535596/,review.openstack.org,Patch,Providing Context,Internal,OpenStack356389,6579,"Patch Set 1:

> I don't want to put these in pieces like this. I would rather wait
 > until all are moved to the core plugin layer and out of the API.
 > Either merge the fix in lbaas or wait for the larger refactor.

Hey Kevin,
Thanks for taking the time to look into this, much appreciated.

I initially submitted a patch to the neutron-lbaas code base: https://review.openstack.org/#/c/351490

During our IRC conversation, (via jschwarz) a suggestion came up to have this decorator on the neutron code base. IMO it looks like this is indeed a better fit.

Since we are blocked with new features[1][2] to the haproxy lbaas driver and since we are getting close to the code freeze, can you please tell me when is the 'API to core plugin' move planned for? perhaps I can help with this?

[1] https://review.openstack.org/#/c/299998/
[2] https://review.openstack.org/#/c/344658/",6579,https://review.openstack.org/#/c/299998/,review.openstack.org,Patch,Providing Context,Internal,OpenStack150718,14131,"Patch Set 3:

this patch depends on 

https://review.openstack.org/#/c/150280/

after 150280 is merged. will update V2.1 test case.",14131,https://review.openstack.org/#/c/150280/,review.openstack.org,Patch,Providing Context,Internal,OpenStack204493,8846,"Patch Set 2: Code-Review-1

I suddenly found out that we are working on this kind of issues. I guess we need to discuss the scope of your patch.

I have the spec merged: https://review.openstack.org/#/c/148181/, which is about the pagination for all the entities in Cinder.

Are you going to implement the pagination for backup and snapshot only? Or are you going to implement it for all the cinder entities, including consistency groups, volume transfers, etc?? If you would like to take care of the pagination for all the cinder entities. It will be fantastic that we can add them into this patch as well.",2861,https://review.openstack.org/#/c/148181/,review.openstack.org,Patch,Providing Context,Internal,OpenStack606106,6873,"Patch Set 5: Code-Review+2

Yup, das geht, having seen the fup [1].

[1] https://review.openstack.org/#/c/608705/",14070,https://review.openstack.org/#/c/608705/,review.openstack.org,Patch,Providing Context,Internal,OpenStack71354,10091,"Patch Set 1:

The glance part is needed for the client.

python-glanceclient part: https://review.openstack.org/#/c/68619/

glance part: https://review.openstack.org/71354",10091,https://review.openstack.org/#/c/68619/,review.openstack.org,Patch,Providing Context,Internal,OpenStack325863,9535,"Patch Set 1:

I have created 2 more patches, one that adds the docstrings to the filters [1] as Xing requested and another that adds the explanation of the generic errors to the devref document [2].

[1]: https://review.openstack.org/326323
[2]: https://review.openstack.org/326324",9535,https://review.openstack.org/326324,review.openstack.org,Patch,Providing Context,Internal,OpenStack152512,8788,"Patch Set 11:

Tempest started failing from PS8 to PS9, but I can't spot anything which could change the way code works:

https://review.openstack.org/#/c/152512/8..9/neutron/agent/linux/iptables_firewall.py

I have rebased for just in case, and waiting for tests.",8788,https://review.openstack.org/#/c/152512/8..9/neutron/agent/linux/iptables_firewall.py,review.openstack.org,Patch,Providing Context,Internal,OpenStack282068,8912,"Patch Set 7:

Have some Tempest tests working for this at https://review.openstack.org/#/c/285640/1.  They're not yet ready to merge in Tempest, but they can be pulled locally to test out this feature / see how this is expected to work.",8912,https://review.openstack.org/#/c/285640/1,review.openstack.org,Patch,Providing Context,Internal,OpenStack478462,25571,"Patch Set 1: Code-Review-1

The code is ok.

This patch is related to bug #1697588, you should add this to the description.

Also you can add, like in https://review.openstack.org/#/c/473689/, the reference to the tempest change: I5f7164f7a7ec5d4380ca22885000caa0183a0bf7",16688,https://review.openstack.org/#/c/473689/,review.openstack.org,Patch,Providing Context,Internal,OpenStack366944,5314,"Patch Set 1:

Will need to keep an eye on https://review.openstack.org/#/c/350809/ (bumping to 2.4 with Newton)",5314,https://review.openstack.org/#/c/350809/,review.openstack.org,Patch,Providing Context,Internal,OpenStack69739,1561,"Patch Set 4:

In my local tree this depends on https://review.openstack.org/#/c/69738/ ... not sure why that's not reflected here :-/",1561,https://review.openstack.org/#/c/69738/,review.openstack.org,Patch,Providing Context,Internal,OpenStack267921,16907,"Patch Set 1:

@Ken'ichi:

Thanks for the review!

My apologies for not making the intent of this patch series clearer. I did initially have it in one much larger patch, but it was too big to review. Even after splitting it up (see below), the patches are still quite large.

There are currently ~1800 calls to stubs.Set remaining. Using a combo of grep/cut/uniq/sort, I tackled the most common cases first. Here's how I split up the patches:

The ~400 calls that look like the following can be found in this patch:

  - self.stubs.Set(db, ...)
  - Replace stubs.Set with stub_out (db)
  - https://review.openstack.org/#/c/267897/

The 300+ calls that look like the following can be found in this patch:

  - self.stubs.Set(compute.api.API, ...)
  - Replace stubs.Set with stub_out (compute api)
  - https://review.openstack.org/#/c/268591/

The ~50 calls that look like the following can be found in this patch:

  - self.stubs.Set(os, ...)
  - Replace stubs.Set with stub_out (os)
  - https://review.openstack.org/#/c/267921/

The 100+ calls that look like the following can be found in this patch:

  - self.stubs.Set(*utils, ...)
  - Replace stubs.Set with stub_out (utils)
  - https://review.openstack.org/#/c/267950/

Finally, the 100+ calls that look like the following can be found in this patch:

  - self.stubs.Set(*.api, ...)  # exclude compute api
  - Replace stubs.Set with stub_out (api)
  - https://review.openstack.org/#/c/268300/

I had planned on working my way through the remaining calls to stubs.Set (and the mox dependency in general) after these patches got merged, but I started to question the churn/value/feasibility of this work given that there are 900+ tests that are still using the mox.ReplayAll style of testing. 

Anyhoo, I hope that helps clear up any confusion around this patch series.

Thanks again,

--diana",16907,https://review.openstack.org/#/c/267897/,review.openstack.org,Patch,Providing Context,Internal,OpenStack147602,8655,"Patch Set 1:

Oleg is right. There was a confusion caused by me. Now it's solved and correct blueprint is https://blueprints.launchpad.net/neutron/+spec/new-iptables-driver",8655,https://blueprints.launchpad.net/neutron/+spec/new-iptables-driver,blueprints.launchpad.net,Specification,Providing Context,Internal,OpenStack424466,9531,"Patch Set 20:

I added the following blueprint https://blueprints.launchpad.net/neutron/+spec/floating-ip-rate-limit to track this work. Please keep the topic of this patchset as bp/floating-ip-rate-limt, as I set it a few minutes ago, so we can track the progress of this work through the blueprint.",4694,https://blueprints.launchpad.net/neutron/+spec/floating-ip-rate-limit,blueprints.launchpad.net,Specification,Providing Context,Internal,OpenStack134530,10257,"Patch Set 2:

@Sridhar, I still can reproduce issue in bug https://bugs.launchpad.net/neutron/+bug/1377985 and it doesn't work if special security group rules are not added. We still need the solution.
Just tried it a few minutes ago (and would be strange if it's not reproducible, because nothing was changed :) )",10969,https://bugs.launchpad.net/neutron/+bug/1377985,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack344581,6951,"Patch Set 8:

i think the failure is related to https://bugs.launchpad.net/neutron/+bug/1612281

I'm going to hold off on rechecks until that gets resolved",6951,https://bugs.launchpad.net/neutron/+bug/1612281,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack520248,6873,"Patch Set 1:

I tried testing locally with my nova.test.patch from the bug report, but it is failing due to https://bugs.launchpad.net/nova/+bug/1733933",13252,https://bugs.launchpad.net/nova/+bug/1733933,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack118604,11530,"Patch Set 13:

Spotted 2 more bugs for the same flag

https://bugs.launchpad.net/nova/+bug/1323578
https://bugs.launchpad.net/nova/+bug/1328367",5638,https://bugs.launchpad.net/nova/+bug/1323578,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack425586,19046,"Patch Set 1:

It looks like the Sheepdog CI failed due to Bug #1660511 (now ""Fix Released"") [1][2]. Captured traceback[3] is similar to [2]'s one.

[1] http://status.openstack.org/elastic-recheck/#1660511
[2] https://bugs.launchpad.net/devstack/+bug/1660511
[3] http://logs.openstack.org/86/425586/1/check/gate-tempest-dsvm-full-sheepdog-ubuntu-xenial-nv/6ecee3b/console.html#_2017-02-01_03_05_46_059578

2017-02-01 03:05:46.059578 | ==============================
2017-02-01 03:05:46.059597 | Failed 1 tests - output below:
2017-02-01 03:05:46.059610 | ==============================
2017-02-01 03:05:46.059615 | 
2017-02-01 03:05:46.059645 | tempest.api.compute.admin.test_volume_swap.TestVolumeSwap.test_volume_swap[id-1769f00d-a693-4d67-a631-6a3496773813,volume]
2017-02-01 03:05:46.059684 | --------------------------------------------------------------------------------------------------------------------------
2017-02-01 03:05:46.059690 | 
2017-02-01 03:05:46.059700 | Captured traceback:
2017-02-01 03:05:46.059712 | ~~~~~~~~~~~~~~~~~~~
2017-02-01 03:05:46.059729 |     Traceback (most recent call last):
2017-02-01 03:05:46.059751 |       File ""tempest/test.py"", line 99, in wrapper
2017-02-01 03:05:46.059807 |         return f(self, *func_args, **func_kwargs)
2017-02-01 03:05:46.059836 |       File ""tempest/api/compute/admin/test_volume_swap.py"", line 64, in test_volume_swap
2017-02-01 03:05:46.059861 |         volume1['id'], 'available')
2017-02-01 03:05:46.059889 |       File ""tempest/common/waiters.py"", line 189, in wait_for_volume_status
2017-02-01 03:05:46.059906 |         raise lib_exc.TimeoutException(message)
2017-02-01 03:05:46.059925 |     tempest.lib.exceptions.TimeoutException: Request timed out
2017-02-01 03:05:46.059962 |     Details: Volume 1f0c964e-51a0-46df-99f1-a5c72893c9f5 failed to reach available status (current in-use) within the required time (600 s).",19046,https://bugs.launchpad.net/devstack/+bug/1660511,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack90379,9174,"Patch Set 3:

The certification test result has already been uploaded. https://bugs.launchpad.net/cinder/+bug/1336661/+attachment/4143657/+files/Hitachi%20block%20storage%20driver%20certification%20test%20result.txt",9174,https://bugs.launchpad.net/cinder/+bug/1336661/+attachment/4143657/+files/Hitachi%20block%20storage%20driver%20certification%20test%20result.txt,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack186930,7125,"Patch Set 3: Code-Review-1

(1 comment)

Here, you may  want to consider the fix for the bug proposed at https://bugs.launchpad.net/nova/+bug/1428424",8645,https://bugs.launchpad.net/nova/+bug/1428424,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack141883,11604,"Patch Set 10:

the check-grenade-dsvm-partial-ncpu and  check-grenade-dsvm failures are are caused by

CRITICAL ceilometer [-] ImportError: No module named middleware

which is tracked by this bug 
https://bugs.launchpad.net/grenade/+bug/1463478

and addressed by the following patchset currently waiting in the gate.
https://review.openstack.org/#/c/189829 

i will recheck tomorrow once the fix merges.",11604,https://bugs.launchpad.net/grenade/+bug/1463478,bugs.launchpad.net,Bug report,Providing Context,Internal,OpenStack39240,6950,"Patch Set 4:

John:  Hm.

https://github.com/rackerlabs/openstack-guest-agents-unix/blob/master/commands/network.py#L146

We won't fail on reading it.  But we'll pass the default down into the distro-specific code..",1030,https://github.com/rackerlabs/openstack-guest-agents-unix/blob/master/commands/network.py#L146,github.com,Code,Providing Context,Internal,OpenStack393150,24021,"Patch Set 17: Code-Review-1

@Zainub,

We have another merge conflict. This is because this patchset merged this afternoon: https://review.openstack.org/#/c/375536. As you can see, it adds this line: https://review.openstack.org/#/c/375536/5/neutron/tests/unit/objects/test_base.py@400, which interferes with your close by removal of:

obj_fields.UUIDField: uuidutils.generate_uuid,

and your addition of:

common_types.UUIDField: uuidutils.generate_uuid,

Here's what you need to do in your local system:

1) git checkout master

2) git pull --ff-only origin master (this will get you the latest version of master in the Neutron repo)

3) git review -d 393150. This will download your latest patchset from gerrit. You are going to see the following in your screen: http://paste.openstack.org/show/590733/. This will leave you in the branch you just downloaded from gerrit

4) git rebase master. Since you have merge conflicts, you are going to see this: http://paste.openstack.org/show/590732/. As you can see, you get a merge conflict in file neutron/tests/unit/objects/test_base.py

5) These are the merge conflicts: http://paste.openstack.org/show/590731/. To solve them, in this case you need to remove line 403. Also remove lines 401, 404 and 406 that were added by git during the rebase.

6) git add neutron/tests/unit/objects/test_base.py

7) git rebase --continue

8) Make all the changes that Victor indicated in the previous review

9) git commit -a --amend

10) git review

We might get a few more failures in the check jobs. But let's fix first what we have right now

Good luck",4694,https://review.openstack.org/#/c/375536/5/neutron/tests/unit/objects/test_base.py@400,review.openstack.org,Code,Providing Context,Internal,OpenStack660827,5367,"Patch Set 1:

Looking at http://codesearch.openstack.org/?q=from%20neutron.services.logapi.common%20import%20constants&i=nope&files=&repos= it looks that it's good to go after neutron-fwaas patch will be merged (and it's in ""depends-on"" already so it's good :))",11975,http://codesearch.openstack.org/?q=from%20neutron.services.logapi.common%20import%20constants&i=nope&files=&repos=,codesearch.openstack.org,Code,Providing Context,Internal,OpenStack254358,11561,"Patch Set 6:

Just been looking at how this gets used.

The encryptor stores the key manager:
https://github.com/openstack/nova/blob/505d88377a0db4dd8ad074f2145f3ae179e184bc/nova/volume/encryptors/base.py#L34

But a new one of these is created for every operation, it seems:
https://github.com/openstack/nova/blob/9b78d904e5c338308ca36ed1166e97cc6d37710f/nova/virt/libvirt/driver.py#L1075

As such, I don't think we need any caching, its pointless.

Also, as such, I am not sure this bug can affects Nova.

Is there somewhere else this gets used that I am missing, that creates this problem?",782,https://github.com/openstack/nova/blob/505d88377a0db4dd8ad074f2145f3ae179e184bc/nova/volume/encryptors/base.py#L34,github.com,Code,Providing Context,Internal,OpenStack168916,12814,"Patch Set 16:

Summarizing we have two RPC calls where MessagingTimeout could possibly occur while launching live-migration.
First call is here: 
https://github.com/openstack/nova/blob/master/nova/conductor/api.py#L209

and second call is here:
https://github.com/openstack/nova/blob/master/nova/conductor/tasks/live_migrate.py#L66

I believe that in this case we should only handle first MessagingTimeout (in nova-api layer) because second call is rpc:cast so it can't generate timeout.

I agree that we should revert vm_state to ACTIVE, task_state to None and also log this information.",12814,https://github.com/openstack/nova/blob/master/nova/conductor/api.py#L209,github.com,Code,Providing Context,Internal,OpenStack79072,1849,"Patch Set 1:

Hmm, nova objects do implement __getitem__:

https://github.com/openstack/nova/blob/master/nova/objects/base.py#L380",6873,https://github.com/openstack/nova/blob/master/nova/objects/base.py#L380,github.com,Code,Providing Context,Internal,OpenStack189367,16121,"Patch Set 9:

rebased due to below recent addition in cinder.exception.py file:

https://github.com/openstack/cinder/commits/master/cinder/exception.py",16121,https://github.com/openstack/cinder/commits/master/cinder/exception.py,github.com,Code,Providing Context,Internal,OpenStack580017,8556,"Patch Set 6:

> Reiterating what I said in IRC:
 > 
 > (8:20:40 AM) mriedem: gmann: alex_xu: i see several of these
 > already merged https://review.openstack.org/#/q/topic:bp/api-extensions-merge-rocky+(status:open+OR+status:merged)
 > but 2 things:
 > (8:20:57 AM) mriedem: 1. rather than cram it all into that single
 > create() method, it would be nice to instead continue the pattern
 > we have in here https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/helpers.py#L55
 > (8:21:17 AM) mriedem: 2. this series isn't moving the view builder
 > code from the extensions into the actual server ViewBuilder, which
 > is something we should do
 > (8:21:53 AM) mriedem: maybe the goal for rocky is to just remove
 > the server_create extension method and then in stein we
 > refactor/cleanup the create() controller method to move things into
 > https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/helpers.py#L55
 > and also move stuff into the view builder?
 > (8:22:23 AM) mriedem: personally it's the view builder that bothers
 > me the most, because i have to hunt all over the extensions to find
 > what puts something into the server response body
 > (8:22:55 AM) mriedem: and the view builder part is going to become
 > very important for tssurya's change for handling a down cell
 > 
 > --
 > 
 > So if we want to just merge the rest of this series as-is and then
 > cleanup the create() controller method in Stein *and* cleanup the
 > view builder code, I can probably agree to that so we're at least
 > making incremental progress. I'd like to know if that's the plan
 > though.

>1st point
We can do that way also, but i am seeing that require to read another method about server create request arg alternation than just original create in server controller itself. But Yeah we can discuss and do in Stein. I will follow up on this in stein. 

>2nd
Yeah, that will be done as part-3 of this work. I am dividing this work into 3 part:
- part-1 - do schema merger. COMPLETED. 
- part-2 - server create merge - Patch all in gate and its +A now.
- part-3 - merging the view builder  - ongoing and i will completing the series by Monday. and yeah let's see if we can merged those in Rocky(i wish to). 

to avoid any regression as it is request, schema & response things, i divided that way than doing in single patch.",8556,https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/helpers.py#L55,github.com,Code,Providing Context,Internal,OpenStack383673,14615,"Patch Set 53:

> I must be blind, but does anyone see where the new tempest test has
 > been executed?
 > 
 > http://logs.openstack.org/73/383673/53/check/gate-tempest-dsvm-neutron-full-ubuntu-xenial/1f48557/console.html#_2017-07-03_22_48_24_016320

This is 

 > I must be blind, but does anyone see where the new tempest test has
 > been executed?
 > 
 > http://logs.openstack.org/73/383673/53/check/gate-tempest-dsvm-neutron-full-ubuntu-xenial/1f48557/console.html#_2017-07-03_22_48_24_016320

https://github.com/openstack/tempest/blob/master/tempest/api/network/admin/test_quotas.py is the tempest test being executed there. I had a patch up in tempest to implement  quota details test but was abandoned. please check https://review.openstack.org/#/c/429950/14",23821,https://github.com/openstack/tempest/blob/master/tempest/api/network/admin/test_quotas.py,github.com,Code,Providing Context,Internal,OpenStack269056,15518,"Patch Set 1:

This patch is packing the OVO sent via RPC and makes them 'versioned' to the receiver party, the sample output with Network OVO:
http://paste.openstack.org/show/484149/",15518,http://paste.openstack.org/show/484149/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack382565,21111,"Patch Set 5:

I checked the gerrit py27 results and found two errors:

1. This was already detected in my local unit test run of nova.tests.unit.compute.test_shelve - actually the error fails on nova.tests.unit.compute.test_shelve.ShelveComputeManagerTestCase.test_unshelve_volume_backed - yet I didn't make any code changes to this function:  see http://paste.openstack.org/show/585243/ for the log.

2. Here is the other error detected by the py27 test in gerrit (although no code was changed for this commit): see http://paste.openstack.org/show/585490/ for the log.

Note: There is also a pep8 error that I forgot to test locally (and also been detected by Zhenyu Zheng).  Am targeting to deliver this fix along with the unit test error in the next patch.",21111,http://paste.openstack.org/show/585490/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack319660,4355,"Patch Set 11:

@sean, ran my test script on the latest version:
http://paste.openstack.org/show/539067/",4355,http://paste.openstack.org/show/539067/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack16033,4393,"Patch Set 1:

So I dug into the current behavior, and it also isn't passing instance_type_extra_specs down to drivers. Here's a sample of what the driver sees, as output from virt/baremetal/driver.spawn
http://paste.openstack.org/show/25841/

For baremetal, IMHO, we really do need to get extra specs in the driver, and it should be preserved along with all the ""normal"" flavor info. This is related to review 11088.

I'm not sure if this patch is the right place to add that... if not, I could use a few pointers in getting that added.",2889,http://paste.openstack.org/show/25841/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack34074,7752,"Patch Set 28:

Nachi>> hmm Still I got error http://paste.openstack.org/show/40580/

Your INI file is in old format. The current INI file looks like

root@ubuntu:/opt/stack/neutron# cat /etc/neutron/fwaas_driver.ini
[fwaas]
driver = neutron.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver

Please update and try again. Thanks.",7752,http://paste.openstack.org/show/40580/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack244177,11303,"Patch Set 3:

pci-test: 
pci test failed due to hit this bug:
  AttributeError: '_TransactionFactory' object has no attribute '_writer_maker'
  https://bugs.launchpad.net/oslo.db/+bug/1515326
for more information please see:
    https://etherpad.openstack.org/p/third-party-ci-status-tracking-intel-hardware",7543,https://etherpad.openstack.org/p/third-party-ci-status-tracking-intel-hardware,etherpad.openstack.org,Memo,Providing Context,Internal,OpenStack640,1030,"Patch Set 5: I would prefer that you didn't submit this

Getting a test failure ...
http://paste.openstack.org/show/2565/",688,http://paste.openstack.org/show/2565/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack434870,18339,"Patch Set 5: Code-Review+1

Tested it on multinode environment with 4,8,16 gig VM’s .
Noticed the network outage reduced to 0-1%. Test results can be found here http://paste.openstack.org/show/601673/.",18339,http://paste.openstack.org/show/601673/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack74786,1849,"Patch Set 1:

boris, thank you for the feedback.

I created this patch to see how many things break when doing a full oslo sync. I picked cinder because I am too close to nova.

As the title says this is not meant to be merged.

I created a etherpad to track my findings.


https://etherpad.openstack.org/p/cinder-oslo-incubator-sync-proof-of-concept",1849,https://etherpad.openstack.org/p/cinder-oslo-incubator-sync-proof-of-concept,etherpad.openstack.org,Memo,Providing Context,Internal,OpenStack201500,10674,"Patch Set 20: Code-Review-2

Sean, their CI is not actively running in the past five days. Plus the ratio of success could use some work. http://paste.openstack.org/show/480447/",170,http://paste.openstack.org/show/480447/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack431714,16907,"Patch Set 1:

Here are some before and after notes that should make this easier to review. 

 - http://paste.openstack.org/show/598292/",16907,http://paste.openstack.org/show/598292/,paste.openstack.org,Memo,Providing Context,Internal,OpenStack160799,6695,"Patch Set 10:

Logstash shows 13 hits today with ""Subnet pool has existing allocations"" error: http://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOiBcIlVuYWJsZSB0byBkZWxldGUgc3VibmV0IHBvb2w6IFN1Ym5ldCBwb29sIGhhcyBleGlzdGluZyBhbGxvY2F0aW9uc1wiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxNDM0MDYxMDk5MjEwfQ==",6695,http://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOiBcIlVuYWJsZSB0byBkZWxldGUgc3VibmV0IHBvb2w6IFN1Ym5ldCBwb29sIGhhcyBleGlzdGluZyBhbGxvY2F0aW9uc1wiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxNDM0MDYxMDk5MjEwfQ==,logstash.openstack.org,Others,Providing Context,Internal,OpenStack362917,19797,"Patch Set 1:

does this go away?

https://review.openstack.org/#/c/336567/",748,https://review.openstack.org/#/c/336567/,review.openstack.org,Patch,Providing Context,Internal,OpenStack93520,6873,"Patch Set 3:

Think I might re-sync this so I can pick this periodic_task commit up:

https://review.openstack.org/#/c/93767/",6873,https://review.openstack.org/#/c/93767/,review.openstack.org,Patch,Providing Context,Internal,OpenStack303085,7787,"Patch Set 2:

I have validated in dependent patch [1], that exceeding RetryRequest error is no longer observed in logs with pluggable ipam enabled&migrated.

There are few more issues that prevent [1] from getting clean pass. But they are planned to be fixed in separate patches ([2] and probably more).

So I think this patch is good to go.

[1] https://review.openstack.org/#/c/181023
[2] https://review.openstack.org/#/c/306519",13768,https://review.openstack.org/#/c/181023,review.openstack.org,Patch,Providing Context,Internal,OpenStack320808,4727,"Patch Set 15:

In order to run the experimental, have a look at https://review.openstack.org/#/c/324263/.
In short, lets add a dummy change to some other file not in the tests path and then run 'check experimental'.",12444,https://review.openstack.org/#/c/324263/,review.openstack.org,Patch,Providing Context,Internal,OpenStack476159,15334,"Patch Set 8: Code-Review+1

Formatting works with https://review.openstack.org/#/c/476204/ on top.",14070,https://review.openstack.org/#/c/476204/,review.openstack.org,Patch,Providing Context,Internal,OpenStack52528,3,"Patch Set 6: Do not merge

We will use https://review.openstack.org/#/c/52894/ to cover this sync request, since merge this simply will not workable for master, we need change two test case also which doesn't compatible with iso8601>=0.1.7.",6549,https://review.openstack.org/#/c/52894/,review.openstack.org,Patch,Providing Context,Internal,OpenStack109476,5638,"Patch Set 3: Code-Review-1

see https://review.openstack.org/#/c/105552/",1849,https://review.openstack.org/#/c/105552/,review.openstack.org,Patch,Providing Context,Internal,OpenStack217364,4523,"Patch Set 2:

This will conflict with https://review.openstack.org/#/c/200610/ (kinda stuck in the gate now) that also rewrote the scality unit tests.",7350,https://review.openstack.org/#/c/200610/,review.openstack.org,Patch,Providing Context,Internal,OpenStack125777,6873,"Patch Set 3:

Alex, that's the whole point of the patch.  Without this, that try/except in the attach_interfaces code is not going to handle this since the exception raised is going to be NeutronClientException, which doesn't extend the NotFound(NovaException).

I saw this when working on this change:

https://review.openstack.org/#/c/125756/",6873,https://review.openstack.org/#/c/125756/,review.openstack.org,Patch,Providing Context,Internal,OpenStack274023,14885,"Patch Set 8:

> Armando pushed the change to project-config and to Neutron to make
 > sure of this patch:
 > 
 > https://review.openstack.org/#/c/304324/
 > https://review.openstack.org/#/c/304321/

There's also:

https://review.openstack.org/#/c/303621/

Which is meant to go in as soon as we've gone past all the bumps.",748,https://review.openstack.org/#/c/303621/,review.openstack.org,Patch,Providing Context,Internal,OpenStack585037,841,"Patch Set 8:

Patch set 9 imported UT/FT workaround in https://review.openstack.org/#/c/619898/. I hope this passes UT/FT.",841,https://review.openstack.org/#/c/619898/,review.openstack.org,Patch,Providing Context,Internal,OpenStack453537,13915,"Patch Set 2:

Finally found out why our CI fails on this, pls see bug https://bugs.launchpad.net/cinder/+bug/1681406 and fix https://review.openstack.org/#/c/455256/ .
I'll rebase this change as soon as the fix is merged.",13915,https://review.openstack.org/#/c/455256/,review.openstack.org,Patch,Providing Context,Internal,OpenStack73672,6491,"Patch Set 19: (13 inline comments)

Fixed all issues in https://review.openstack.org/#/c/78782/.  Please verify.",6491,https://review.openstack.org/#/c/78782/,review.openstack.org,Patch,Providing Context,Internal,OpenStack15153,67,"Patch Set 1:

Looks good -- should be tied as a dependency to https://review.openstack.org/15155",1525,https://review.openstack.org/15155,review.openstack.org,Patch,Providing Context,Internal,OpenStack242573,17973,"Patch Set 21: Code-Review-1

Redesigned based on https://review.openstack.org/#/c/307124

Tox won't pass until it gets merged.",17973,https://review.openstack.org/#/c/307124,review.openstack.org,Patch,Providing Context,Internal,OpenStack129178,333,"Patch Set 4: Code-Review-1

Seems the plan is to rebase this patch on https://review.openstack.org/#/c/152759/, letting this patch focus on improving the tests and resolving the bug that was uncovered by the test here.",1689,https://review.openstack.org/#/c/152759/,review.openstack.org,Patch,Providing Context,Internal,OpenStack612393,4128,"Patch Set 14:

(2 comments)

You will need the following fix too, so make this change depend on:

https://review.openstack.org/625135",23561,https://review.openstack.org/625135,review.openstack.org,Patch,Providing Context,Internal,OpenStack346954,18289,"Patch Set 4:

So the patch [1] does not work ? test is still breaking?

[1] https://review.openstack.org/#/c/346585/",9531,https://review.openstack.org/#/c/346585/,review.openstack.org,Patch,Providing Context,Internal,OpenStack205282,5280,"Patch Set 2:

arrrrg was hitting that bug that was merged today... https://review.openstack.org/#/c/176379

need to update my devstack I guess :)",6984,https://review.openstack.org/#/c/176379,review.openstack.org,Patch,Providing Context,Internal,OpenStack276144,6062,"Patch Set 2:

yes, I added https://review.openstack.org/#/c/286819/
as a follow up ~",6062,https://review.openstack.org/#/c/286819/,review.openstack.org,Patch,Providing Context,Internal,OpenStack398389,7730,"Patch Set 1:

(1 comment)

Pawel I asked John to make [1] merged I hope that should be done by the end of the day so I do not have to rebase on top of your work

[1] https://review.openstack.org/#/c/373264/",7730,https://review.openstack.org/#/c/373264/,review.openstack.org,Patch,Providing Context,Internal,OpenStack216890,7448,"Patch Set 1: Code-Review-2

This is for reference.  I think we would merge Swami's patch here [1].

 [1] https://review.openstack.org/#/c/215329",7448,https://review.openstack.org/#/c/215329,review.openstack.org,Patch,Providing Context,Internal,OpenStack315341,19741,"Patch Set 4:

Thank you John, I have submitted new patch set for removing deprecated memcached option and rebase this patch based on it, please take a look and review - https://review.openstack.org/#/c/315463/",19741,https://review.openstack.org/#/c/315463/,review.openstack.org,Patch,Providing Context,Internal,OpenStack611088,15334,"Patch Set 12:

Backport proposed here https://review.openstack.org/#/c/625880/1",15334,https://review.openstack.org/#/c/625880/1,review.openstack.org,Patch,Providing Context,Internal,OpenStack188787,1779,"Patch Set 2: Code-Review+1

I would prefer that you rebase this on https://review.openstack.org/188321
If Not I can rebase on top of this.",1653,https://review.openstack.org/188321,review.openstack.org,Patch,Providing Context,Internal,OpenStack536249,27386,"Patch Set 2:

Has merged into[1]
[1]https://review.openstack.org/#/c/536252/",27386,https://review.openstack.org/#/c/536252/,review.openstack.org,Patch,Providing Context,Internal,OpenStack349582,21239,"Patch Set 1:

The related patches:
[1]: https://review.openstack.org/#/c/322341/
[2]: https://review.openstack.org/#/c/343542/
[3]: https://review.openstack.org/#/c/347256/",21239,https://review.openstack.org/#/c/322341/,review.openstack.org,Patch,Providing Context,Internal,OpenStack49694,841,"Patch Set 2:

Unit tests failure hits Cisco UT bug https://review.openstack.org/#/c/49317/ . Why don't other patches hit this?",841,https://review.openstack.org/#/c/49317/,review.openstack.org,Patch,Providing Context,Internal,OpenStack21946,2031,"Patch Set 24: Looks good to me, but someone else must approve

I tested this patch with counterpart nova patch https://review.openstack.org/#/c/44596/ and after small change in nova patch I confirm it works well with ML2.

I give +1. We need more reviewers since this patch affects all plugin.",841,https://review.openstack.org/#/c/44596/,review.openstack.org,Patch,Providing Context,Internal,OpenStack400384,10135,"Patch Set 18:

I've been testing this on stable/newton [1][2] and I saw the reproducer fail and the fix pass. Currently still waiting for results to post on those reviews because zuul got restarted a couple of times tonight, preventing results from posting to the reviews. I rechecked them again so we should get results posted soon.

I dug into why the bug doesn't reproduce on master and found that in newer os-brick, it retries _connect_single_volume in the event of a failure, does a cleanup that removes and disconnects devices, then tries the connect again [3]. We can see it in the logs on the reproducer test on master [5] where the connect fails first with ""Could not find the WWN for sda."" then disconnects things, then tries again and succeeds the second time.

Newer os-brick is tolerating the underlying bug, so I think we still need this nova change as the proper fix and not rely on os-brick's retry ability. If you take a look at the nova/virt/libvirt/driver.py code, neither _destroy nor _undefine_domain disconnect volumes. But then _get_guest_xml eventually goes to connect volumes. So we have a mismatch there which is wrong. We're inherently doing something wrong by trying to connect when there hasn't been a disconnect.

[1] https://review.openstack.org/#/c/512852
[2] https://review.openstack.org/#/c/512896
[3] https://github.com/openstack/os-brick/blob/af2f60f/os_brick/initiator/connectors/iscsi.py#L548
[5] http://logs.openstack.org/60/512760/1/check/legacy-tempest-dsvm-neutron-scenario-multinode-lvm-multibackend/b6880f6/logs/screen-n-cpu.txt.gz#_Oct_17_19_08_15_540083",4690,https://review.openstack.org/#/c/512896,review.openstack.org,Patch,Providing Context,Internal,OpenStack263400,8873,"Patch Set 2:

I submitted https://review.openstack.org/263550 to address the LBaaS api job.",6524,https://review.openstack.org/263550,review.openstack.org,Patch,Providing Context,Internal,OpenStack184647,9420,"Patch Set 4:

Joe: just for you...https://review.openstack.org/184968

That gives me a 7x speed increase on that test.",8768,https://review.openstack.org/184968,review.openstack.org,Patch,Providing Context,Internal,OpenStack552874,15334,"Patch Set 2:

> Still not rendering right.
 > 
 > http://logs.openstack.org/74/552874/2/check/build-openstack-sphinx-docs/b2ac70b/html/configuration/config.html#pci

https://review.openstack.org/553730 should correct that for now.",10135,https://review.openstack.org/553730,review.openstack.org,Patch,Providing Context,Internal,OpenStack247480,1736,"Abandoned

It will be moved to oslo.utils: https://review.openstack.org/#/c/249107/",1736,https://review.openstack.org/#/c/249107/,review.openstack.org,Patch,Providing Context,Internal,OpenStack635671,11816,"Patch Set 2:

Can you please add 
Depends-On: https://review.openstack.org/635706 
to the commit message.",10267,https://review.openstack.org/635706,review.openstack.org,Patch,Providing Context,Internal,OpenStack38073,8021,"Patch Set 6: I would prefer that you didn't merge this

So a change that will conflict with your work (and that I did incidentaly) is on it's way to the gate now so even if this was approved - It'll likely fail the gate.

The change is https://review.openstack.org/#/c/39086/ - so I recommend you rebase on top of that (in some way as the change moves a lot of code from under this patch).

I don't hate this approach - however I saw a patch series that solves it in a more elegant manner https://review.openstack.org/#/q/status:open+project:openstack/nova+branch:master+topic:bp/query-scheduler,n,z namely https://review.openstack.org/#/c/42389/ but I am not sure when it's planned to be landed/used. Adding alaski to the review.",5511,https://review.openstack.org/#/c/42389/,review.openstack.org,Patch,Providing Context,Internal,OpenStack18682,5754,"Patch Set 1:

Could you rebase this patch to https://review.openstack.org/#/c/18456/ so that it passes tests?",1994,https://review.openstack.org/#/c/18456/,review.openstack.org,Patch,Providing Context,Internal,OpenStack99427,8027,"Patch Set 4:

https://review.openstack.org/#/c/101164/ has been posted to implement the refactoring of get_datastore_ref_and_name() as brought up in this patch. Turns out quite a number of lines are altered with this refactor. If 101164 stays as an independent patch, I will update the get_image_properties patch on top of it.",8027,https://review.openstack.org/#/c/101164/,review.openstack.org,Patch,Providing Context,Internal,OpenStack114605,10370,"Patch Set 2: Workflow-1

This fix will be part of:
https://review.openstack.org/#/c/89982/",10370,https://review.openstack.org/#/c/89982/,review.openstack.org,Patch,Providing Context,Internal,OpenStack381333,17120,"Patch Set 3:

Also, last night we merged this fix to a regression introduced during Newton: https://review.openstack.org/#/c/380669/. Please rebase your patchset to the latest master. Otherwise, some of the test cases for floating ips with DNS still fail: http://paste.openstack.org/show/584311/. These are the sults after rebasing: http://paste.openstack.org/show/584312/

I recommend that until we merge https://review.openstack.org/#/c/301809/, you run the unit tests in it manually in your local system every time you submit new revisions to this patchset. I will be glad to help with this and in any case I will keep an eye on this patchset ;-)",4694,https://review.openstack.org/#/c/301809/,review.openstack.org,Patch,Providing Context,Internal,OpenStack158745,15239,"Patch Set 6:

This CI is still not ready. Checking the last 20 runs, it fails all but one run:

Checking name: Nexenta Edge CI
last 20 comments from 'Nexenta Edge CI' on project 'openstack/cinder'
[0] 2015-06-13 03:55:59 (2 days, 12:18:45 old) https://review.openstack.org/189920 'Adds the Violin Memory V7000 series FC driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-20-189920-5/ns_edge : FAILURE in 47m 48s
[1] 2015-06-13 03:34:05 (2 days, 12:40:39 old) https://review.openstack.org/158745 'Nexenta Edge iSCSI backend driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-45-158745-12/ns_edge : FAILURE in 46m 54s
[2] 2015-06-13 00:21:15 (2 days, 15:53:29 old) https://review.openstack.org/158745 'Nexenta Edge iSCSI backend driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-45-158745-12/ns_edge : FAILURE in 50m 36s
[3] 2015-06-12 21:41:39 (2 days, 18:33:05 old) https://review.openstack.org/191192 'Revert First version of Cinder driver for Quobyte' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-92-191192-2/ns_edge : FAILURE in 43m 46s
[4] 2015-06-12 21:32:22 (2 days, 18:42:22 old) https://review.openstack.org/191064 'Replace dict(obj.iteritems() with dict(obj)' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-64-191064-1/ns_edge : FAILURE in 6m 14s
[5] 2015-06-12 21:04:05 (2 days, 19:10:39 old) https://review.openstack.org/190695 'Volume manager should set filter_function and goodness_function' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-95-190695-2/ns_edge : FAILURE in 67m 5s
[6] 2015-06-12 20:52:30 (2 days, 19:22:14 old) https://review.openstack.org/182745 '3PAR enable multiattach capability reporting' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-45-182745-5/ns_edge : FAILURE in 40m 30s
[7] 2015-06-12 20:49:51 (2 days, 19:24:53 old) https://review.openstack.org/190391 'NexentaStor 5 iSCSI backend driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-91-190391-7/ns_edge : FAILURE in 51m 51s
[8] 2015-06-12 19:01:52 (2 days, 21:12:52 old) https://review.openstack.org/191066 'Replace dit.itervalues() with dict.values()' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-66-191066-1/ns_edge : FAILURE in 8m 10s
[9] 2015-06-12 19:00:44 (2 days, 21:14:00 old) https://review.openstack.org/187886 'Validate outermost request body element name consistently' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-86-187886-4/ns_edge : FAILURE in 25m 15s
[10] 2015-06-12 18:22:24 (2 days, 21:52:20 old) https://review.openstack.org/190391 'NexentaStor 5 iSCSI backend driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-91-190391-7/ns_edge : SUCCESS in 49m 46s
[11] 2015-06-12 17:10:27 (2 days, 23:04:17 old) https://review.openstack.org/190391 'NexentaStor 5 iSCSI backend driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-91-190391-7/ns_edge : FAILURE in 8m 10s
[12] 2015-06-12 16:48:41 (2 days, 23:26:03 old) https://review.openstack.org/174241 'Fix a wrong argument of delete_keys method' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-41-174241-2/ns_edge : FAILURE in 100m 30s
[13] 2015-06-12 14:57:09 (3 days, 1:17:35 old) https://review.openstack.org/178573 'Re-add DRBD driver.' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-73-178573-18/ns_edge : FAILURE in 98m 18s
[14] 2015-06-12 11:03:42 (3 days, 5:11:02 old) https://review.openstack.org/185545 'Fix weird change of volume status in re-scheduling' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-45-185545-12/ns_edge : FAILURE in 78m 55s
[15] 2015-06-12 10:26:56 (3 days, 5:47:48 old) https://review.openstack.org/190173 'Replace it.next() with next(it) for py3 compat' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-73-190173-3/ns_edge : FAILURE in 85m 13s
[16] 2015-06-12 09:22:44 (3 days, 6:52:00 old) https://review.openstack.org/185906 'set-size-limit-for-volume' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-06-185906-11/ns_edge : FAILURE in 42m 19s
[17] 2015-06-12 08:29:40 (3 days, 7:45:04 old) https://review.openstack.org/182985 'Introduce Guru Meditation Reports into Cinder' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-85-182985-4/ns_edge : FAILURE in 54m 59s
[18] 2015-06-12 08:20:23 (3 days, 7:54:21 old) https://review.openstack.org/185906 'set-size-limit-for-volume' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-06-185906-11/ns_edge : FAILURE in 53m 4s
[19] 2015-06-12 07:15:39 (3 days, 8:59:05 old) https://review.openstack.org/189517 'Support SMI-S provider v8.0.3 in VMAX driver' 
* nexenta-dsvm-volume-ns_edge http://140.174.232.106/refs-changes-17-189517-4/ns_edge : FAILURE in 50m 38s
success count by job:
* nexenta-dsvm-volume-ns_edge: 1
failure count by job:
* nexenta-dsvm-volume-ns_edge: 19",170,https://review.openstack.org/158745,review.openstack.org,Patch,Providing Context,Internal,OpenStack466486,333,"Patch Set 1:

This is the follow up patch for https://review.openstack.org/#/c/462536/

Needs to wait for new neutron-lib",333,https://review.openstack.org/#/c/462536/,review.openstack.org,Patch,Providing Context,Internal,OpenStack145095,12000,"Patch Set 2: Code-Review+2 Workflow-1

Let's land https://review.openstack.org/#/c/125338/ and release 0.1.11 first.",6549,https://review.openstack.org/#/c/125338/,review.openstack.org,Patch,Providing Context,Internal,OpenStack563732,6873,"Patch Set 1:

testing in tempest too- https://review.openstack.org/#/c/563801/",8556,https://review.openstack.org/#/c/563801/,review.openstack.org,Patch,Providing Context,Internal,OpenStack482994,8556,"Patch Set 1:

Also, why wouldn't this be based on top of https://review.openstack.org/#/c/480792/ ?

This is also going to make https://review.openstack.org/#/c/454322/35/api-ref/source/parameters.yaml extra confusing for 2.51 because in 2.51 the events and all event fields are required *except* for the 'traceback' field which would still be bound by admin-only policy by default.",6873,https://review.openstack.org/#/c/480792/,review.openstack.org,Patch,Providing Context,Internal,OpenStack128940,9569,"Patch Set 60:

you should depend on this https://review.openstack.org/203037 also, otherwise this patch is buggy.",5754,https://review.openstack.org/203037,review.openstack.org,Patch,Providing Context,Internal,OpenStack1202,1362,"Patch Set 4:

Also, check out https://review.openstack.org/#change,2214 which is likely to get in soon; you'll need to change the volumes.py extension changes to coordinate with templates.  (You can feel free to contact me offline to get a rundown on how templates work, if you need...)",679,https://review.openstack.org/#change,review.openstack.org,Patch,Providing Context,Internal,OpenStack41382,6939,"Patch Set 3: I would prefer that you didn't merge this

Please wait until this lands: https://review.openstack.org/#/c/41601/",2759,https://review.openstack.org/#/c/41601/,review.openstack.org,Patch,Providing Context,Internal,OpenStack77125,7491,"Patch Set 10: Code-Review+2 Workflow+1

Winston-D actually figured out the source of the problem:  https://review.openstack.org/#/c/101407/  I am going to give this a +A.  If it fails I may have to rebase it on Winston-D's change.",7198,https://review.openstack.org/#/c/101407/,review.openstack.org,Patch,Providing Context,Internal,OpenStack24998,5948,"Patch Set 7: Work In Progress

Waiting for https://review.openstack.org/#/c/25566 to be merged",5948,https://review.openstack.org/#/c/25566,review.openstack.org,Patch,Providing Context,Internal,OpenStack199196,10267,"Patch Set 9:

If we clean conntrack entries, that will break the connections. But here we are trying to continue the existing connections.
Please check my previous patch https://review.openstack.org/#/c/196054/)",10267,https://review.openstack.org/#/c/196054/,review.openstack.org,Patch,Providing Context,Internal,OpenStack328944,19741,"Patch Set 3:

(4 comments)

Thank you John and Stephen, the nits are fixed in following patch-set: https://review.openstack.org/#/c/340713/",19741,https://review.openstack.org/#/c/340713/,review.openstack.org,Patch,Providing Context,Internal,OpenStack183137,7012,"Patch Set 16:

(1 comment)

The dependent patch, with Ian's and Kairat's comments addressed, is up at https://review.openstack.org/#/c/219731/",7012,https://review.openstack.org/#/c/219731/,review.openstack.org,Patch,Providing Context,Internal,OpenStack341633,12408,"Patch Set 9:

Please rebase this on top of  https://review.openstack.org/412564",12000,https://review.openstack.org/412564,review.openstack.org,Patch,Providing Context,Internal,OpenStack378299,8213,"Patch Set 1:

Done:

https://review.openstack.org/#/c/379816/

https://review.openstack.org/379820",8213,https://review.openstack.org/#/c/379816/,review.openstack.org,Patch,Providing Context,Internal,OpenStack1373,67,"Patch Set 5: I would prefer that you didn't submit this

Hey Vish.

I'm seeing the following error when I run this in Smokestack:

AttributeError: 'MetadataRequestHandler' object has no attribute '_image_type'

http://paste.openstack.org/show/3387/",360,http://paste.openstack.org/show/3387/,paste.openstack.org,Patch,Providing Context,Internal,OpenStack124946,5196,"Patch Set 1: Code-Review-1

Take a look at this change in oslo https://review.openstack.org/99965. After merging it could be used here. I was thinking about creating this kind of test to neutron(https://review.openstack.org/111286, https://bugs.launchpad.net/neutron/+bug/1349345)but now, as was done changes like https://review.openstack.org/115620 I'm not sure that we need this.",7249,https://review.openstack.org/99965,review.openstack.org,Patch,Providing Context,Internal,OpenStack75865,6549,"Patch Set 5:

btw, I will do a Oslo-db code sync-up change after https://review.openstack.org/#/c/75356/ landing, and rebase this patch on it.",6549,https://review.openstack.org/#/c/75356/,review.openstack.org,Patch,Providing Context,Internal,OpenStack343816,16800,"Patch Set 2:

This patch is dependent upon [1] which needs to be rebased as well.

[1] https://review.openstack.org/#/c/341846/",16800,https://review.openstack.org/#/c/341846/,review.openstack.org,Patch,Providing Context,Internal,OpenStack25526,7073,"Patch Set 1:

Unit test added but using the wrong change it sorry, https://review.openstack.org/#/c/25753/",7073,https://review.openstack.org/#/c/25753/,review.openstack.org,Patch,Providing Context,Internal,OpenStack116717,9311,"Patch Set 1: Code-Review-2

Talked to Tristan about this and pushed up the sync for him:  https://review.openstack.org/116941",7198,https://review.openstack.org/116941,review.openstack.org,Patch,Providing Context,Internal,OpenStack336092,10058,"Patch Set 27:

After two days debugging and CI result checking, the CI result summary: http://paste.openstack.org/show/600300/

CI BROKEN

Huawei:                                
huawei-iscsi-dsvm-tempest-full

Infortrend:                                
infortrend-cinder-volume-iscsi        
infortrend-cinder-volume-fc

VMware NSX CI        
ext-cinder-prio-dsvm-nsx                

Vedams-H...river CI                 
vedams-hpmsa-dsvm-tempest-full-iscsi        
vedams-hpmsa-dsvm-tempest-full-fc
        
Oracle ZFSSA CI 
oracle-zfssa-dsvm-nfs                        

Nexenta Edge CI                        
nexenta-dsvm-volume-ns_edge                 
nexenta-dsvm-volume-cinder_nedge11_nbd         

NEC Cinder CI        
NEC-ISCSI        
NEC-FC        

Failing:  MicroSoft CI        


All of the rest CI tests are PASSING or SUCCESS

I have sent email to the vendors to ask for fixing the CI broken issues.

I will also open a defect to fix the windows' driver code which caused the CI failure with attempting to extend the volume to a size of 0 GB.",21144,http://paste.openstack.org/show/600300/,paste.openstack.org,Patch,Providing Context,Internal,OpenStack486204,7764,"Patch Set 50:

Spec has been approved for Rocky:
https://review.openstack.org/#/c/540879/",24711,https://review.openstack.org/#/c/540879/,review.openstack.org,Patch,Providing Context,Internal,OpenStack616850,24454,"Patch Set 2:

> recheck

This patch won't merge until this change https://review.openstack.org/#/c/643130/ is merged.
Please Wait for it's merge then recheck here.",27615,https://review.openstack.org/#/c/643130/,review.openstack.org,Patch,Providing Context,Internal,OpenStack17965,1561,"Patch Set 1: Work In Progress

oslo change needs to go in first:

https://review.openstack.org/#/c/17554/",1561,https://review.openstack.org/#/c/17554/,review.openstack.org,Patch,Providing Context,Internal,OpenStack69179,8290,"Patch Set 1: I would prefer that you didn't merge this

Sorry for the -1, but given you're changing the same lines as https://review.openstack.org/#/c/67514/ So I would like to see a consistent change for the line to avoid conflicts.",6484,https://review.openstack.org/#/c/67514/,review.openstack.org,Patch,Providing Context,Internal,OpenStack218478,7448,"Patch Set 4:

(2 comments)

This patch just gets me thinking about pyroute2 support,
https://review.openstack.org/#/c/155631/ to avoid all the screen-scraping.  But that's work for another day.",1131,https://review.openstack.org/#/c/155631/,review.openstack.org,Patch,Providing Context,Internal,OpenStack81356,10247,"Patch Set 3:

Note that Jenkins will fail until the tempest side change https://review.openstack.org/81551 has actually merged. Jenkins failures look clean currently (only failing on the tests we expect them to fail on).",5292,https://review.openstack.org/81551,review.openstack.org,Patch,Providing Context,Internal,OpenStack192179,12955,"Patch Set 1:

This fix is required for this patch. Please check this
https://review.openstack.org/#/c/165023/25",12955,https://review.openstack.org/#/c/165023/25,review.openstack.org,Patch,Providing Context,Internal,OpenStack116039,1689,"Patch Set 1:

The job is running, the queue is backed up a little...

http://status.openstack.org/zuul/",748,http://status.openstack.org/zuul/,status.openstack.org,Software homepage,Providing Context,Internal,OpenStack153893,14358,"Patch Set 1: Code-Review-1

(1 comment)

this should go to oslo-incubator first (see https://wiki.openstack.org/wiki/Oslo#Incubation for details)",6849,https://wiki.openstack.org/wiki/Oslo#Incubation,wiki.openstack.org,Tutorial or article,Providing Context,Internal,OpenStack143987,9067,"Patch Set 4:

Can you also check if this translation rule apply to this patch

http://docs.openstack.org/developer/oslo.i18n/guidelines.html#avoid-forcing-the-translation-of-translatable-variables

I am not sure if they do apply, so slightly hesitant to give a -1 :)",5538,http://docs.openstack.org/developer/oslo.i18n/guidelines.html#avoid-forcing-the-translation-of-translatable-variables,docs.openstack.org,Tutorial or article,Providing Context,Internal,OpenStack219248,14358,"Patch Set 13:

Hi John, spec is on review: https://review.openstack.org/#/c/237588/. Could you please review it?",14358,https://review.openstack.org/#/c/237588/,review.openstack.org,Patch,Suggesting Experts,Internal,OpenStack33630,2861,"Patch Set 8:

I tested the bug today and discovered something more. My conclusion is that the reason for this bug is not the naming convention and I guess it is due to the consumer register in create_consumer in impl_zmq.py. Unfortunately I have locked the exact reason for it.

I pasted a very long comment in https://bugs.launchpad.net/cinder/+bug/1166899 and I need the comments from anyone, who is the expert in the part of zeromq implementation.",2861,https://bugs.launchpad.net/cinder/+bug/1166899,bugs.launchpad.net,Bug report,Suggesting Experts,Internal,OpenStack37872,2861,"Patch Set 5:

Nikola and Phil, Please review https://review.openstack.org/#/c/38412/.
I changed the code according to the comments. Thank yo so much.",2861,https://review.openstack.org/#/c/38412/,review.openstack.org,Patch,Suggesting Experts,Internal,OpenStack195713,11803,"Patch Set 3:

According to http://eventlet.net/doc/basic_usage.html, it does appear that eventlet.spawn is calling greenthread.spawn under-the-covers, so it seems like it would make sense to also check for this.",16839,http://eventlet.net/doc/basic_usage.html,eventlet.net,API documentation,Clarifying,External,OpenStack327201,7448,"Patch Set 3:

(1 comment)

@Rawlin, good question.  I added an inline comment to illustrate something.  The join version of your subquery would be something like this:

select * from subports JOIN trunks on subports.trunk_id == trunks.id WHERE trunks.port_id = ???;

DBs are pretty good at doing these joins.  I wouldn't worry about the efficiency of this operation as long as my patch adding the index on subports.trunk_id merges.

http://www.w3schools.com/sql/sql_join.asp",7448,http://www.w3schools.com/sql/sql_join.asp,www.w3schools.com,API documentation,Clarifying,External,OpenStack54925,6722,"Patch Set 9: (2 inline comments)

Hi, Kevin L. Mitchell,
Thanks for your review first, do you mean the order of the list is different on
different times when running this unit test if build up a list by converting a set?
I do not think the order will change on different execution, the order of set will
not change, you can see ""Return a list whose items are the same and in the
same order as iterable‘s items."" about explanation of 'list([iterable])' in
http://docs.python.org/2/library/functions.html#list, So I do not agree with you,
if you have other concern, can tell me anytime,if you do not have, please remove -1 when you have time, Thank you :)",8651,http://docs.python.org/2/library/functions.html#list,docs.python.org,API documentation,Clarifying,External,OpenStack419074,6593,"Patch Set 1:

> 
 > Hemanth, I think both api and scrubber now are mokeypatching all
 > the modules. So is the current patch. Cos, all the 5 parameters
 > that eventlet's monkey_patch() takes have been enabled there. [1] I
 > think it is okay to be implicitly state the same here.
 > Registry on the other hand has enabled only socket, time and
 > thread.
 > 
 > 
 > http://eventlet.net/doc/basic_usage.html#eventlet.monkey_patch

It may be the same. Or not? http://eventlet.net/doc/patching.html#eventlet.patcher.monkey_patch

Looks like now psycopg can be monkey patched as well. Now, we don't use postgres, so it is probably not an issue. But, can you see what I'm concerned about? Monkey patching ``all`` is very implicit. If eventlet adds support for something else tomorrow, then that would get monkey patched by default too irrespective of our intention. We'll then be looking at a nasty debugging scenario.

Call me paranoid but explicit is better than implicit. 
Moreover, what is ``all`` buying us that explicit monkey patching doesn't? Help me understand.",8158,http://eventlet.net/doc/basic_usage.html#eventlet.monkey_patch,eventlet.net,API documentation,Clarifying,External,OpenStack59408,9173,"Patch Set 1: No score

Daniel, I think what you're asking is how to amend an existing review.  If you're using git on the command line, save your changes, ""git add"" them, and then ""git commit --amend"" to commit the changes.

http://git-scm.com/docs/git-commit",7179,http://git-scm.com/docs/git-commit,git-scm.com,API documentation,Clarifying,External,OpenStack148747,2243,"Patch Set 2:

Hi John,

Just wanted to say that your reply to me about the global being updated is not correct.  For example, see this transcript:

Python 2.7.8 (default, Oct 18 2014, 12:50:18) 
[GCC 4.9.1] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> >>> >>> >>> 
>>> LVM_CMD_PREFIX = ['env', 'LC_ALL=C']
>>> print LVM_CMD_PREFIX
['env', 'LC_ALL=C']
>>> cmd = LVM_CMD_PREFIX + ['vgs', '--noheadings', '-o', 'name', 'NAME']
>>> print cmd
['env', 'LC_ALL=C', 'vgs', '--noheadings', '-o', 'name', 'NAME']
>>> print LVM_CMD_PREFIX
['env', 'LC_ALL=C']
>>> 

(Formally, section 5.6 of https://docs.python.org/2/library/stdtypes.html#index-15 says that ""s + t"" gives the concatenation of s and t.  Unfortunately it doesn't explicitly state that the returned value is a new list - but in practice it is.)

Hope that's useful - Neil.",13734,https://docs.python.org/2/library/stdtypes.html#index-15,docs.python.org,API documentation,Clarifying,External,OpenStack136834,8449,"Patch Set 4: Code-Review-1

thanks for all the comments - I believe I've addressed all of them. 

SETTING -1 FOR NOW because this code is apparently hazardous to the health of ovs:

I moved the cleanup outof the addCleanup, because it was causing a segfault - basically, tearDown() is apparently [1] called before the cleanup methods. This meant that the int-br (and tap-xXXX where dnsmasq is attached) was being pulled out from under dnsmasq. Aparrently this is very bad for the health of the kernel.

With ovs 2.3.0 [2] in it's present form, this code with succeed on the first run,and then segfault ovs on the next run, reliably. After this only a reboot will bring ovs back (modprobe, restarting ovs, nothing). I need to investigate some more, but any ideas would be very very helpful,

thanks!

[1] https://docs.python.org/dev/library/unittest.html#unittest.TestCase.addCleanup
[2] (3.git20141107.fc20)",8449,https://docs.python.org/dev/library/unittest.html#unittest.TestCase.addCleanup,docs.python.org,API documentation,Clarifying,External,OpenStack3954,2140,"Patch Set 1: I would prefer that you didn't submit this

I do want to point out that this implements the latest format of the CreateSecurityGroup response, not the version we claim to support: http://docs.amazonwebservices.com/AWSEC2/2009-04-04/APIReference/index.html?ApiReference-query-CreateSecurityGroup.html


Somebody from the EC2 API team should make the call as to whether we aim for our supported version (2009-04-04) or latest",1132,http://docs.amazonwebservices.com/AWSEC2/2009-04-04/APIReference/index.html?ApiReference-query-CreateSecurityGroup.html,docs.amazonwebservices.com,API documentation,Clarifying,External,OpenStack284597,18603,"Patch Set 5:

> (2 comments)

Hi Michal!
Thanks for your comment! ;)
I know that: assertFalse(A < B) = assertTrue(A >= B) = assertGreaterEqual(A, B) = assertLessEqual(B, A). Or my 'conclusion' is wrong?
(The cause of the exchange: https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertFalse)",18603,https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertFalse,docs.python.org,API documentation,Clarifying,External,OpenStack27059,1653,"Patch Set 3: I would prefer that you didn't merge this

Nothing against this review per se, but after reading this blog:

http://doughellmann.com/2012/11/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2.html

using dict() instead of {} suddenly does not sound like a great idea to me. I am adding Doug to the review so that he could chime in.",748,http://doughellmann.com/2012/11/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2.html,doughellmann.com,Blog post,Clarifying,External,OpenStack307075,9535,"Patch Set 2:

child_versions is used by Oslo Versioned Objects to do backporting, but we can remove it because we have added obj_relationship property to the list objects, and Oslo will use that property if there is no child_versions dictionary.

You can read a better explanation here: http://gorka.eguileor.com/learning-something-new-about-oslo-versioned-objects/",9535,http://gorka.eguileor.com/learning-something-new-about-oslo-versioned-objects/,gorka.eguileor.com,Blog post,Clarifying,External,OpenStack32248,6593,"Patch Set 2: Looks good to me, but someone else must approve

Rafi,
""The BDFL [3] recommends inserting a blank line between the last paragraph in a multi-line docstring and its closing quotes, placing the closing quotes on a line by themselves. This way, Emacs' fill-paragraph command can be used on it.""
http://www.python.org/dev/peps/pep-0257/

Furthermore, concern over merge conflicts hardly seems like a good reason not to merge something.  If there is a merge conflict it can be resolved.

While I am fine with removing this requirement altogether (I don't use emacs), If we keep this around as part of the style guide I prefer to enforce it automatically instead of manually.

http://arstechnica.com/information-technology/2013/06/is-it-a-good-idea-to-impose-uniform-code-format-for-all-developers/ 

Note: only giving this a +1, to wait for more consensus.",1849,http://arstechnica.com/information-technology/2013/06/is-it-a-good-idea-to-impose-uniform-code-format-for-all-developers/,arstechnica.com,Blog post,Clarifying,External,OpenStack159596,170,"Patch Set 1:

Thanks to Flavio for reminding me of this. I'm not even sure if he's talking about this, but whatever. :)

https://twitter.com/flaper87/status/570864233027514368",170,https://twitter.com/flaper87/status/570864233027514368,twitter.com,Blog post,Clarifying,External,OpenStack37421,6549,"Patch Set 4:

Zhi, I have already looked at patch 1. (How else would I know it was correct?)

Flavio is mistaken for all of the reasons I've given previously.

Your current patch is more complicated than it needs to be and in fact introduces bugs.

Here's a some good sources for why you should decode early (not relevant for this discussion) and why you should encode late:
http://farmdev.com/talks/unicode/
http://eric.themoritzfamily.com/python-encodings-and-unicode.html

Take this as an example: Someone has configured their logging setup to use UTF-16 or UTF-32. What will your last patch do? What will your first patch do?

Ultimately, the encoding choice is not your decision! It's the users decision. Don't make it for them. This is why we want to do the encoding as late as possible, where the user can make that decision for themselves.",100,http://eric.themoritzfamily.com/python-encodings-and-unicode.html,eric.themoritzfamily.com,Blog post,Clarifying,External,OpenStack267283,17776,"Patch Set 3:

Dear Hirofumi,
Thanks for the review.

Yes, I agree that , considering http://tools.ietf.org/html/rfc5952#section-4, rules can be followed to ensure proper translation of IPv6 addresses.

In that scenario, the devref and documentation ( and release note? )would be updated ( as you already mentioned). However, if user still provides the full IPv6 address, it would be compressed ( as the rule has been enforced). Will put up the devref and documentation in the next-next PS",17776,http://tools.ietf.org/html/rfc5952#section-4,tools.ietf.org,Book content,Clarifying,External,OpenStack115582,91,"Patch Set 4:

Hi Dan, thanks for your comments.

I agree with the packaging stuff, but there are other issues here:

1. As per [*] I understand that the libvirt XML expects a bootloader. Currently OpenStack generated libvirt.xml file lacks it, but if it is expected we should generate it.

2. libvirt is setting the bootloader to a full path ""/usr/bin/pygrub"", but this is deprecated [**], the warning below is shown in the logs. IMHO this should be solved in libvirt [***], because of the deprecation warning.
  
    libxl: warning: libxl_bootloader.c:413:bootloader_disk_attached_cb: bootloader='/usr/bin/pygrub' is deprecated; use bootloader='pygrub' instead

3. pygrub, that is the default bootloader, does not support Qcow2 disks. pvgrub does, but it is not possible to tell libvirt to use it (via OpenStack or via some libvirt config). Even if I would be able to force configure Xen to use pvgrub, libvirt will overwrite it to ""/usr/bin/pygrub"".

Currently we are stuck using the depreacted xend because of this (2). I
could file a bug to Debian and Ubuntu saying that they should install pygrub in
its standard location, but this just solves (2), but no (3). For instance we want
to start working on the testing of the CoW support using Xen+libvirt, but we
cannot start because of this.

How could I as an operator tell that I want to use pvgrub instead of pygrub, if
I am not able to specify this in libvirt or OpenStack?

[*] https://www.redhat.com/archives/libvir-list/2014-August/msg00804.html
[**] http://wiki.xen.org/wiki/PyGrub
[***] https://bugzilla.redhat.com/show_bug.cgi?id=1104695",91,https://bugzilla.redhat.com/show_bug.cgi?id=1104695,bugzilla.redhat.com,Bug report,Clarifying,External,OpenStack58494,1779,"Patch Set 4:

Gerrit comments are really not a good forum for this kind of debate. It is wider than just libvirt - eg Xen or VWmare drivers increase their min required version the same issues apply. Python modules  get their min versions increased all the time with zero warning at all, often with lots of pain for people.

This really highlights a gap in our procedures / policies for integration with external software components. I think that someone who cares about this issue needs to pick up the ball, write up a formal policy proposal wrt changing version deps on external components, take it to the mailing list for discussion and agreement by whoever needs to agree (Nova core / PTLs?).

I'll happily follow any formal procedure we clearly define + document, but I can't second guess what requirements people might have in the absence of any docs.

In any case, the intent to increase min versions will likely have to be postponed for now due to a bug we've uncovered which impacts openstack. https://bugzilla.redhat.com/show_bug.cgi?id=929412  So we will likely have to wait until Juno to increase the version & get the gate running on it.",1779,https://bugzilla.redhat.com/show_bug.cgi?id=929412,bugzilla.redhat.com,Bug report,Clarifying,External,OpenStack661266,2394,"Patch Set 2:

Ugh.  The lower-constraints failure is because configparser.py uses enumerate() to iterate over the lines of the (mocked) /etc/nova/release config file, and this uses __iter__() under the hood which was not supported via mock_open until https://bugs.python.org/issue21258 was fixed. The fix was backported to the external mock library for 3.0.0: https://github.com/testing-cabal/mock/commit/73f6eed0d6867299fa2543b88a07cd8f12198361

but for some reason lower-constraints specifies mock==2.0.0 for all Python versions even though mock is built-in from Python 3.3 onwards:

https://github.com/testing-cabal/mock/blob/master/README.rst

So I either need to give up on supporting mocking oslo config file contents, or add an option to patch_open which allows use of StringIO instead of mock_open. This has the disadvantage that mock assertions cannot be made on StringIO objects, but that's why we'd default to mock_open and only use StringIO when we need to.

Thoughts?",2394,https://bugs.python.org/issue21258,bugs.python.org,Bug report,Clarifying,External,OpenStack639396,8864,"Patch Set 1:  > (3 comments)  >   > It looks like maybe something has changed about what we're doing  > with neutron that ends up emitting the event. We should figure that  > out.  I think over time we've just added so much stuff that by the time the code that actually listens for events is reached, Neutron has done its thing and has sent us the event. The downstream bug [1] maybe makes it clearer.  You're right, introducing state and cleaning up after is a pain, but I don't see a way around the fundamental necessity of listening as soon as we poke Neutron in way that'll cause it to send the event.  Maybe then just don't change wait_for_instance_events() and just wrap it around self.network_api.setup_networks_on_host? Do we have all we need at that time to call it properly?  [1] https://bugzilla.redhat.com/show_bug.cgi?id=1678681",8864,https://bugzilla.redhat.com/show_bug.cgi?id=1678681,bugzilla.redhat.com,Bug report,Clarifying,External,OpenStack465653,15952,"Patch Set 1:

(1 comment)

I tried to do the same exercise with threads, but it seems there is no way in Python to properly kill a thread without causing trouble. So I guess a subprocess looks like a good candidate. The one thing that makes me scared is that I don't see usages of multiprocessing in nova, seems to me that oslo.concurrency is using subprocess as well. And this bug also suggests that we might have issues around the eventlet-multiprocessing combo: https://github.com/eventlet/eventlet/issues/210 So maybe our best option would be to use subprocess as well? Maybe add the timeout to the oslo library?",5044,https://github.com/eventlet/eventlet/issues/210,github.com,Bug report,Clarifying,External,OpenStack53923,6737,"Patch Set 3:

Eric, I think it is the same issue as this: http://bugs.python.org/msg174915

cinder-volume does the same thing for windows but it appears to affect more than windows.",6737,http://bugs.python.org/msg174915,bugs.python.org,Bug report,Clarifying,External,OpenStack602362,8313,"Patch Set 3:

I think it is related to how python2 and python3 handles closures, I tried to reproduce the issue without neutron:
https://gist.github.com/elajkat/4b2f9ac9c9dcabe63ab6d2f94dcb224e

Shortly: six.get_function_closure in py27 gives back None, in py35 it gives back something like <cell at 0x7fbe60ec24c8: empty>.

And as pecan handles only None (https://github.com/pecan/pecan/blob/master/pecan/util.py#id=L20), we run into error.",8313,https://github.com/pecan/pecan/blob/master/pecan/util.py#id=L20,github.com,Code,Clarifying,External,OpenStack483994,15334,"Patch Set 6:

> Adding this comment for information purpose:
 > If I use v1.0.0-testing.2 released on 5th Oct (https://github.com/novnc/noVNC/archive/v1.0.0-testing.2.zip),
 > then it's unable to get token from the URL in nova-novncproxy
 > service.
 > 
 > I had reported this issue (https://github.com/novnc/noVNC/issues/967)
 > in noVNC and the noVNC community suggested to use path query
 > parameter to retreive token.
 > 
 > This requires changes in nova, mainly nova-compute and
 > nova-novncproxy services.

I validated a recent DevStack deployment with noVNC 1.0. It was necessary to change '[vnc] novncproxy_base_url' from '{address}/vnc_auto.html' to '{address}/vnc_simple.html'. This is because of commit 83391ffc in noVNC [1]. Once that was done, everything worked as expected and I could not reproduce the above issue. I also was not able to identify any commits upstream that made this change. What have I missed?

[1] https://github.com/novnc/noVNC/commit/83391ffc38d91f6ceb5da6cf764a5411dc431543",15334,https://github.com/novnc/noVNC/commit/83391ffc38d91f6ceb5da6cf764a5411dc431543,github.com,Code,Clarifying,External,OpenStack465404,13630,"Patch Set 4:

> The commit message isn't entirely true. Ceph (and by extension,
 > rados) >= 10.1.0 handles unicode strings perfectly well [1] as part
 > of its Python 3 support [2]. In addition, using 'str' like this
 > means we could risk breaking support for anyone using unicode in
 > paths. I don't imagine these folks are that common and I'm not even
 > sure if anyone would use unicode in a path. Finally, there's the
 > fact that we're getting unicode in the first place when we really
 > shouldn't be. I would guess this is caused by WebOb, which encodes
 > everything in unicode, when handling the build request from the
 > API. Fixing things higher up the stack is a possibility.
 > 
 > All that being said, this does fix the issue at hand and is
 > _unlikely_ to break anything, so we can use. I would like to see a
 > comment in the code noting why we do this, however, along with a
 > comment that this isn't necessary for ceph 10.1.0+. At some point
 > in the future, we could then drop both that and the test. The -1 is
 > for that missing comment.
 > 
 > [1] https://github.com/ceph/ceph/blob/v10.1.0/src/pybind/rados/rados.pyx#L430-L448
 > [2] https://github.com/ceph/ceph/blob/v10.1.0/src/pybind/rados/rados.pyx#L29-L35

When I reviewed it I noticed there are already several use of str() in that file for the same issue AFAICT, so if we want a comment on them, we are going to add a lot of comments.",4690,https://github.com/ceph/ceph/blob/v10.1.0/src/pybind/rados/rados.pyx#L29-L35,github.com,Code,Clarifying,External,OpenStack482622,18602,"Patch Set 5:

> > (4 comments)
 > >
 > > I feel that compute.api.HostAPI is dead code. I will ask around
 > if
 > > this is really the case.
 > > Cheers,
 > > gibi
 > I sent a mail to the mailing list and proposed to remove this from
 > our TODO list.
 > http://lists.openstack.org/pipermail/openstack-dev/2017-September/122287.html

We agreed [1] not to transform this. So I removed it from the TODO list as well [2].

[1] http://lists.openstack.org/pipermail/openstack-dev/2017-September/122309.html 
[2] https://github.com/gibizer/nova-versioned-notification-transformation-burndown/commit/112a25aecf7e9b1f344840ae4ce150f70e75b634#diff-cd2b276ea9db6ffddf9aa78d871ab2e9",9708,https://github.com/gibizer/nova-versioned-notification-transformation-burndown/commit/112a25aecf7e9b1f344840ae4ce150f70e75b634#diff-cd2b276ea9db6ffddf9aa78d871ab2e9,github.com,Code,Clarifying,External,OpenStack275616,12171,"Patch Set 22:

> > > (1 comment)
 > > >
 > > > > > > (2 comments)
 > > > > > >
 > > > > > > Is there any agent-side patch required to close the
 > circle?
 > > > > >
 > > > > > The kernel feature is mostly transparent to ovs, you just
 > > plug
 > > > a
 > > > > > 'representor' device passed from nova into the bridge and
 > it
 > > > will
 > > > > > intelligently steer flows between software and hardware
 > > > depending
 > > > > > on hardware capabilities. So there is no need in special
 > > agent
 > > > > > handling.
 > > > >
 > > > > I meant, we'd need to enable a new datapath_type on the agent
 > > > side
 > > > > at least
 > > > There is no new datapath type in this solution  (it is not like
 > > > DPDK). The solution is using the ovs kernel datapath see [1].
 > > >
 > > >
 > > > [1] - https://github.com/openvswitch/ovs/commit/18ebd48cfb01ea0e239c6820520a1c57063cc58f
 > >
 > > You seem to contradict your bug description:
 > >
 > > https://bugs.launchpad.net/neutron/+bug/1627987
 > >
 > > can you clarify, how the newly added VIF type can be leveraged?
 > > Perhaps by means of some documentation (or reference to it)?
 > 
 > yes the bus description is the old suggestion, but the ovs
 > community finally went with the
 > 
 > > > (1 comment)
 > > >
 > > > > > > (2 comments)
 > > > > > >
 > > > > > > Is there any agent-side patch required to close the
 > circle?
 > > > > >
 > > > > > The kernel feature is mostly transparent to ovs, you just
 > > plug
 > > > a
 > > > > > 'representor' device passed from nova into the bridge and
 > it
 > > > will
 > > > > > intelligently steer flows between software and hardware
 > > > depending
 > > > > > on hardware capabilities. So there is no need in special
 > > agent
 > > > > > handling.
 > > > >
 > > > > I meant, we'd need to enable a new datapath_type on the agent
 > > > side
 > > > > at least
 > > > There is no new datapath type in this solution  (it is not like
 > > > DPDK). The solution is using the ovs kernel datapath see [1].
 > > >
 > > >
 > > > [1] - https://github.com/openvswitch/ovs/commit/18ebd48cfb01ea0e239c6820520a1c57063cc58f
 > >
 > > You seem to contradict your bug description:
 > >
 > > https://bugs.launchpad.net/neutron/+bug/1627987
 > >
 > > can you clarify, how the newly added VIF type can be leveraged?
 > > Perhaps by means of some documentation (or reference to it)?
 > 
 > yes, so the bug is the old suggestion that was to a new datapath,
 > the ovs community decided to go with a different approach to make
 > it part of the ovs kernel datapath. I will update the bug
 > description. where shall I add the documentation of newly added VIF
 > type and to leverage it?

Ideally that would be in the user doc, perhaps somewhere in [1].

[1] https://docs.openstack.org/ocata/networking-guide/config-sriov.html",748,https://github.com/openvswitch/ovs/commit/18ebd48cfb01ea0e239c6820520a1c57063cc58f,github.com,Code,Clarifying,External,OpenStack592285,20722,"Patch Set 6:

> > Yikun, does this patch fix the concurrency problem you and Kevin
 > were seeing on the multi-cell instance list benchmarks?
 > 
 > My understanding is another patch would be needed on top to monkey
 > patch the time module


Actually this patch, already fix the problem:

eventlet.monkey_patch(os=False, thread=False)

equals to:

eventlet.monkey_patch(builtins=False, socket=True,thread=False,
subprocess=True,MySQLdb=False,psycopg=True,time=True,os=False,select=True)

The ""time"" flag is True, if we don't set any Flag as True.[1]

The problem is that we didn't enable monkey_patch in uwsgi, so I enable it in [2].


[1] https://github.com/eventlet/eventlet/blob/af407c77f208ceefe5a35e39aed0cf3fdfc07cb9/eventlet/patcher.py#L255
[2] https://review.openstack.org/#/c/592285/6/nova/api/openstack/wsgi_app.py@32",20722,https://github.com/eventlet/eventlet/blob/af407c77f208ceefe5a35e39aed0cf3fdfc07cb9/eventlet/patcher.py#L255,github.com,Code,Clarifying,External,OpenStack408668,2750,"Patch Set 1:

Also, strangely, that -9 is the regular UNIX signal SIGKILL.  The 
negative sign is coming from the Python 'subprocess' module (as pointed by Stefan Hajnoczi on QEMU IRC).

https://github.com/python/cpython/blob/master/Lib/subprocess.py#L73,L77

From  __str__():

        [...]
        if self.returncode and self.returncode < 0:
            try:
                return ""Command '%s' died with %r."" % ( 
                       self.cmd, signal.Signals(-self.returncode))

        [...]

From the _handle_exitstatus() method, Python is using it's own encoding:

        [...]
            if _WIFSIGNALED(sts):
                self.returncode = -_WTERMSIG(sts)
                
        [...]",6962,https://github.com/python/cpython/blob/master/Lib/subprocess.py#L73,github.com,Code,Clarifying,External,OpenStack301747,21228,"Patch Set 8:

>Neutron is not into RFC protocol implementation. Underlying tools should be extended to support what you may need here. Any reason not to contribute the feature there
>Right. Which is why I am asking if anyone has discussed adding support for it, rather than having code in Neutron for it.

Here's explanation, why it's not already implemented in dhcp_release
http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2013q2/007084.html

As dhcp_release can not be easily extended, (because of both  code structure and protocol differences, it's much simpler to write a separate utilty for that. And if this utility is in neutron, it's more convenient to plan releases, since there's no need to wait until it will be implemented in dnsmasq.",21228,http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2013q2/007084.html,lists.thekelleys.org.uk,Communication channel,Clarifying,External,OpenStack61310,6463,"Patch Set 6: I would prefer that you didn't merge this

Turns out this is a bug in the libvirt interface library that has been fix in the upstream library (check out the email thread at https://www.redhat.com/archives/libvir-list/2013-November/msg00967.html ).  Rather than putting in special case code that will quickly be unneeded I think it makes more sense to either run the fixed version of libvirt or an older version that doesn't have the baselineCPU enhancement at all.",1981,https://www.redhat.com/archives/libvir-list/2013-November/msg00967.html,www.redhat.com,Communication channel,Clarifying,External,OpenStack18163,2271,"Patch Set 1: Looks good to me, but someone else must approve

I wasn't sure about this one as
losetup --find should find a free device atomically.

However there is still the issue of processes
competing for limited loop devices (my kernel
defaults to making 8 available), so retry with
a delay could alleviate this contention.

BTW what year is this? I thought this silly max_loop
limitation was removed years ago...
https://lkml.org/lkml/2007/3/31/126
So it's not set to 8 explicitly on my system
  # cat /sys/module/loop/parameters/max_loop
  0
  # echo 100 > /sys/module/loop/parameters/max_loop 
  -bash: /sys/module/loop/parameters/max_loop: Permission denied
Oh looking at the code I have to explicitly create device nodes, and then the kernel should auto accommodate that.
Quite klunky. So on Fedora/RHEL6 I'd have to do this
to create 256 loop devices: MAKEDEV -v /dev/loop
That would need to be put in rc.local for persistence.

It would be worth mentioning in a comment in the loop
code, that limited loop devices is the reason for retries,
and that increasing the number of available loop devices
will help mitigate the issue (in addition to retrying).

Somewhat related to losetup and retries,
I notice that on some kernels, losetup -d
will intermittently fail, thus leaking a precious
loop device unless the losetup -d is retired:
https://lkml.org/lkml/2012/9/28/62",1812,https://lkml.org/lkml/2012/9/28/62,lkml.org,Communication channel,Clarifying,External,OpenStack70776,8910,"Patch Set 1: I would prefer that you didn't merge this

I think this is the wrong architectural approach.

SPICE has the ability to transport arbitrary QEMU character devices over its data stream. ie you can connect QEMU serial ports to the SPICE service. The SPICE client can then access the data stream associated with the serial device with bi-directional I/O supported. Now SPICE is traditionally thought of as a GUI system, but that is by convention only - the core protocol allows you to create a plain client that only uses text based console streams, and ignores the GUI display part. The fat client library for spice is actually split into GObject and GTK parts specifically to allow this.

The QEMU server side already exists

  http://lists.freedesktop.org/archives/spice-devel/2014-January/015919.html

The libvirt config part is being developed and nearing completion

  https://www.redhat.com/archives/libvir-list/2014-February/msg00487.html

That leaves the SPICE HTML5 client work as the only remaining piece blocking openstack usage, and optionally a SPICE fat client if we need one.

The advantages of doing this in SPICE are multiple

- OpenStack merely has to configure the serial port to use SPICE. No major new infrastructure or many 1000's of lines of code to support, as this change is proposing

- No extra services for an administrator deploying openstack to deal with 

- Consistent end user experience - the one client gives them access to all resources associated with their VM - its graphical display, sound card output/input, USB device redirection, smartcard integration, and serial ports.


One might be tempted to say we should support both at the same time, but I don't think that's a good idea. For a start we still have the downsides mentioned above - 1000's more lines of code to support, new services for admins to deal with. Second, you can only configure QEMU serial ports to have one backend. If we use SPICE, then there's no way for this proposed text console service to use the QEMU serial port. If we use this new serial service, then you're preventing SPICE from offering a seemless experience across all VM resources.

In summary, IMHO, we should exclusively use SPICE for text serial console, not spend effort writing & maintaining a load of new code",1779,https://www.redhat.com/archives/libvir-list/2014-February/msg00487.html,www.redhat.com,Communication channel,Clarifying,External,OpenStack39927,1528,"Patch Set 3:

Yes, unfortunately unless qemu-nbd can be made to detect timeouts / collisions itself, all bets are off.

http://lkml.indiana.edu/hypermail/linux/kernel/0612.1/0733.html

""""""And BTW that /sys/ thingie is racy by design (as is the log file). By
the time you try to do anything with that PID, process may be gone.""""""",1528,http://lkml.indiana.edu/hypermail/linux/kernel/0612.1/0733.html,lkml.indiana.edu,Communication channel,Clarifying,External,OpenStack483565,7,"Patch Set 4:

gibi and I talked about this and decided the best thing to do was let this through and fix it in a follow up. He's making a bug.

The effect of the error (when it happens) is the desired behavior (there's no where to put the host so you don't get to put it). But it isn't doing so in planned elegance.

More in IRC: http://p.anticdent.org/116n",11564,http://p.anticdent.org/116n,p.anticdent.org,Communication channel,Clarifying,External,OpenStack22628,475,"Patch Set 1:

Mike Bayer (author of SA) gave a helpful explanation of why drop index is behaving this way: https://groups.google.com/forum/?fromgroups=#!topic/sqlalchemy/as8aNff6A-o

TL;DR: SQLAlchemy-migrate wrongly treats the Metadata object as something which can be used to alter the database. It's really intended to be built-up (added to), and then emitted once.

TL;DR of the TL;DR: Switch to Alembic for H :-)",475,https://groups.google.com/forum/?fromgroups=#!topic/sqlalchemy/as8aNff6A-o,groups.google.com,Forum thread,Clarifying,External,OpenStack125963,8582,"Patch Set 2:

There was an issue with my code above - the rbd snapshot of the ephemeral disk needs a distinctive name as well, so glance can distinguish it from a parent of a clone from another source:

https://github.com/jdurgin/nova/commits/rbd-ephemeral-snapshot-icehouse",1107,https://github.com/jdurgin/nova/commits/rbd-ephemeral-snapshot-icehouse,github.com,Github activity,Clarifying,External,OpenStack309613,21309,"Patch Set 5:

Also when multipath is not enabled, and fc volume and iscsi volumes are attached to an instance, there is a duplicate entry for FC volume with same NSP.
As in link http://imgur.com/YsRVL8S",21462,http://imgur.com/YsRVL8S,imgur.com,Media,Clarifying,External,OpenStack663607,6737,"Patch Set 1:

as an aside, i just tested this patch in a local deployment and it isnt actually sufficient to resolve the problem because the value stored by glance is also invalid - https://pastebin.ubuntu.com/p/mj9gFpSBMv/

i'll have a look see if i can get the glance value stripped of invalid characters when doing the comparison but otherwise ill have to patch glance as well.",6737,https://pastebin.ubuntu.com/p/mj9gFpSBMv/,pastebin.ubuntu.com,Memo,Clarifying,External,OpenStack149261,6072,"Patch Set 11:

If you prove the 'FOR UPDATE' is not good here you also prove the DB is NOT ACID, and you prove your solution does not works as well.

Your solution is also based on a write intent lock and serialization, two process can SUCCEED at UPDATE time, so both can think they can commit.
The replication is row based (not statement or mixed). The other nodes will not know what was the WHERE part of your UPDATE.

When a DB node realise he needs to modify a ROW which is locked on the local node but, he got from remotely, he simply just drop the related local transaction.

http://www.percona.com/files/presentations/percona-live/nyc-2012/PLNY12-galera-cluster-best-practices.pdf  read the slide 23.

""If two transactions modify same row on
different nodes at the same time, one of
the transactions must abort""

As I remember I sent an example to the ML.",5803,http://www.percona.com/files/presentations/percona-live/nyc-2012/PLNY12-galera-cluster-best-practices.pdf,www.percona.com,Organization homepage,Clarifying,External,OpenStack82676,2035,"Patch Set 1:

gongysh: As per the bug description, it's a project file used by the rope refactoring library.  It integrates with emacs/vim/etc and provides features like automated refactoring and source navigation (jump-to-definition) for python. 

See: http://rope.sourceforge.net/",2035,http://rope.sourceforge.net/,rope.sourceforge.net,Others,Clarifying,External,OpenStack550173,15334,"Patch Set 4: Code-Review-1

As discussed this needs to wait until the underlying distros update novnc to >=1.0.0 that hasn't happened yet AFAIK, for example Fedora is still using v0.6.1: https://src.fedoraproject.org/rpms/novnc/blob/f28/f/sources",10135,https://src.fedoraproject.org/rpms/novnc/blob/f28/f/sources,src.fedoraproject.org,Others,Clarifying,External,OpenStack65267,6167,"Patch Set 32:

@sahid,

AFAICT the signature has not changed. it's either present or not. The hasattr should hold and work with the real libvirt.virConnect so we should be good. If we fake it then we may not know if/when it breaks :) 

http://libvirt.org/git/?p=libvirt-python.git;a=commitdiff;h=ac532dd37dcca7f7b43dda56516aa39a69b3401c
http://libvirt.org/git/?p=libvirt-python.git;a=blob;f=libvirt-override-virConnect.py;h=c228eb278cb68197650bdd3cb9796beddd702283;hb=HEAD#l348

def registerCloseCallback(self, cb, opaque):",5638,http://libvirt.org/git/?p=libvirt-python.git,libvirt.org,Others,Clarifying,External,OpenStack68142,7141,"Patch Set 28:

@Gary: We use the virtual_ipaddress_excluded feature to solve this exact issue: http://serverfault.com/questions/334197/keepalived-for-more-than-20-virtual-addresses",8873,http://serverfault.com/questions/334197/keepalived-for-more-than-20-virtual-addresses,serverfault.com,Q&A thread,Clarifying,External,OpenStack216085,13203,"Patch Set 29: Code-Review-1

Looks like the conversion back to plaintext fails with python 3.

Also, I'd like to see an explicit answer to Wang Haomeng's question.  A number of us raised a similar concern in
earlier patches.  Is there a reason why one-way encryption
of the sort he mentions could not be used instead of the
unsafe base64 encode?

I don't think we really want to be setting the precedent
in official, in-tree OpenStack code of offering a false sense of security to the cloud administrator, which IMO
is much worse than just showing plaintext since we all
know that base64 encoding is trivially reversible.

https://www.sans.org/reading-room/whitepapers/detection/base64-pwned-33759",9003,https://www.sans.org/reading-room/whitepapers/detection/base64-pwned-33759,www.sans.org,Software homepage,Clarifying,External,OpenStack160458,7987,"Patch Set 1:

@Ihar
We do have a plan for splitting. There's a Stackforge project with all the Cisco drivers [0]. The APIC driver is already part of it, at this time we are verifying that everything works so that we can proceed to the actual split by Kilo time frame.

[0] https://github.com/stackforge/networking-cisco/",7987,https://github.com/stackforge/networking-cisco/,github.com,Software homepage,Clarifying,External,OpenStack545476,5196,"Patch Set 1:

lol, so after a lot of digging and adding a bunch of print statements to the code, I figured out that '--group-regex=nova\\.tests\\.functional\\.api\\.openstack\\.placement\\.test_placement_api(?:\\.|_)([^_]+)' was being treated as a regex in the functional jobs. This is because the cli argument is 'group_regex' not 'group-regex' in stestr<=1.1.0. This has been fixed in stestr master with: https://github.com/mtreinish/stestr/commit/93500d00422ba8d7ad93d8fcf5b2e06ea4963cbe There should be a release which will include that soon, I just have one last feature to land and then some prerelease testing before pushing it out. But in the mean time we can just fix the argument to be the correct one to get around this.

The reason this works with the quotes in the current definition is because '' is being passed in if there are no posargs provided and regexes are OR'ed for matches. So there was a regex that matched everything and a regex which matched none meaning the union of those sets is everything. The interesting thing this points out is that the group_regex does nothing today, and yet the functional tests still worked without any issues. I wonder if we really need it anymore. But that's something we can investigate in the future (and we'll need to ask cdent about too)",5196,https://github.com/mtreinish/stestr/commit/93500d00422ba8d7ad93d8fcf5b2e06ea4963cbe,github.com,Software homepage,Clarifying,External,OpenStack48475,7817,"Patch Set 3:

I'd like to understand how including ordereddict affects peoples ability to install glance on distros such as Debian/Ubuntu which do not currently package it.

http://packages.ubuntu.com/search?suite=all&section=all&arch=any&keywords=ordereddict&searchon=names

Is it the case that a new ordereddict package will be created for those distros?

If not, how will it be possible to install glance on Debian/Ubuntu?

Thanks.",455,http://packages.ubuntu.com/search?suite=all&section=all&arch=any&keywords=ordereddict&searchon=names,packages.ubuntu.com,Software homepage,Clarifying,External,OpenStack94114,9608,"Patch Set 2:

# flake8: noqa or # noqa would work for me, but if I read this correctly https://pypi.python.org/pypi/flake8 those are implemented at flake8 version 2.1. It looks like we pull in 2.0:
pip show flake8 
---
Name: flake8
Version: 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: setuptools, pyflakes, pep8, mccabe",5202,https://pypi.python.org/pypi/flake8,pypi.python.org,Software homepage,Clarifying,External,OpenStack68056,8996,"Patch Set 3: Abandoned

@David Yes I'm sure the default value of sitepackages is False:

http://tox.readthedocs.org/en/0.9/config.html

@Joe I agree. Patch shall be abandonned until libvirt issue is solved.",8996,http://tox.readthedocs.org/en/0.9/config.html,tox.readthedocs.org,Specification,Clarifying,External,OpenStack633855,2394,"Patch Set 5: Workflow-1

Turns out that the Python binding for virConnectGetDomainCapabilities() requires all 5 arguments described at

https://libvirt.org/html/libvirt-libvirt-domain.html#virConnectGetDomainCapabilities

so this is not quite right yet.  I'm discussing with Kashyap how best to fix.",2394,https://libvirt.org/html/libvirt-libvirt-domain.html#virConnectGetDomainCapabilities,libvirt.org,Specification,Clarifying,External,OpenStack319444,9970,"Patch Set 2: Code-Review-1

I understand this issue is Diamond Problem about Python. I can see the same discussion in stackoverflow[1]. I don't want to agree this fix because it can happen again in other place. In this fix, NeutronDbPluginV2 self doesn't need to have super() because his all ancestor classes don't have __init__() which have to be called. The issue depends on MRO of class calls NeutronDbPluginV2. Therefore, we basically have to try to reduce issues like Diamond Problem rather than adding super() as workaround.

[1]: http://stackoverflow.com/questions/3277367/how-does-pythons-super-work-with-multiple-inheritance",7715,http://stackoverflow.com/questions/3277367/how-does-pythons-super-work-with-multiple-inheritance,stackoverflow.com,Stack Overflow,Clarifying,External,OpenStack460524,6579,"Patch Set 14:

Rodolfo,

why do you think other_config should be used?

while i agree using external_ids for this stuff is awkward,
it's at least safer than other_config as it won't be interpreted by the switch.
http://docs.openvswitch.org/en/latest/topics/integration/

anyway, my suggestion is to consult ovs folks.",6854,http://docs.openvswitch.org/en/latest/topics/integration/,docs.openvswitch.org,Tutorial or article,Clarifying,External,OpenStack222079,7787,"Patch Set 11:

> This means we have to query all of the RBAC tables via a big UNION query. 

so that is exactly the case *for* joined inheritance, when you want to query polymorphically which it seems is the case here.

> However, this API will be hit much less frequently than queries to the ports, networks, etc so it's probably not worth the performance penalty you are implying.


well if the queries for Port, Network etc. tend to be very simple lookups of one item, that wouldn't be too bad.  Things get crazy with joined inh if you have a lot of joined-eager loads from some parent object to say a Network collection. 

> For example, we are talking about adding tags to core resources. If we don't have a table like this we will need to add a tags table for every type of object that can be tagged.

So this is the polymorphic association pattern which I've written about for a long time; there's a suite illustrating all the different approaches to this at http://docs.sqlalchemy.org/en/rel_1_0/orm/examples.html#module-examples.generic_associations.   For this case, it again depends on if you need to query for all NeutronResource objects with a certain set of tags (e.g. a query that would return a combination of types) or not.   If you didn't, then yes I do recommend having an association table per type.",11816,http://docs.sqlalchemy.org/en/rel_1_0/orm/examples.html#module-examples.generic_associations,docs.sqlalchemy.org,Tutorial or article,Clarifying,External,OpenStack42695,7996,"Patch Set 1:

It is always tricky drawing the line for what should go into the .gitignore I checked a couple of other widely used python projects and most do not carve out specific exceptions for OS or dev environment files.  Instead this should really be handled on a global level the environment via a global ignore file. (https://help.github.com/articles/ignoring-files)",2592,https://help.github.com/articles/ignoring-files,help.github.com,Tutorial or article,Clarifying,External,OpenStack134592,8543,"Patch Set 3:

Looking at the iSCSI specs: http://www.ietf.org/rfc/rfc3720.txt

Section 8.2.1

""Implementations MUST support use of up to 128 bit random CHAP secrets""

Implementations MIGHT go beyond that (16 bytes), but IMO Cinder should stick with the RFC standard limits that every implementation must support.",3185,http://www.ietf.org/rfc/rfc3720.txt,www.ietf.org,Tutorial or article,Clarifying,External,OpenStack129288,6072,"Patch Set 5:

Just to repeat what I've sent to ML: default isolation level in postgres guarantees the same as READ COMMITTED in mysql, per documentation (see 13.2.1): 
http://www.postgresql.org/docs/9.1/static/transaction-iso.html

Splitting the logic into different transactions means all kinds of race conditions because the atomicity of operations will be lost.
Not to say complexity of doing rollback/cleanup increases dramatically. While in theory it's possible to do so, it basically means rewrite whole neutron core logic from scratch.

So I think we need to consider moving to different tx isolation level, especially because it's been already there for postgres.",6072,http://www.postgresql.org/docs/9.1/static/transaction-iso.html,www.postgresql.org,Tutorial or article,Clarifying,External,OpenStack172040,6773,"Patch Set 1:

Hi Sean,

Yeah, the tag won't interfere if they don't use it. But I suspect that someone using iPXE/gPXE would benefit from this tag, this is a pretty common setup for dnsmasq + iPXE.

You can google it, here's some real examples:

- http://www.richud.com/wiki/Network_iPXE_dnsmasq_Examples_PXE_BOOT#dnsmasq.conf_real_DHCP_server 

- http://lordsith.net/blog/deploying-ipxe-server-in-a-smartos-zone/

You will find a variation of names for this tag, gpxe or ipxe. That's because gpxe is deprecated since 2010 and ipxe is the project being maintained now[1]

So the tag should be created before setting the extra_dhcp_opts, I don't know if you can create it there (I think you can not :-/, I'll take a better look into it)

Yeah, we could potentially make neutron look for this tag and if it's set in the dhcp extra opts it would the DHCP agent with it. It sounds a bit overcomplex, but is a possibility. 

[1] http://ipxe.org/faq#fnt__1",6773,http://www.richud.com/wiki/Network_iPXE_dnsmasq_Examples_PXE_BOOT#dnsmasq.conf_real_DHCP_server,www.richud.com,Tutorial or article,Clarifying,External,OpenStack163033,9311,"Patch Set 2:

@Nova-core, please confirm that there are no other console type...

According to https://tools.ietf.org/html/rfc6455#section-10.1, if Origin is missing (e.g. connection coming from an about out-of-browser client) then we could skip the origin test entirely.",9311,https://tools.ietf.org/html/rfc6455#section-10.1,tools.ietf.org,Tutorial or article,Clarifying,External,OpenStack72637,7703,"Patch Set 10:

Hi garyk,

Thanks for reviewing the patch. Saw your inline comments. 

Those brackets were for wrapping the long message line. Preffered using brackets to avoid backslash as defined here.

http://legacy.python.org/dev/peps/pep-0008/#maximum-line-length

If the brackets doesn't look better, I can go ahead and change them to use backslash instead.

Please let me know your thoughts?",7703,http://legacy.python.org/dev/peps/pep-0008/#maximum-line-length,legacy.python.org,Tutorial or article,Clarifying,External,OpenStack329149,11564,"Patch Set 35:

(1 comment)

> Could you, please, explain a little how gabbi
 > works? I see it uses http client and somewhere in
 > the tests server should start I can't find this place.

Would you like this in the commit message or code or is this for the sake of discussion in the comments?

In the context used here, where the gabbi tests are run under tox+testr, the tests are created by the build_tests method in the test_placement_api.py file. The placement-api server itself is not started as an external process. Instead wsgi-intercept[1] is used to run the WSGI application that provides the API in the same process. The function that provides that application is defined by the intercept parameter to build_tests. That WSGI application is instantiated per yaml file. Meanwhile the APIFixture that is listed as a fixture in each yaml file sets up (and tears down) the database and other backend fixtures that are required for the wsgi application to operate.

[1] http://wsgi-intercept.readthedocs.io/en/latest/",11564,http://wsgi-intercept.readthedocs.io/en/latest/,wsgi-intercept.readthedocs.io,Tutorial or article,Clarifying,External,OpenStack263432,1247,"Patch Set 4: Code-Review+1

Just a convenient note, in case anyone reviewing is wondering what 'direct' means in comparison to 'peer-to-peer' migration.  Summarizing from here[1]:

  - 'direct': libvirt client process (libvirt.so) controls different
    phases of live migration
  - 'peer-to-peer': the source libvirt daemon controls the 
    entire migration process, by directly connecting to 
    the destination host

[1] https://libvirt.org/migration.html",6962,https://libvirt.org/migration.html,libvirt.org,Tutorial or article,Clarifying,External,OpenStack410106,15905,"Patch Set 2:

> Glance RC-1 is released, this can proceed.
 > 
 > Please explain why the utf-8 encoding is unnecessary and why it
 > shouldn't be applied to the rest of the codebase in your commit
 > message. You've only explained the *what*, not the *why*.

I don't have a strong reason for that.
As per PEP 263, a Python file with non-ASCII characters must have a line with ""coding: <some-encoding>"". Python files containing only 7-bit ASCII characters need no such line.[1][2]

In other word, Each project has its preference regards to this. I think it is fine to remove the utf-8 tags.

[1] https://www.python.org/dev/peps/pep-0263/
[2] https://review.openstack.org/#/c/95865/",15905,https://www.python.org/dev/peps/pep-0263/,www.python.org,Tutorial or article,Clarifying,External,OpenStack45298,4393,"Patch Set 2:

The whole point of safe_encode() is to never return a unicode type. It always returns a str type encoded in utf-8.

Ultimately we want to keep all strings as the unicode type internally to Nova. Keeping a string encoded as a str type will lead to lots of confusion of what encoding it is, when it is encoded, etc.

If the transport needs an encoded str type (as opposed to a unicode type), then we should strive to make this as transparent as possible.

It looks to me right now that the sending side will see a unicode type but then the receiving side will see a str type encoded with utf-8. This is because the string appears to only ever be encoded but never decoded back to a unicode type.

Here's a good reference on why we should strive to use a unicode type internally as much as possible:
http://nedbatchelder.com/text/unipain.html

Your patch is a net improvement over the previous change since it fixes up the versioning issues and makes sure all other uses also get encoded, but the fact there is no decoding will likely lead to problems.",100,http://nedbatchelder.com/text/unipain.html,nedbatchelder.com,Tutorial or article,Clarifying,External,OpenStack115582,91,"Patch Set 4:

Hi Dan, thanks for your comments.

I agree with the packaging stuff, but there are other issues here:

1. As per [*] I understand that the libvirt XML expects a bootloader. Currently OpenStack generated libvirt.xml file lacks it, but if it is expected we should generate it.

2. libvirt is setting the bootloader to a full path ""/usr/bin/pygrub"", but this is deprecated [**], the warning below is shown in the logs. IMHO this should be solved in libvirt [***], because of the deprecation warning.
  
    libxl: warning: libxl_bootloader.c:413:bootloader_disk_attached_cb: bootloader='/usr/bin/pygrub' is deprecated; use bootloader='pygrub' instead

3. pygrub, that is the default bootloader, does not support Qcow2 disks. pvgrub does, but it is not possible to tell libvirt to use it (via OpenStack or via some libvirt config). Even if I would be able to force configure Xen to use pvgrub, libvirt will overwrite it to ""/usr/bin/pygrub"".

Currently we are stuck using the depreacted xend because of this (2). I
could file a bug to Debian and Ubuntu saying that they should install pygrub in
its standard location, but this just solves (2), but no (3). For instance we want
to start working on the testing of the CoW support using Xen+libvirt, but we
cannot start because of this.

How could I as an operator tell that I want to use pvgrub instead of pygrub, if
I am not able to specify this in libvirt or OpenStack?

[*] https://www.redhat.com/archives/libvir-list/2014-August/msg00804.html
[**] http://wiki.xen.org/wiki/PyGrub
[***] https://bugzilla.redhat.com/show_bug.cgi?id=1104695",91,http://wiki.xen.org/wiki/PyGrub,wiki.xen.org,Tutorial or article,Clarifying,External,OpenStack633869,9531,"Patch Set 4:

> I'm reintroducing my -1 because I don't think that you gave
 > sufficient thought to what I was saying.
 > 
 > This new configuration option is a classic example of:
 > https://assafmuller.com/2017/05/19/when-is-not-cool-to-add-a-new-openstack-configuration-option/
 > 
 > We should not add it. We should instead calculate a better value.

Configuration is better than hard coding in most cases, right? Firstly we are impoving the original code here. And I don't think this new option is fully match your blog categories. We do not add or change the driver or architecture here. And this configuration is as simple as enough, users can understand it (maybe I should expand the notes a little more for it). For now, the max value 32 have tested in our local environment. Operators may not be aware of this new option, until their deployment meet the large scale issue or starting storm problem in a very rare case of DVR (plz see the commit message). Then they must take responsibility to learn this new option, and test the value for their own scale and operating pressure. We do not introduce too much head-breaking option for operators. It is very easy to test.

For now I do not change this to calculate the value is because , IMO, it now meets the most zen of the python:
https://www.python.org/dev/peps/pep-0020/
LOL, : )

Furthermore, the community cannot measure the user deployments and make the choice for them. There are so many composite scenario. Community developers can not learn or test all the cases, but they can narrow down the influences of a new configuration, yeah, which is this patch doing now. And this problem is something like the bug, maybe you can say your code does not bring a bug, but there are new bugs coming out one by one.",9531,https://www.python.org/dev/peps/pep-0020/,www.python.org,Tutorial or article,Clarifying,External,OpenStack46184,7629,"Patch Set 3:

Hi Dan,

See: http://en.wikipedia.org/wiki/Zombie_process

So basically, this set of tests hits that ""zombie"" problem pretty frequently. The way I've written the loop in this patch, we keep polling the pid until we get specifically err.errno == errno.ESRCH which is only thrown as an exception when the process is not found in the process table.

That basically does the job of not only waiting on the process to exit... but also for it to be reaped.

in short: waiting is semantically correct but not enough.",7629,http://en.wikipedia.org/wiki/Zombie_process,en.wikipedia.org,Tutorial or article,Clarifying,External,OpenStack149261,6072,"Patch Set 11:

1.
""lock free"" approach is not lock free. In our context it just means it does not do `Distributed Locking` at DML or SELECT FOR update.

If you read the article, you see most example about `user locks` on a web interface.
The criticized data-base example which does a ""Before committing, each transaction verifies that no other transaction has modified the data it has read"", requires to use some kind of Atomic Consistent synchronization primitive, which usually much-much cheaper lock type compered to the `distributed ones`: For example Atomic cache consistent 'test and set' or 'check and swap' with memory fencing.

What galena actual does is something different, it looks like an a variant of an Optimized Multi-Paxos which can be considered as `distributed lock` on steroids.
Its synchronization granularity seams GLOBAL, but if the changes(proposals) arrives in the right order from the same proposer, galere MAY do additional tricks.

""If two processes believe they are leaders, they may stall the protocol by continuously proposing conflicting updates.""

http://en.wikipedia.org/wiki/Paxos_%28computer_science%29
This does not necessarily leads to a ROLLBACK it can be a retry-able issue on the DB side.

Locally galera respects all write intent DB locks.

2. As I described  what we all know: the FOR UPDATE does not do 
causes any kind of slow `distributed lock`.
What the FOR UPDATE causes: It puts a write inter _cheap_ lock to the same row as the UPDATE. It is not double locking, the UPDATE statement needs the exact same row.

If the given writer recives a conflicting COMMIT between the SELECT and UPDATE it will automatically ROLLBACK the transaction. (now you rise an exception, which is a manual ROLLBACK)
You does the same thing as FOR UPDATE and writing extra code for that.

If by accident the clients are connected to the same writer, you avoided a ROLLBACK.

The above proposal 2 connection select advice was about mitigating the `random ROLLBACK` effect.

Just dealing with a DBDeadlock exception leads to simpler code, because you need to handle this anyway when the conflicting change arrives after the real UPDATE statement.

Just some rhetorical question:
What do you think how small is the time between the SELECT+UPDATE ?
What do you think how much time we spend in a _bulk_ 2 net allocation ?
What do you think how many network create actually needs to happen per/sec in a system?
What is the chance for two client connected to the same node and the 'FOR UPDATE' actually save us from a random ROLLBACK? (This seams easy :))",5803,http://en.wikipedia.org/wiki/Paxos_%28computer_science%29,en.wikipedia.org,Tutorial or article,Clarifying,External,OpenStack18476,1082,"Patch Set 2: I would prefer that you didn't merge this

I'm confused by b) in the commit message. Specifically ""For reference, current keys are:
       files uuid availability_zone hostname meta public_keys name"".

Our documentation would seem to suggest otherwise:

http://docs.openstack.org/folsom/openstack-compute/admin/content/metadata-service.html

Note this example:

$ curl http://169.254.169.254/2009-04-04/meta-data/public-keys/
0=mykey

---

Also, the docs from EC2 seem to show dashes are the preferred way the EC2 metadata keys are accessed:

http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html",360,http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html,docs.aws.amazon.com,Tutorial or article,Clarifying,External,OpenStack37421,6549,"Patch Set 4:

Now I'm not saying that the logging module is perfect, but it can handle unicode just fine. It does need a little bit of help in some cases (mostly because of Python 2).

Your latest example shows exactly why you should be decoding strings early (you are using an encoded string in the exception).

You really want to keep ""strings"" internally in the unicode type if they can contain anything more than ASCII characters.

The reasons behind this are:
1) You never know what the user will want the output to be. Assuming utf-8 will disappoint anyone who doesn't use utf-8. The only safe thing to do is keep the string in a ""normalized"" format and then encode as late as possible where the code that finally outputs the string *does* know what the user wants
2) In python 3, str() is actually unicode() (for exactly the same reasons you should be using unicode() in python 2). Keeping everything in unicode() type is forward compatible with python 3, but encoding to utf-8 early isn't.

So why not use utf-8 as the normalized format internally? Because we already have the unicode() type that is specifically for this purpose plus it has a lot of extra functionality to makes code easier to write.

Here's yet another article that explains a lot of the reasons why you should decode early and encode late (as well as common frustrations with unicode in Python 2):

http://pythonhosted.org/kitchen/unicode-frustrations.html

And if you're looking for a code example for my utf-16 thought experiment:

    import codecs
    import logging
    class FileHandler(logging.StreamHandler):
        def __init__(self, filename, encoding):
            logging.StreamHandler.__init__(self)
            self.file = codecs.open(filename, mode='a', encoding=encoding)
        def emit(self, record):
            msg = self.format(record)
            print >>self.file, msg
    logger = logging.getLogger('')
    formatter = logging.Formatter(u'%(foo)s %(message)s')
    #formatter = logging.Formatter('%(foo)s %(message)s')
    terminal = logging.StreamHandler()
    terminal.setFormatter(formatter)
    logger.addHandler(terminal)
    logfile = FileHandler('utf-16.log', 'utf-16')
    logfile.setFormatter(formatter)
    logger.addHandler(logfile)
    logger.error('test', extra={'foo': u'\u2022'})          # Succeeds
    logger.error('test', extra={'foo': u'\u2022'.encode('utf-8')})  # FAIL

In this example there are two handlers being written to for every log line. The first is a normal StreamHandler for sys.stderr which will encode to whatever your terminal is (usually utf-8).

The second is a simple handler to write to a utf-16 encoded log file.

So to summarize, not only is the original version of this patch smaller, it's also easier to use, doesn't make assumptions about what the user wants and is also forward compatible with Python 3.",100,http://pythonhosted.org/kitchen/unicode-frustrations.html,pythonhosted.org,Tutorial or article,Clarifying,External,OpenStack19842,6661,"Patch Set 6:

Hi Vish, 

The large URI is from encoding a large user-data blob.

The EC2 API specifies that one can use either GET or POST:
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-query-api.html

Note that all the EC2 examples given use GET (so it's not surprising that many client tools do, too).  The client tools succeed on EC2 and Nimbus (http://bugzilla.mcs.anl.gov/bugzilla/show_bug.cgi?id=6992) but not nova.  

As far as I can tell from the nova code, it doesn't discriminate GET or POST but just parses the request and renders a response. Given that the API explicitly says either GET or POST is acceptable, I think that keeping the default at 8k and letting the admin configure it as needed is reasonable.

I'll resubmit this patch with the 8k default.",6661,http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-query-api.html,docs.aws.amazon.com,Tutorial or article,Clarifying,External,OpenStack99370,9555,"Patch Set 3:

@Chris Behrens: https://docs.python.org/2/library/logging.html",9555,https://docs.python.org/2/library/logging.html,docs.python.org,API documentation,Elaborating,External,OpenStack314054,19554,"Patch Set 7:

well, there is a way (maybe) to backport a cheap version of && that works here to EXCLUDE.  I've gotten almost all of it working except we need to create a GIST operator class for it (see http://www.postgresql.org/docs/9.2/static/sql-createopclass.html) and that is an enormous ordeal.   You can see how far I've gotten though where I've successfully created a && operator that does CIDR overlap: https://gist.github.com/zzzeek/46fe8db01d597b2ec92424956b0ebb50 .

But making the GIST operator class is a huge PITA.  If you want to try it, that's one thing.  Or we can try to see if having this feature only available for 9.4.   but EXCLUDE USING still looks promising.",11816,http://www.postgresql.org/docs/9.2/static/sql-createopclass.html,www.postgresql.org,API documentation,Elaborating,External,OpenStack149625,8802,"Patch Set 17:

(1 comment)

@sdague i don't really see what you are objecting to here - we depend on plenty of external libraries which we don't control, a number of them backed by C libraries too. The python exposed API is documented here http://lazka.github.io/pgi-docs/#Libosinfo-1.0",1779,http://lazka.github.io/pgi-docs/#Libosinfo-1.0,lazka.github.io,API documentation,Elaborating,External,OpenStack149625,8802,"Patch Set 17: Code-Review-1

(1 comment)

Honestly, this is a place where I think it would be good to consider our own low level nova library to use this code, and put all the libosinfo interactions in there. I really don't like us owning the reflection directly in Nova so tightly coupled to a C lib we don't own. 

Especially when links like https://libosinfo.org/api/ are a 404 (followed from the home page)",2750,https://libosinfo.org/api/,libosinfo.org,API documentation,Elaborating,External,OpenStack117442,2813,"Patch Set 32:

FYI, libvirt docs:

https://libvirt.org/formatdomain.html#elementsDisks

The optional io attribute controls specific policies on I/O; qemu guests support ""threads"" and ""native"". Since 0.8.8

So libvirt version-wise this looks OK, but documentation isn't great on when this should be used or not.",6873,https://libvirt.org/formatdomain.html#elementsDisks,libvirt.org,API documentation,Elaborating,External,OpenStack301348,7448,"Patch Set 1:

So just a note on what we think the issue is here.

Assume a multi-node DVR setup, where there is one network node and two compute nodes.  One compute node has a single VM, the other two VMs - one of which has a floating IP assigned.  So each compute node has a VM *without* a floating IP.

With this change, on the compute node with two VMs, if the VM with just a fixed IP communicates with the one with the FIP, the packets will go into the qrouter namespace, trigger both SNAT and DNAT rules, and seem to arrive at the target VM from the default SNAT address.  Return packets will flow back the same way thanks to conntrack, so no packets will ever enter the snat namespace on the network node.

If the other VM, all alone on a compute node, communicates with the FIP of the VM on the other compute node, packets will be forwarded to the network node, where they will go through the snat namespace, where DNAT and SNAT will take place.  Like above, return traffic will flow back via the conntrack entry and snat namespace.

The problem lies in how NAT works.  Since both the qrouter and snat namespaces could be doing NAT, there is no centralized coordination of TCP port usage.  For example, both VMs could have chosen the same source port for the connection, in which case both could pass-through directly, or both NATs could choose to change the source port during translation, having both connection tuples be identical as well since the source IP will have been changed in both cases to the same default SNAT address.

From http://linux.die.net/man/8/iptables :

""--to-source ipaddr[-ipaddr][:port-port]
which can specify a single new source IP address, an inclusive range of IP addresses, and optionally, a port range (which is only valid if the rule also specifies -p tcp or -p udp). If no port range is specified, then source ports below 512 will be mapped to other ports below 512: those between 512 and 1023 inclusive will be mapped to ports below 1024, and other ports will be mapped to 1024 or above. Where possible, no port alteration will occur.""

So when the server process (on the VM with the FIP) replies, where will the packet go?  Most likely all will go to the local VM due to the existence of the conntrack entry.  While this is a rare occurrence, in theory it seems to be possible.

A possible solution to this is to have the NAT code in each namespace specify a port-range to use, such that they don't overlap.  Network node gets most, compute node gets a little.

The other solution is to not optimize the traffic, and send everything through the snat namespace, as is done in https://review.openstack.org/#/c/289172/

Does that seem correct to others?",1131,http://linux.die.net/man/8/iptables,linux.die.net,API documentation,Elaborating,External,OpenStack73386,748,"Patch Set 2: No score

(1 inline comment)

Thanks for the pointer Armando. I learnt something with it :) I am entirely convinced that this change is NOT going to break anything. But, also its a redundant change. All we are doing here is bumping rollback to 1 level up in call stack.

Regarding minimizing time window, I understood that session objects should always be used in a non-concurrent fashion. Document: http://docs.sqlalchemy.org/en/rel_0_7/orm/session.html#thread-local-scope

I dig into the neutron common code and did not find a code where this object is made thread-safe. It would be good if you can point me to one.

Anyways, removing my previous -1.",7962,http://docs.sqlalchemy.org/en/rel_0_7/orm/session.html#thread-local-scope,docs.sqlalchemy.org,API documentation,Elaborating,External,OpenStack292095,8358,"Patch Set 1:

Hi Vincent Hou,
The bug #1550184 only focus that dict_keys' object does not support indexing. Other case '.keys()' are legally in py3.
https://docs.python.org/3/tutorial/datastructures.html#dictionaries
Thank you. :)",8358,https://docs.python.org/3/tutorial/datastructures.html#dictionaries,docs.python.org,API documentation,Elaborating,External,OpenStack149625,8802,"Patch Set 19: Code-Review-1

So, honestly, I started looking into the libosinfo source more, and I think I'm back to a -1. There is a statement about ""let's not duplicate this data"" but one of the things libosinfo does is vendors into its tree 2 public data sets that are doing the right thing, and publishing public data sets - http://www.linux-usb.org/usb.ids and http://pci-ids.ucw.cz/.

The API for accessing this from python is also - http://lazka.github.io/pgi-docs/#Libosinfo-1.0 - which is an automated class dump. There are no examples. All the business logic thus requires reading source code to figure out what even the expected call model is.

I understand the desire to get this kind of info into Nova. I think this should be done with an upstream project that focuses on publishing open data sets for direct consumption by other systems (like the usb id project and pci id projects). I hope that because there is an overlap between folks working on Nova and folks working on this library we could get there. I get that it would be a different model for libosinfo, but it doesn't seem to be against their mission.

Because this is a library, and not a public data set, the upgrade risk for consumers is much higher (debian is still shipping a 2 year old version of this library in ""testing"" for instance, and even older on some other architectures). This data seems like it should be like tzdata and be something that distros refresh the dataset on every commit. It would be great if libosinfo was publishing the dataset on every update like tzdata is. Otherwise we're going to have really uneven, in unexpected ways, behavior based on patch level of base OS.",2750,http://lazka.github.io/pgi-docs/#Libosinfo-1.0,lazka.github.io,API documentation,Elaborating,External,OpenStack285607,7787,"Patch Set 1: Code-Review+2

ahaa!, so that was it, (http://docs.sqlalchemy.org/en/latest/orm/extensions/declarative/api.html ), thanks for digging into it!.",8788,http://docs.sqlalchemy.org/en/latest/orm/extensions/declarative/api.html,docs.sqlalchemy.org,API documentation,Elaborating,External,OpenStack295865,17505,"Patch Set 8:

I brought up that other change in the nova IRC channel today. Just because another change gets in without integration testing doesn't mean it's OK, or everything should. My particular concern is that the hypervisor handles these operations when the guest is in a different state than what we've allowed before.

In https://review.openstack.org/#/c/223382/ Melanie Witt pointed out:

To add some detail, in libvirt, 'nova suspend' does a domain managedSave [1] which saves all memory contents to disk, which seems like it would be safe for creating an image. The 'nova pause' does a domain suspend [2] which freezes the process, not saving anything to disk.

Commit c538024fddc5994afe13f41817b9fe0b8e8f3fdd added SUSPENDED and PAUSED to the allowed states for 'snapshot' and the libvirt driver was updated to handle PAUSED by doing a domain managedSave if the state is PAUSED during the snapshot.

In the case of snapshot of volume-backed, we won't have a managedSave for PAUSED, so PAUSED shouldn't be allowed.

[1] https://libvirt.org/html/libvirt-libvirt-domain.html#virDomainManagedSave

[2] https://libvirt.org/html/libvirt-libvirt-domain.html#virDomainSuspend

--

So the situation with volume-backed vs non-volume-backed WRT snapshot and paused/suspended are different, at least in how the libvirt driver handles them and what happened to the guest when it was paused/suspended.

Since we don't do a managedSave on the guest when doing a snapshot of a volume-backed instance, it's a different scenario. For example, we attempt to queisce the guest before the volume snapshot if it's ACTIVE, should we also be doing that if it's PAUSED?

Anyway, these are my concerns on the change and why I push for integration testing on API changes like this since unit tests aren't going to tell us if the hypervisor is going to handle this operation for a guest in this other state.",6873,https://libvirt.org/html/libvirt-libvirt-domain.html#virDomainManagedSave,libvirt.org,API documentation,Elaborating,External,OpenStack314054,19554,"Patch Set 26:

Thanks for your reply.

> well that's the trick here, the CI jobs need to have superuser which I'm not sure they do (though I'd bet they do).   If neutron upgrades on PG run w/o superuser, that's an issue also.   But openstack needs to be able to use PG extensions like HSTORE and such so there has to be some approach for this kind of thing.

I think Postgresql Heroku can create the HSTORE extension without superuser, right?. I tested on my postgresql, it still need superuser.

> for your local run, the user ""openstack_citest"" needs superuser permission, you can grant that as described at https://www.postgresql.org/docs/9.1/static/sql-alterrole.html.

Yes, I have done that and it was ok.
So regarding your opinion, should I ask the core-reviews about using PG extersion for Openstack? or we can ask the cores of Postgresql that is it possible to add btree_gist as an available extersion? :-). Do you have any suggestion for this patch?

Normally, the user for Neutron just had premision to create DB. So the upgrade process will be failed. I really worry about this.",19554,https://www.postgresql.org/docs/9.1/static/sql-alterrole.html,www.postgresql.org,API documentation,Elaborating,External,OpenStack61610,6593,"Patch Set 1: Looks good to me (core reviewer)

Looks good.  Missed Eric's link and also looked it up:

http://pubs.opengroup.org/onlinepubs/7990989799/xbd/envvar.html",4355,http://pubs.opengroup.org/onlinepubs/7990989799/xbd/envvar.html,pubs.opengroup.org,API documentation,Elaborating,External,OpenStack199297,6873,"Patch Set 2: Code-Review+1

LGTM, just for fun I ran a latex build with this applied using: https://review.openstack.org/199332 and ended up with this:

http://blog.kortar.org/wp-content/uploads/2015/07/Nova3.pdf

~600 pages of apidoc in the output pdf, super useful :)

It also generated a non-fatal error during the latex build about being too deeply nested (somewhere in the apidoc for a the virt layer, it's hard too tell) But that could just be my local env, or more likely another sphinx bug in latex generation. But, it's not like it was fatal, nor does anyone else really care about the latex output from sphinx.",5196,http://blog.kortar.org/wp-content/uploads/2015/07/Nova3.pdf,blog.kortar.org,API documentation,Elaborating,External,OpenStack36603,7593,"Patch Set 13:

Haomai Wang said:

 > Although it seems that the assert statements look well, I 
 > still want to emphasize the way isn't friendly. We should 
 > Consider reason below: 1. Nova is accepting a lot of 
 > patches every day and no one can guarantee that these 
 > assert statements will be destroyed. In a rare case, users 
 > want to see a friendly exception message instead of. 2. 
 > There exists rare cases such as memory corruption 3. 
 > Assert statement isn't accept at product codes

1. doesn't make any sense to me - the fact that we have some many contributors makes the assert I commented on even *more* useful, because it helps developers screw up the logic

As for user friendly exceptions, sure - I agree. Users should never see AssertionError

If you don't want assert statements executed at runtime, make sure to run with python -O - see e.g. http://docs.python.org/2/reference/simple_stmts.html#the-assert-statement",1247,http://docs.python.org/2/reference/simple_stmts.html#the-assert-statement,docs.python.org,API documentation,Elaborating,External,OpenStack231709,8124,"Patch Set 3:

According to python doc[1], universal_newlines=True enforces \n usage as line separator in stdout/stderr ... so nothing related to the change.

I am not sure it's a good idea to use universal_newlines=True as nothing ensures stdout/stderr line separator == os.linesep, it seems safer to use str.splitlines which handles correctly every line separator.

[1] https://docs.python.org/2/glossary.html#term-universal-newlines",8124,https://docs.python.org/2/glossary.html#term-universal-newlines,docs.python.org,API documentation,Clarifying,External,OpenStack387674,18335,"Patch Set 1: Code-Review-1

This is a great start but it needs some test coverage.

A straightforward way to do that would be to add to the gabbi tests in nova/tests/functional/api/openstack/placement/gabbits/ so that those tests which evaluate for a 404 response check the response body, either with a response_strings or response_json_paths test. If you can't figure out how to do that either by looking at the existing tests or the docs[1] then find me (cdent) IRC and I can help out.

[1] http://gabbi.readthedocs.io/en/latest/format.html",11564,http://gabbi.readthedocs.io/en/latest/format.html,gabbi.readthedocs.io,API documentation,Elaborating,External,OpenStack365688,11564,"Patch Set 3:

> LGTM, thanks. Just curious, is there a way to make tests
 > conditional with gabbi, like skip the ones that will fail with
 > mysql?

You can explicitly mark an individual test to skip (see http://gabbi.readthedocs.io/en/latest/format.html#metadata ), but it is not conditional. You can also use fixtures to skip an entire file, see http://gabbi.readthedocs.io/en/latest/fixtures.html and raising unittest.case.SkipTest.",11564,http://gabbi.readthedocs.io/en/latest/format.html#metadata,gabbi.readthedocs.io,API documentation,Elaborating,External,OpenStack443745,6873,"Patch Set 3:

> It's not a ""failure"" in the sense of a 400+ code, so can't really
 > assert that something will be raised here, if that's what you mean.

Your todo seems to be saying ""this test currently only passes because we assert the current reality, which is _wrong_"". When the bug is fixed this test will fail and should be fixed. Is that right?

A different way of having the same thing is marked the test as an 'xfail' or expected fail. The unit test way of doing that is https://docs.python.org/2/library/unittest.html#skipping-tests-and-expected-failures

When we first started adding gabbi tests to telemetry it exposed all sorts of bad http behavior so rather than not adding tests until they were fixed, we made a bunch of failing tests and used 'xfail: true' to say ""yeah, we know."" and made bugs that were linked directly from the test's yaml.

If my understanding of what you're trying to do with the test here is wrong, then none of this matters...",11564,https://docs.python.org/2/library/unittest.html#skipping-tests-and-expected-failures,docs.python.org,API documentation,Elaborating,External,OpenStack33482,7088,"Patch Set 1: Looks good to me (core reviewer); Approved

Reference: http://pubs.vmware.com/vsphere-51/index.jsp#com.vmware.wssdk.apiref.doc/vim.host.Capability.html?resultof=%2522%256e%2565%2573%2574%2565%2564%2522%2520%2522%256e%2565%2573%2574%2522%2520%2522%2548%2556%2522%2520%2522%2568%2576%2522%2520",1849,http://pubs.vmware.com/vsphere-51/index.jsp#com.vmware.wssdk.apiref.doc/vim.host.Capability.html?resultof=%2522%256e%2565%2573%2574%2565%2564%2522%2520%2522%256e%2565%2573%2574%2522%2520%2522%2548%2556%2522%2520%2522%2568%2576%2522%2520,pubs.vmware.com,API documentation,Elaborating,External,OpenStack148339,6072,"Patch Set 2:

Hi enikanorov -

For context, I think what one has to appreciate when using SQLAlchemy is that it is a fairly large and modularized system.  When one wishes to perform various lower level SQL tasks such as manipulating transaction isolation level, this in ""Core"", which exists separate from the ORM so that the library can be an effective SQL toolkit without the burden of using an ORM.  When using the ORM we have to be willing to familiarize with the integration points, for which I can add some more top level documentation, but these integration points are essentially session.connection() http://docs.sqlalchemy.org/en/rel_0_9/orm/session_api.html#sqlalchemy.orm.session.Session.connection and the ""bind"" attribute of starting up a session, which can be any connectable: http://docs.sqlalchemy.org/en/rel_0_9/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites.

Another thing to note with Openstack is that I work for openstack now.  So please ask me first :)  I am zzzeek on irc.

> For instance, it's not clear how execute_options should be used. Especially in the kind of work with sessions that we do in neutron (we don't use connections directly).

This is not a clear-cut question, as the isolation level setting cannot, by definition, take effect for the current transaction.  As DBAPI connections are already in progress on a transaction, it is not typically possible for this setting to be changed mid-transaction.  Looking at MySQL's documentation here:
http://dev.mysql.com/doc/refman/5.0/en/set-transaction.html, this is indeed the case.  All three variants of SET TRANSACTION ISOLATION LEVEL do *not* impact the current transaction.    Looking at the source to psycopg2, I have determined that in their case, if you set the transaction isolation level mid-transaction, it implicitly **resets** the existing transaction, e.g. it is an implicitly destructive operation.   I'd note that psycopg2 does not document this behavior on their end either, I had to read the source.

With that in mind, a single Session is an object that may be already proceeding within a transaction.   This would suggest that the appropriate approach, given a Session that has already been used, is really to begin a second Session that is bound to this new connection with a new isolation level, as we see in http://docs.sqlalchemy.org/en/rel_0_9/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites.   However this means that the objects which are present in this new session aren't the same objects as that of the original session.   This is again necessary however, as the objects in the session are really proxies for rows within the transaction; a ""row proxy"" in one isolation level is definitely not the same as a ""row proxy"" in another.

What I'm getting at here is that while it would be nice for there to be a Session.set_isolation_level() setting with a big giant document pointing to it, things are just not that simple; Sessions often represent in-progress database transactions which typically cannot have their isolation level changed mid-stream; and the objects contained within represent proxies to those rows.  Sessions also can represent any number of *multiple* connections at the same time (though Openstack does not make use of this feature).

> Another question may arise - why is sqlalchemy issues COMMIT statement when changing transaction isolation?

I hadn't looked at this code in some years, but this should be apparent now which is because the isolation level otherwise does not take any effect until the next transaction.   Given that on the Postgresql side, the driver does an implicit ROLLBACK and not a COMMIT, there should be some degree of warning provided by the Connection object if these settings are used while a Transaction object is already in effect; I can make these changes as warnings for 0.9 and exceptions for 1.0.  https://bitbucket.org/zzzeek/sqlalchemy/issue/3296/raise-if-isolation_level-execution-option is added.   When there is no Transaction present, the Connection works in so-called ""autocommit"" mode so COMMIT or ROLLBACK is safe to call at such a point.

In short, transaction isolation level is something that can't be changed mid-stream in any case.  SQLAlchemy's isolation level APIs have to date been in the state such that access to these DBAPI-level facilities has been provided for those users that needed comprehensive access to them, but without the level
of use-case protections and documentation notes that would be sufficient for users unfamiliar with the backend-specific behavior of these features; ticket 3296 serves to begin adding more of these.

Note that I have also updated documentation for raw_connection, and added new accessors Connection.isolation_level and Connection.default_isolation_level with much new inter-linkages for 0.9.9:

https://github.com/zzzeek/sqlalchemy/commit/4032aaf097a9268bc331e4b4815d77b19ba3febb

https://github.com/zzzeek/sqlalchemy/commit/c3d898e8d06c7e549bb273fc8654f5d24fab2204",11816,http://docs.sqlalchemy.org/en/rel_0_9/orm/session_api.html#sqlalchemy.orm.session.Session.connection,docs.sqlalchemy.org,API documentation,Elaborating,External,OpenStack13170,616,"Patch Set 3:

Here is a version that avoids pickling, using straight gdbm. Gdbm is well supported by other languages in case folks want to get at the mapping themselves without using python.

E.g.
http://ruby-doc.org/stdlib-1.9.3/libdoc/gdbm/rdoc/GDBM.html
http://search.cpan.org/~rjbs/perl-5.16.1/ext/GDBM_File/GDBM_File.pm",616,http://search.cpan.org/~rjbs/perl-5.16.1/ext/GDBM_File/GDBM_File.pm,search.cpan.org,API documentation,Elaborating,External,OpenStack197710,1736,"Patch Set 1:

Python docs related to import in threading and deadlocks: https://docs.python.org/2/library/threading.html#importing-in-threaded-code",1736,https://docs.python.org/2/library/threading.html#importing-in-threaded-code,docs.python.org,API documentation,Elaborating,External,OpenStack47966,1994,"Patch Set 1: I would prefer that you didn't merge this

(17 inline comments)

I think, it makes a sense to use more specific methods for assert. 
See http://docs.python.org/2/library/unittest.html#unittest.TestCase.assertTrue",7491,http://docs.python.org/2/library/unittest.html#unittest.TestCase.assertTrue,docs.python.org,API documentation,Proposing Improvement,External,OpenStack664193,7634,"Patch Set 1: Code-Review+2

‰ÏÓ https://docs.sqlalchemy.org/en/13/changelog/migration_09.html#new-query-options-api-load-only-option

Thanks Takashi-san.",14070,https://docs.sqlalchemy.org/en/13/changelog/migration_09.html#new-query-options-api-load-only-option,docs.sqlalchemy.org,API documentation,Elaborating,External,OpenStack45725,6522,"Patch Set 13: (3 inline comments)

doc says 2.7+ on TestCase.addCleanup

http://docs.python.org/2.7/library/unittest.html#unittest.TestCase.addCleanup",6522,http://docs.python.org/2.7/library/unittest.html#unittest.TestCase.addCleanup,docs.python.org,API documentation,Elaborating,External,OpenStack99155,1779,"Patch Set 8: Code-Review+2 Workflow+1

Reference: http://libvirt.org/formatdomain.html#elementsMemoryBacking",1247,http://libvirt.org/formatdomain.html#elementsMemoryBacking,libvirt.org,API documentation,Elaborating,External,OpenStack643519,29620,"Patch Set 2:

> (3 comments)

And when I use the tox,it also tell me that /root/test/cinder/.tox/py27/lib/python2.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use ""pip install psycopg2-binary"" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
I have pip this packeage but it seemed useless.",29620,http://initd.org/psycopg/docs/install.html#binary-install-from-pypi,initd.org,API documentation,Elaborating,External,OpenStack366767,9656,"Patch Set 1:

oh and I probably shouldn't show you this.  There's also this: http://docs.sqlalchemy.org/en/latest/orm/session_api.html#sqlalchemy.orm.session.Session.enable_relationship_loading",11816,http://docs.sqlalchemy.org/en/latest/orm/session_api.html#sqlalchemy.orm.session.Session.enable_relationship_loading,docs.sqlalchemy.org,API documentation,Elaborating,External,OpenStack129288,6072,"Patch Set 15:

FYI: another way without global isolation level change: https://review.openstack.org/#/c/147540/ .

BTW. The isolation level change may cause more deadlock situation to deal with: http://www.percona.com/blog/2010/02/11/read-commited-vs-repetable-read-in-tpcc-like-load/",5803,http://www.percona.com/blog/2010/02/11/read-commited-vs-repetable-read-in-tpcc-like-load/,www.percona.com,Blog post,Elaborating,External,OpenStack106365,10536,"Patch Set 5:

@Mark
- unitest added, 2 test cases for delete and failed to delete netns
- functional test result (either True or False) are already checked by unitest.

Funtional test ""ensures that they defined check function runs through to completion. This will alert developers if an API change is made that breaks the sanity check functions"" [1]

[1] http://otherwiseguy.tumblr.com/post/89880974499/neutron-external-sanity-checks",10536,http://otherwiseguy.tumblr.com/post/89880974499/neutron-external-sanity-checks,otherwiseguy.tumblr.com,Blog post,Elaborating,External,OpenStack38974,8284,"Patch Set 2:

I'm still really not at all convinced we want to support this. Websockets are not merely a browser technology. They are a formally standardized way of taking an initial HTTP(s) conneciton and upgrading it to provide a full-duplex communication channel. Any scheme attempting todo full-duplex comms over traditional HTTP channels is relying on unsupported abilities of the (proxy) servers the connection transits through.


https://tools.ietf.org/rfc/rfc2817 (may 2000)
HTTP Connect is formally standardize since 2000. ""This memo also documents the HTTP CONNECT method for establishing end-to-end tunnels across HTTP proxies""

https://tools.ietf.org/html/rfc6455 (dec 2011)
WebSocket is a web technology, ""The goal of this technology is to provide a mechanism for browser-based""

While it may be a bit more work for clients to support websockets, I think that one-time work is a better tradeoff than having to maintain multiple different spice console proxies in openstack forever more.

It is not only a lot of work and difficult to implement, it is also less efficient (proxy and client have to transform stream, with redundant functionnality). It is planned in a near future to allow direct websocket connection to spice server, without external proxy.

Please reconsider your evaluation.",8284,https://tools.ietf.org/html/rfc6455,tools.ietf.org,Book content,Elaborating,External,OpenStack121407,11692,"Patch Set 1:

Referring to the comment, filtering 400 protects against conflicts with already existing resources. It's linked to a potential ODL bug [1].

Filtering 400 is irrelevant in case of single update operations (no resource creation) and full synchronization (404 was returned during the previous get operation). 

To manage conflict, ODL MD must at least check the content of the already existing resource returned by ODL (ie. provider:segmentation_id). I think it's safer to raise an exception than just checking the ID.

In all cases, filtering 400 masks ""real"" bad requests.

I added Kyle and Dave as reviewers even if they have already been informed.

[1] https://bugs.opendaylight.org/show_bug.cgi?id=1785",11692,https://bugs.opendaylight.org/show_bug.cgi?id=1785,bugs.opendaylight.org,Bug report,Providing Context,External,OpenStack123957,12898,"Patch Set 8:

RHEL (Centos etc.) bug numbers:

    qemu-kvm
      7.0 https://bugzilla.redhat.com/1166605
      7.1 https://bugzilla.redhat.com/1160237
    qemu-kvm-rhev
      7.0 https://bugzilla.redhat.com/1167224
      7.1 https://bugzilla.redhat.com/1142331

Fedora 21 will get updated qemu-img soonish
(though it's not even released yet so that's kinda moot)

p.s. Upstream qemu also reworked the SEEK_HOLE logic
to avoid various problems with it which are now brought
to the forefront given it's now the default method.
I didn't hightlight these specifically as they're edge cases,
though the RHEL and Fedora updates will have the latest
SEEK code in place",1812,https://bugzilla.redhat.com/1166605,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack10744,1849,"Patch Set 1:

I was wondering whether 50 bytes was always appropriate.
Maybe you could enforce ASCII encoding also to make that valid. Though that seems a bit draconian.

We're really worried about the screen width here,
so perhaps a function like this is appropriate?
http://bugs.python.org/file24773/width.py
(That's from http://bugs.python.org/issue12568)",1812,http://bugs.python.org/issue12568,bugs.python.org,Bug report,Proposing Improvement,External,OpenStack530965,24072,"Patch Set 4: Code-Review-1

(1 comment)

I see you've filed this upstream libvirt bug: https://bugzilla.redhat.com/show_bug.cgi?id=1531076 (""Support 'host-model' on aarch64"").

But I wonder if there's any other way to avoid 'host-passthrough'",6962,https://bugzilla.redhat.com/show_bug.cgi?id=1531076,bugzilla.redhat.com,Bug report,Elaborating,External,OpenStack230481,7249,"Patch Set 13:

Some info placed here: http://docs.sqlalchemy.org/en/rel_1_0/dialects/sqlite.html#serializable-isolation-savepoints-transactional-ddl
""The pysqlite DBAPI driver has several long-standing bugs which impact the correctness of its transactional behavior. In its default mode of operation, SQLite features such as SERIALIZABLE isolation, transactional DDL, and SAVEPOINT support are non-functional, and in order to use these features, workarounds must be taken."" 
also here: http://bugs.python.org/issue10740
The neutron unit test use sqlite as backend db, maybe need to find some more generic way to solved it, such as add configuration to let cloud admin to decide whether to use nested transaction, at the same time leave the unit test transaction unchanged.",9531,http://bugs.python.org/issue10740,bugs.python.org,Bug report,Elaborating,External,OpenStack577385,6962,"Patch Set 3:

> The help text looks fine.
 > 
 > Should we maybe set the default value to '/dev/urandom'?
 > 
 > According to ""https://libvirt.org/formatdomain.html#elementsRng"" if
 > no filename is specified (which seems to be the case by default
 > currently) then qemu will use ""/dev/random"" by default.

Yes, Nova can set default to /dev/urandom.  (Also, most other projects are overriding the QEMU default to /dev/urandom anyway; e.g. the libguestfs project: https://github.com/libguestfs/libguestfs/blob/master/lib/launch-direct.c#L592)

And QEMU upstream itself should default to /dev/urandom; I raised it on their upstream mailing list.",6962,https://github.com/libguestfs/libguestfs/blob/master/lib/launch-direct.c#L592,github.com,Code,Elaborating,External,OpenStack356380,22793,"Patch Set 1:

Hussain, I'm not so sure about the performance gain.

In cPython the formatting of the string [1] will in the end create a string object [2] which actually calls the integer class' `tp_str` method to return a string [3] which is a very simple method [4], and then finally do a string type conversion from a PyString to a STRING [5].

In the decimal case [6], it calls `formatint` method [7] which is not so simple since it has to check all flags [8] and calls PyOS_snprintf [9], which in turn calls PyOS_vsnprintf [10], then vsnprintf gets called [11], which is a C standard library call and it's also not light at all.

So by looking at the code, and without having performed any real test, it looks like it may be even faster to do %s than %d.

And we should also consider that %s is safer, since it won't fail if the argument is not an integer.

[1]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4448
[2]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4456
[3]: https://github.com/python/cpython/blob/2.7/Objects/object.c#L430
[4]: https://github.com/python/cpython/blob/2.7/Objects/intobject.c#L1172
[5]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4477
[6]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4483
[7]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4509
[8]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4131
[9]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4179
[10]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L48
[11]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L75",9535,https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4509,github.com,Code,Elaborating,External,OpenStack356380,22793,"Patch Set 1:

Hussain, I'm not so sure about the performance gain.

In cPython the formatting of the string [1] will in the end create a string object [2] which actually calls the integer class' `tp_str` method to return a string [3] which is a very simple method [4], and then finally do a string type conversion from a PyString to a STRING [5].

In the decimal case [6], it calls `formatint` method [7] which is not so simple since it has to check all flags [8] and calls PyOS_snprintf [9], which in turn calls PyOS_vsnprintf [10], then vsnprintf gets called [11], which is a C standard library call and it's also not light at all.

So by looking at the code, and without having performed any real test, it looks like it may be even faster to do %s than %d.

And we should also consider that %s is safer, since it won't fail if the argument is not an integer.

[1]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4448
[2]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4456
[3]: https://github.com/python/cpython/blob/2.7/Objects/object.c#L430
[4]: https://github.com/python/cpython/blob/2.7/Objects/intobject.c#L1172
[5]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4477
[6]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4483
[7]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4509
[8]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4131
[9]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4179
[10]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L48
[11]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L75",9535,https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4456,github.com,Code,Elaborating,External,OpenStack147539,1653,"Patch Set 14:

(7 comments)

Hi Gary.

Sorry for a lot of questions. But since our ec2api team has to port such modifications to ec2api project (https://github.com/stackforge/ec2-api/blob/master/ec2api/metadata/__init__.py#L197), we need to understand some details.

Thanks.",10224,https://github.com/stackforge/ec2-api/blob/master/ec2api/metadata/__init__.py#L197,github.com,Code,Elaborating,External,OpenStack324720,2750,"Patch Set 4:

> > libguestfs is not available on s390x IIRC. We relied on the NBD
 > > fallback for file injection. Let me check this internally.
 > 
 > Looks like libguestfs supports s390x since version 1.36:    
 > https://github.com/libguestfs/libguestfs/commit/a1173828285aeaab67d7d38aa3eb19bceb2e1a32
 > 
 > I need until next week to have a definitive answer to the
 > capabilities of libivrt on s390x; the in-house experts are not in
 > the office this week. Will update here.

The libguestfs is available on s390x, but it has this bug which blocks its functionality: https://bugzilla.redhat.com/show_bug.cgi?id=1376547 
Can we at least have a deprecation cycle with a warning, before we rip NBD out? Or did that already happen and I missed it?",11303,https://github.com/libguestfs/libguestfs/commit/a1173828285aeaab67d7d38aa3eb19bceb2e1a32,github.com,Code,Elaborating,External,OpenStack459753,20676,"Patch Set 14:

There one more flag that needs to be set to hide the hypervisor for Windows VMs in order to make the NVidia driver happy (not necessary for Linux where <hidden state='on|off'/> is sufficient). 

<hyperv>
  <vendor_id state=""on"" value=""FakeID""/>
</hyperv>

Where `FakeID` just needs to be a random string different from the default. https://lists.gnu.org/archive/html/qemu-devel/2015-10/msg00662.html (libvirt 1.3.3/qemu 2.5) see also https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#.22Error_43:_Driver_failed_to_load.22_on_Nvidia_GPUs_passed_to_Windows_VMs

I was working on a very similar patch to the one proposed here and was pointed to this review from IRC (see https://gist.github.com/claudiok/5dd9fd01b9628e35f0b48884471e58cf for my version in case it clarifies this).

I assume ""hyperv"" settings could also be configured using a separate per-flavor setting in order to make this patch as simple as possible.",26029,https://gist.github.com/claudiok/5dd9fd01b9628e35f0b48884471e58cf,gist.github.com,Code,Elaborating,External,OpenStack314054,19554,"Patch Set 7:

well, there is a way (maybe) to backport a cheap version of && that works here to EXCLUDE.  I've gotten almost all of it working except we need to create a GIST operator class for it (see http://www.postgresql.org/docs/9.2/static/sql-createopclass.html) and that is an enormous ordeal.   You can see how far I've gotten though where I've successfully created a && operator that does CIDR overlap: https://gist.github.com/zzzeek/46fe8db01d597b2ec92424956b0ebb50 .

But making the GIST operator class is a huge PITA.  If you want to try it, that's one thing.  Or we can try to see if having this feature only available for 9.4.   but EXCLUDE USING still looks promising.",11816,https://gist.github.com/zzzeek/46fe8db01d597b2ec92424956b0ebb50,gist.github.com,Code,Elaborating,External,OpenStack326906,4690,"Patch Set 1:

(1 comment)

This feels cleaner to me than the similar version over on https://review.openstack.org/#/c/322181.  I do wonder if we can further simplify this cell routing code.  I'm not a fan of the transport objects being created in the nova.context object via target_cell().  It feels heavy and adds dependency coupling between what should be a simple object describing the user and request information with the messaging layer of the system.  (Also, transport objects are heavy weight, with potential connection pools behind them, so creating them on the fly every time the decorator is called will be expensive)

I put together an alternative option for handling the cell routing within rpcapi.  Let me know if you think this is worth pursuing:

https://gist.github.com/bdelliott/90acf4fbec3504a202362fb9675b69e1

Basically, the goal here is to simplify some of the complexity between managing multiple clients for each cell, as well as the default client for the non-cellsv2 deployments.  I think this code could be re-usable so you could do the same thing for calling console services in cells also.

Transports should be cached somewhere. :)

Per Dan's comments, I agree that we will need to upgrade each cell prior to upgrading the API services.  That seems more of a process issue than a code one.",2835,https://gist.github.com/bdelliott/90acf4fbec3504a202362fb9675b69e1,gist.github.com,Code,Elaborating,External,OpenStack59014,9520,"Patch Set 13: Looks good to me (core reviewer); Approved

I think this is a great start for enforcing valid state transitions.  You can clearing see the allowed transitions.  I think this as a step in the right direction.

I would like to note that there are still some flaws.  While this patch does enforce a graph of states it does not switch from state to state based on an event.  We are still left with many places in the code where an event occurs and we must check the state to determine what to do.  Ideally we would feed the incoming event into a FSM the results wold be the execution of a specific bit of code given the current state, and that event.

An example of what I mean can be found here: 
https://github.com/buzztroll/staccato/blob/master/staccato/common/state_machine.py

However, I recognize that would be a large refactor and I certainly think that this is a step in the right direction.  Nice work!",6493,https://github.com/buzztroll/staccato/blob/master/staccato/common/state_machine.py,github.com,Code,Elaborating,External,OpenStack567926,4523,"Patch Set 1:

Do you have a link to somewhere that says this is deprecated? I tried to find one, but I don't see anything stating they are deprecating this.


Nothing in the source either:

https://github.com/requests/requests/blob/00fd4c8eb4ac0fd7b8f8d76bbf15ab06351c052c/requests/packages.py",11904,https://github.com/requests/requests/blob/00fd4c8eb4ac0fd7b8f8d76bbf15ab06351c052c/requests/packages.py,github.com,Code,Elaborating,External,OpenStack324720,2750,"Patch Set 4:

> libguestfs is not available on s390x IIRC. We relied on the NBD
 > fallback for file injection. Let me check this internally.

Looks like libguestfs supports s390x since version 1.36:     https://github.com/libguestfs/libguestfs/commit/a1173828285aeaab67d7d38aa3eb19bceb2e1a32

I need until next week to have a definitive answer to the capabilities of libivrt on s390x; the in-house experts are not in the office this week. Will update here.",11303,https://github.com/libguestfs/libguestfs/commit/a1173828285aeaab67d7d38aa3eb19bceb2e1a32,github.com,Code,Elaborating,External,OpenStack356380,22793,"Patch Set 1:

Hussain, I'm not so sure about the performance gain.

In cPython the formatting of the string [1] will in the end create a string object [2] which actually calls the integer class' `tp_str` method to return a string [3] which is a very simple method [4], and then finally do a string type conversion from a PyString to a STRING [5].

In the decimal case [6], it calls `formatint` method [7] which is not so simple since it has to check all flags [8] and calls PyOS_snprintf [9], which in turn calls PyOS_vsnprintf [10], then vsnprintf gets called [11], which is a C standard library call and it's also not light at all.

So by looking at the code, and without having performed any real test, it looks like it may be even faster to do %s than %d.

And we should also consider that %s is safer, since it won't fail if the argument is not an integer.

[1]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4448
[2]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4456
[3]: https://github.com/python/cpython/blob/2.7/Objects/object.c#L430
[4]: https://github.com/python/cpython/blob/2.7/Objects/intobject.c#L1172
[5]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4477
[6]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4483
[7]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4509
[8]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4131
[9]: https://github.com/python/cpython/blob/2.7/Objects/stringobject.c#L4179
[10]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L48
[11]: https://github.com/python/cpython/blob/2.7/Python/mysnprintf.c#L75",9535,https://github.com/python/cpython/blob/2.7/Objects/intobject.c#L1172,github.com,Code,Elaborating,External,OpenStack184155,3031,"Patch Set 6:

Thanks Mathieu!  FWIW, I grabbed that and ported it into our Kilo build, if anyone is interested:  https://gist.github.com/misterdorm/5be03435973306cc42fc",9060,https://gist.github.com/misterdorm/5be03435973306cc42fc,gist.github.com,Code,Elaborating,External,OpenStack29961,7598,"Patch Set 5:

https://github.com/eventlet/eventlet/blob/e40cd680873e3f0d94ed29e9474dd057585c53ec/eventlet/green/subprocess.py#L54",6549,https://github.com/eventlet/eventlet/blob/e40cd680873e3f0d94ed29e9474dd057585c53ec/eventlet/green/subprocess.py#L54,github.com,Code,Elaborating,External,OpenStack13010,67,"Patch Set 4: Looks good to me (core reviewer); Approved

seems like a future python will have this validate option. http://hg.python.org/cpython/rev/857d9fe60169/ but we'll this patch seems to work the best for now.",1711,http://hg.python.org/cpython/rev/857d9fe60169/,hg.python.org,Code,Elaborating,External,OpenStack203163,9775,"Patch Set 19:

The PMAPI is here: https://github.com/performancecopilot/pcp/blob/master/src/python/pcp/pmapi.py",9775,https://github.com/performancecopilot/pcp/blob/master/src/python/pcp/pmapi.py,github.com,Code,Elaborating,External,OpenStack46438,1313,"Patch Set 1: I would prefer that you didn't merge this

""Latest boto 2.13.0 has a bug""
please add a link to the boto bug report.
BTW bug is line:
 https://github.com/boto/boto/blob/530b1aa08e03a28a1c789db45c1936bc0d56344f/boto/ec2/securitygroup.py#L351

called from:
.../boto/ec2/securitygroup.py"", line 115, in add_rule
    dry_run=dry_run
TypeError: add_grant() got an unexpected keyword argument 'dry_run'",1955,https://github.com/boto/boto/blob/530b1aa08e03a28a1c789db45c1936bc0d56344f/boto/ec2/securitygroup.py#L351,github.com,Code,Elaborating,External,OpenStack442126,17799,"Patch Set 2:

How would you do the in-place change?  You can't do it while the instance is running, so would you do it automatically on instance stop?  That seems kludgy.

A rebuild might work, but then you lose your user data.  We can't migrate LVM-backed instances, so that doesn't work.

Fundamentally LVM is a poorly-supported backend, and unless we add additional capabilities it's going to require operator intervention to switch from sparse to thin.  (I'm not even sure it's possible to convert a sparse volume to a still-sparse thin volume.)

Incidentally, with recent-ish LVM tooling I'm told that a sparse volume actually silently makes a separate thinpool behind the scenes, but older tooling behaved differently.  (See a thread I started at https://www.redhat.com/archives/linux-lvm/2015-October/msg00006.html)",8768,https://www.redhat.com/archives/linux-lvm/2015-October/msg00006.html,www.redhat.com,Communication channel,Elaborating,External,OpenStack363209,11564,"Patch Set 1:

for refrence there's discussion about not using generations here: http://p.anticdent.org/22rc",11564,http://p.anticdent.org/22rc,p.anticdent.org,Communication channel,Elaborating,External,OpenStack453330,12021,"Patch Set 2:

OpenFlow 1.1 spec does not define action_strip_vlan anymore (compared to the 1.0), for OVS it will block the action if you connect with a higher version:
# ovs-ofctl -O OpenFlow11 add-flow br-int ""table=201,action=strip_vlan""                                                                         
ovs-ofctl: none of the usable flow formats (OpenFlow10+table_id,NXM+table_id) is among the allowed flow formats (OpenFlow11)

The following ovs-discuss thread may be of interest too:
https://mail.openvswitch.org/pipermail/ovs-discuss/2016-March/040266.html",21798,https://mail.openvswitch.org/pipermail/ovs-discuss/2016-March/040266.html,mail.openvswitch.org,Communication channel,Elaborating,External,OpenStack17861,24,"Patch Set 1: Looks good to me, but someone else must approve

As a point of reference, the libvirt support is implemented upstream in this series. Expect that to be in either the libvirt 1.0.1 or 1.0.2 release

https://www.redhat.com/archives/libvir-list/2012-November/msg01552.html",1779,https://www.redhat.com/archives/libvir-list/2012-November/msg01552.html,www.redhat.com,Communication channel,Elaborating,External,OpenStack199020,8911,"Patch Set 5:

Hey Sergey Vilgelm, I have the same PS[0] as yours. But it block now. You can get more information from mine.

Davanum Srinivas (dims)         

> Sean indicated that Nova folks would like a few features in oslo.policy before Nova adopts it. Please see the following threads:
>    http://markmail.org/message/objf6ht572b5fnza
>    http://markmail.org/message/txiyiolvn6mopa62

[0] https://review.openstack.org/#/c/198065/",7488,http://markmail.org/message/txiyiolvn6mopa62,markmail.org,Communication channel,Elaborating,External,OpenStack134332,5638,"Patch Set 19:

Thanks Daniel. We know the issue and are working it on the tempest side, if you follow the Depends-On link in the commit message, you can see the tempest reviews that need to get in. 

There's an email thread as well with the discussion about the sequence in which to fix things. http://markmail.org/message/7mesqrhh52jsgbwd",5638,http://markmail.org/message/7mesqrhh52jsgbwd,markmail.org,Communication channel,Elaborating,External,OpenStack538929,6593,"Patch Set 1: Workflow+1

Now that I've seen a second question and response from Simon on --strict-order being bad, I'm going to approve this.

http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2018q1/012012.html",1131,http://lists.thekelleys.org.uk/pipermail/dnsmasq-discuss/2018q1/012012.html,lists.thekelleys.org.uk,Communication channel,Elaborating,External,OpenStack122523,5280,"Patch Set 4: -Code-Review

FYI one other thing to bear in mind - we now have a serial console proxy service too in nova, but due to a limitation of QEMU that actually uses a second serial port in the guest. If we could have just a single serial port that worked with both the serial console and the logging system, we would solve both uses cases we're debating here.

One of the things I'm working in the near future is an enhancement in libvirt that lets us achieve exactly that. Specifically, libvirt will provide a 'virtlogd' daemon which can provide both an interactive console and persistent logging on the same guest serial port.

https://www.redhat.com/archives/libvir-list/2015-January/msg00762.html",1779,https://www.redhat.com/archives/libvir-list/2015-January/msg00762.html,www.redhat.com,Communication channel,Elaborating,External,OpenStack483994,15334,"Patch Set 6:

> Adding this comment for information purpose:
 > If I use v1.0.0-testing.2 released on 5th Oct (https://github.com/novnc/noVNC/archive/v1.0.0-testing.2.zip),
 > then it's unable to get token from the URL in nova-novncproxy
 > service.
 > 
 > I had reported this issue (https://github.com/novnc/noVNC/issues/967)
 > in noVNC and the noVNC community suggested to use path query
 > parameter to retreive token.
 > 
 > This requires changes in nova, mainly nova-compute and
 > nova-novncproxy services.

I validated a recent DevStack deployment with noVNC 1.0. It was necessary to change '[vnc] novncproxy_base_url' from '{address}/vnc_auto.html' to '{address}/vnc_simple.html'. This is because of commit 83391ffc in noVNC [1]. Once that was done, everything worked as expected and I could not reproduce the above issue. I also was not able to identify any commits upstream that made this change. What have I missed?

[1] https://github.com/novnc/noVNC/commit/83391ffc38d91f6ceb5da6cf764a5411dc431543",15334,https://github.com/novnc/noVNC/issues/967,github.com,Github activity,Elaborating,External,OpenStack110236,11737,"Patch Set 42:

Mike: the other patch was split-off as e.g. suggested by Eric Harney (Sep 25 17:42), and some discussion on IRC. I'm aware of the comments by John Griffith, we discussed this a bit on IRC as well, and there was no clear outcome on how to proceed (if I understood John correctly he was somewhat against the LVM patch, but wanted to leave the final dicision to others).

Clearly this is pretty late in the process, but luckily we had foreseen this could happen and have a branch which implements the subclass proposal (https://github.com/scality/cinder/pull/3). Do you want me to push that one to this review? Then all functionality is contained in a single patch (unlike what was suggested before).",13777,https://github.com/scality/cinder/pull/3,github.com,Github activity,Elaborating,External,OpenStack344997,11604,"Patch Set 1:

hi
vhost-user reconnect has now merged in ovs
https://github.com/openvswitch/ovs/commit/c1ff66ac80b51aea49c3d672393a9a35f5164790

and is part of the 2.6 branch
https://github.com/openvswitch/ovs/commits/branch-2.6

as such all depenecies should be merged upstream.

as part of the upstream ovs reviews the flag i was using to detect reconnect support was removed so i will need to adapt this change.

i will reupload once i have made the required changes.
removed",11604,https://github.com/openvswitch/ovs/commits/branch-2.6,github.com,Github activity,Elaborating,External,OpenStack144303,12299,"Patch Set 1: Code-Review+1

FWIW, there's discussion of including this functionality in https://gitlab.com/pycqa/flake8/issues/12 It's also important to know that this will be relatively unnecessary in newer versions of hacking as hacking enables multiprocessing support in flake8.",12000,https://gitlab.com/pycqa/flake8/issues/12,gitlab.com,Github activity,Elaborating,External,OpenStack423366,12000,"Patch Set 1:

WebOb is not considering adding support for Chunked Encoding because there is no support for it in the WSGI specification, there is no good way to support it.

If you know that your server properly provides an EOF marker when reading from environ['wsgi.input'], then you can set environ['webob.is_body_readable'] to True and WebOb will bypass the check for environ['CONTENT_LENGTH'] (which is required by the WSGI specification, but can't be set if there is a Transfer Encoding, which is a Hop-by-Hop which is not supported by WSGI).

This was done due to compatibility issues with `wsgiref` and other potential WSGI servers, and previously WebOb also wouldn't allow a body on DELETE for example, or on GET (which was/is used by ElasticSearch).

See this PR for more information: https://github.com/Pylons/webob/pull/283

My recommendation, set 'webob.is_body_readable' in the WSGI environ, and make sure that the server used works with the example provided in the Github link above.",25453,https://github.com/Pylons/webob/pull/283,github.com,Github activity,Elaborating,External,OpenStack284941,13393,"Patch Set 18: Code-Review-1

I've tried to dig a bit into why the futures+futurist+py34 issue happens but to no result yet. Also, lack of b/w is making me quit before I get too determined to find the outcome.


Basically, the info so far is:

A latest release of futures isn't py3 compatible. See more details here:

  * https://github.com/datastax/python-driver/pull/387

This is rather surprising though, as it seems to fail for this patch with versions futures==3.0.5 & futurist==0.18.0

whereas for the following patch the same versions work

  * https://review.openstack.org/#/c/361393/
  * http://logs.openstack.org/93/361393/2/check/gate-glance-python34-db/58234b6/tox/py34-3.log.txt


From the looks of it, a transient dependency could potentially be issue but which one will need some more time spending...


Besides, this commit will need release notes and some reviews after tests work. I am of opinion this won't make it into Newton.",2537,https://github.com/datastax/python-driver/pull/387,github.com,Github activity,Elaborating,External,OpenStack487327,9708,"Patch Set 1: Code-Review+1

The original wsgi-intercept bug, in case anyone is curious: https://github.com/cdent/wsgi-intercept/issues/30",11564,https://github.com/cdent/wsgi-intercept/issues/30,github.com,Github activity,Elaborating,External,OpenStack432948,9171,"Patch Set 2:

Xing,

It is unrelated to this patch.

There are 7 failures. The backup creation failed in all cases with the following error message:

""AttributeError: 'module' object has no attribute 'poll'""

See https://github.com/eventlet/eventlet/issues/398",9171,https://github.com/eventlet/eventlet/issues/398,github.com,Github activity,Elaborating,External,OpenStack35281,1247,"Patch Set 2:

FYI, the pip bug was filed here: https://github.com/pypa/pip/issues/1042",1247,https://github.com/pypa/pip/issues/1042,github.com,Github activity,Elaborating,External,OpenStack175491,6687,"Patch Set 2:

For a specific use case: this patch[1] for Rackspace's quark plugin is working internally, but it can't be accepted upstream without this change.

[1] https://github.com/rackerlabs/quark/pull/374",6687,https://github.com/rackerlabs/quark/pull/374,github.com,Github activity,Elaborating,External,OpenStack4188,1926,"Patch Set 2: Looks good to me, but someone else must approve

Fix looks good, obvious from e.g.

https://github.com/mikechristie/open-iscsi/commit/2c839a2#L13L1282

That the exit code used to be 255 (i.e. what you get if you exit(-1)) and is now ISCSI_ERR_NO_OBJS_FOUND (i.e. 21), and we need to support both statuses",1247,https://github.com/mikechristie/open-iscsi/commit/2c839a2#L13L1282,github.com,Github activity,Elaborating,External,OpenStack400875,7730,"Patch Set 28:

(1 comment)

> No it's false... you are seen that in the wrong way. The problem is
 > that we could pin the emulator threads to a CPU thread which should
 > stay free (threads policy).
 > So basically as I said before we need to compute the usable cores
 > even
 > in your method and so basically we will have to add the same logic
 > (thread_no, sibling_set) in your method.

After talking through this on a Hangout, it seems the 'cpu_thread_policy=isolate' case has hamstrung us in such a way that this is likely ""the best bad idea we have"" [1]. The 'isolate' policy may require more than one host CPU be pinned/marked as used per instance vCPU, however, the instance's NUMA topology objects do not store any of these additional CPUs. This means we can't build an accurate picture of which host CPUs are in use immediately after pinning instance cores (it's only available once we make an actual claim) and therefore we would risk trying to pin emulator threads to CPUs that should be unavailable were pinning emulator threads a separate step.

We can fix this going forward by tracking the ""reserved"" CPU mappings in the InstanceNUMACell/InstanceNUMATopology instead and a TODO should be added to this effect. This would also fix an issue we will see in the future, described inline. However, that's a far larger chunk of work that shouldn't need to be done here. Instead, much as I dislike it, the pinning for emulator threads must be calculated at the same time as the pinning for the instance's CPUs.

Sahid - does that summarize what we discussed? If so, I think a note or two in the code summarizing the rationale for the design would be very helpful for future readers (including us). I'd also like to see a TODO to investigate tracking the CPUs reserved by the instance in the instance's NUMA topology instead. Other than that though, I think this is good to go.

[1] https://youtu.be/h6H454-u4yI?t=40s",15334,https://youtu.be/h6H454-u4yI?t=40s,youtu.be,Media,Elaborating,External,OpenStack29280,5572,"Patch Set 10:

Here are some links to further information on the baremetal use case. 

  # see the Services section in particular
  https://wiki.openstack.org/wiki/Baremetal
  
  # see slide 32 in particular
  http://www.slideshare.net/devananda1/ods-havana-provisioning-bare-metal-with-open-stack

  # recording of my talk using the above slide deck
  http://www.youtube.com/watch?v=zzPt-NdJlVY",2889,http://www.youtube.com/watch?v=zzPt-NdJlVY,www.youtube.com,Media,Elaborating,External,OpenStack198390,16658,"Patch Set 4:

It reminds me the 'eleven' joke =P

http://www.youtube.com/watch?v=5FFRoYhTJQQ",11391,http://www.youtube.com/watch?v=5FFRoYhTJQQ,www.youtube.com,Media,Elaborating,External,OpenStack192712,105,"Patch Set 4:

https://www.youtube.com/watch?v=dcr0ITujHOc",748,https://www.youtube.com/watch?v=dcr0ITujHOc,www.youtube.com,Media,Elaborating,External,OpenStack185182,7166,"Patch Set 2: Code-Review-1

(2 comments)

You need to watch this before proposing any more patches. https://www.youtube.com/watch?v=PPN3KTtrnZM",1063,https://www.youtube.com/watch?v=PPN3KTtrnZM,www.youtube.com,Media,Elaborating,External,OpenStack176093,7448,"Patch Set 6: Code-Review-1

On second thought, a new patchset also requires a rebase for the dependent patch, and I'm reluctant to touch that one as I'm not so familiar with it. On your machine it probably runs full stack because it wasn't rebased on [1], which disabled fullstack..

The change that needs to be done is in neutron/tests/functional/__init__.py: [2], specifically line 30 in that pastebin.

[1] https://review.openstack.org/#/c/171874/13/neutron/tests/functional/__init__.py
[2]: http://pastebin.com/RpMtYC9r",12444,http://pastebin.com/RpMtYC9r,pastebin.com,Memo,Elaborating,External,OpenStack30794,1247,"Patch Set 2:

I did a double check by doing

 git rebase -i 839cd5da5c013b77330acbe7ad9ad98c8f12c03a

and removed five patches.

 pick 362bd7f Reference QUOTA OptGoup names in lowercase
 pick 2f13345 Reference DEFAULT_SERVICETYPE OptGoup names in lowercase
 pick b8b2c4e Reference OVS OptGoup names in lowercase
 pick 956b873 reference quota options in lowercase
 pick 8da2fb7 Require oslo.config 1.2.0a2

I posted the diff at http://pastebin.com/7Ndr88GZ",1994,http://pastebin.com/7Ndr88GZ,pastebin.com,Memo,Elaborating,External,OpenStack523606,7634,"Patch Set 6: Code-Review+2

After following the discussion on IRC and per efried's and cdent's comments, this looks a-ok to me.

PS: I assume cdent's original thinking was inspired by this https://tools.ietf.org/html/rfc6648",15334,https://tools.ietf.org/html/rfc6648,tools.ietf.org,Memo,Elaborating,External,OpenStack16210,2031,"Patch Set 29:

forget the URI:
https://docs.google.com/document/d/1hqcivTHnB7yrcs834CpM6XF6sUEdF98d0WGFctgtyMA/edit",2874,https://docs.google.com/document/d/1hqcivTHnB7yrcs834CpM6XF6sUEdF98d0WGFctgtyMA/edit,docs.google.com,Memo,Elaborating,External,OpenStack11209,1653,"Patch Set 1:

I'm seeing issues with this patch if the linux device (e.g., eth0.1000) already exists.  

see: http://pastebin.com/CYTUcSkP",447,http://pastebin.com/CYTUcSkP,pastebin.com,Memo,Elaborating,External,OpenStack125363,100,"Patch Set 2:

I've never used DB2 and this isn't a primary source, but it looks like DB2 is just as smart as MySQL and PostgreSQL:

http://ibmdatamag.com/2010/10/db2-indexes-and-query-performance-part-1/",100,http://ibmdatamag.com/2010/10/db2-indexes-and-query-performance-part-1/,ibmdatamag.com,Organization homepage,Elaborating,External,OpenStack156563,14024,"Patch Set 21:

Ihar, from http://keepalived.org/changelog.html, it looks like vrrp_script was added in release 1.13, which was released in 2006. Hopefully even RHEL has software that was released in 2006 :)",8873,http://keepalived.org/changelog.html,keepalived.org,Others,Providing Context,External,OpenStack390412,6951,"Patch Set 2:

I also loaded your change in this online rst editor / renderer and it renders fine: http://rst.ninjs.org/",4694,http://rst.ninjs.org/,rst.ninjs.org,Others,Elaborating,External,OpenStack10095,4987,"Patch Set 1:

This is not related to a particular distro I suppose - the format is determined by the lockfile package and it has been changed the last and only time in 2010: http://code.google.com/p/pylockfile/source/detail?r=102&path=/branches/packages/lockfile/__init__.py

Perhaps the author of the original patch https://github.com/openstack/nova/commit/2fbccc0c693193533284330325f5803c8c6ce52a had a 2010 version of lockfile?

However, I think I should also change the unit tests for this.",4987,http://code.google.com/p/pylockfile/source/detail?r=102&path=/branches/packages/lockfile/__init__.py,code.google.com,Others,Elaborating,External,OpenStack331137,9656,"Patch Set 2:

Ihar, sure. Logs are ~2.5MB. Didn't remove anything: https://www.dropbox.com/s/n1jxni3exoekpx3/tox.logs?dl=0",14611,https://www.dropbox.com/s/n1jxni3exoekpx3/tox.logs?dl=0,www.dropbox.com,Others,Providing Context,External,OpenStack215885,17990,"Patch Set 1:

The subject being rather a large dose of hyperbole aside, these changes do make the document more consistent. Not an important change, but a technically correct one.

The practice of putting two spaces after a full stop came from the limitations (specifically the lack of per-character kerning) of typewriter and certain types of block type. It is generally frowned upon by most modern style guides. [1][2] There are multiple instances of a single space being used in this document, and this patch correctly removed the only use of a double space.

[1] https://en.wikipedia.org/wiki/Sentence_spacing_in_language_and_style_guides
[2] http://www.chicagomanualofstyle.org/qanda/data/faq/topics/OneSpaceorTwo.html",1207,http://www.chicagomanualofstyle.org/qanda/data/faq/topics/OneSpaceorTwo.html,www.chicagomanualofstyle.org,Q&A thread,Elaborating,External,OpenStack21615,447,"Patch Set 1: Looks good to me (core reviewer)

Had to look this one up if it was actually is or are lol: http://english.stackexchange.com/questions/40669/there-is-are-one-or-several-apple-s",4395,http://english.stackexchange.com/questions/40669/there-is-are-one-or-several-apple-s,english.stackexchange.com,Q&A thread,Elaborating,External,OpenStack236210,11975,"Patch Set 9:

(24 comments)

@Vikram and @Ihar: I fixed or answered for Your comments so please my answers inline.
@Ihar: this HZ value is required to calculate minimum burst value which should be set in tc if user will set burst on 0 kilobyts for exampe. For example on page http://unix.stackexchange.com/a/100797 it is well explained for what is this HZ value needed there. AFAIK in x86 and x64 systems it is usually set for 250 and that is default value which I set for this param. But I want to provide option to allow users change it if they will use custom build kernels.
In this new PS I also added some description in devref document for QoS. In next days I want to add also fullstack tests for this functionallity.",11975,http://unix.stackexchange.com/a/100797,unix.stackexchange.com,Q&A thread,Elaborating,External,OpenStack125249,4690,"Patch Set 1:

What I found is in python 2.4, there isn't any cert verification in its ssl module [1]. I then learned the ssl library on pypi [2] doesn't do any hostname verification when it verifies certs, so it's also not secure [3][4].

It seems the only solution in 2.4 is the M2Crypto library [5]. 

[1] https://docs.python.org/release/2.4.4/lib/module-socket.html#l2h-2618
[2] https://pypi.python.org/pypi/ssl/
[3] https://mail.python.org/pipermail/python-list/2010-July/583052.html
[4] https://www.cs.utexas.edu/~shmat/shmat_ccs12.pdf
[5] https://pypi.python.org/pypi/M2Crypto",4690,https://www.cs.utexas.edu/~shmat/shmat_ccs12.pdf,www.cs.utexas.edu,Research paper,Elaborating,External,OpenStack124215,4395,"Patch Set 2: Code-Review-2

Now that [1] has been provisioned, this needs to be revised to get the fix to [1]. Blocking for now, to make sure this is not accidentally merged.

[1] https://github.com/stackforge/vmware-nsx",748,https://github.com/stackforge/vmware-nsx,github.com,Software homepage,Providing Context,External,OpenStack550173,15334,"Patch Set 4:

> As discussed this needs to wait until the underlying distros update
 > novnc to >=1.0.0 that hasn't happened yet AFAIK, for example Fedora
 > is still using v0.6.1: https://src.fedoraproject.org/rpms/novnc/blob/f28/f/sources

Ubuntu are currently shipping 0.4.0 FWIW:

https://packages.ubuntu.com/search?keywords=novnc",10135,https://packages.ubuntu.com/search?keywords=novnc,packages.ubuntu.com,Software homepage,Elaborating,External,OpenStack237264,5756,"Patch Set 13:

ill pull the conversation i had with terry from the rfe bug  into a spec on etherpad (https://etherpad.openstack.org/p/ovs-vhost-user-support-via-capabilities-detection) and then submit to gerrit for reivew next week.

i have an hour and a half before my flight boards so ill see what i can get done and pick it back up on tuesday.

ill limit the scope of the spec to just the enablement of vhost-user with standard ovs from openvswich.org( http://github.com/openvswitch/ovs) with the ovs dpdkvhostuser port type.

the agent type disscustion can evolve separately via the RFE bug opened by maxime(https://etherpad.openstack.org/p/ovs-vhost-user-support-via-capabilities-detection)

@armando
are you interested in/ have bandwidth to oversee the bluepirnt/spec or should i reach out to some of the other core developers to take that role. im not sure how the spec/blurepint changes effect that so ill just pull together a spec and submit it for review and we can go from there.",11604,http://github.com/openvswitch/ovs,github.com,Software homepage,Elaborating,External,OpenStack380067,10267,"Patch Set 1: Code-Review-1

Hmm. Sqlite 3.7.17 is more than three years old [1]. Surely we can require that developers running unit tests should install a newer version of sqlite? Changing production code to accommodate some old buggy version of sqlite for unit tests to pass seems wrong to me.

[1] https://www.sqlite.org/changes.html",6524,https://www.sqlite.org/changes.html,www.sqlite.org,Software homepage,Elaborating,External,OpenStack241652,9284,"Patch Set 9:

Unfortunately, there is no CI for this in neutron currently. This is used by OpenContrail neutron plugin: https://github.com/juniper/contrail-neutron-plugin
The support is still under development and has not yet been included in the mainline. Once it is, the OpenContrail CI will be performing tests for this.

We want this commit merged in as this will allow our customers to use the vanilla nova without the necessity to install our custom, patched versions of nova.",9284,https://github.com/juniper/contrail-neutron-plugin,github.com,Software homepage,Elaborating,External,OpenStack120246,7665,"Patch Set 3:

Hi Zhi,

I just tried downloading an independent tool for graphviz and since it was like another programming language to learn I decided to not spend much time with it.  I also went to http://www.graphviz.org/ several times to see if they had a WYSIWYG tool and it just timed out for me.

So, either I can leave the generated PNG diagram in with the visio source file or just pull it out all together. I could also look at switching to ASCII art.

Thanks,
Travis",7665,http://www.graphviz.org/,www.graphviz.org,Software homepage,Elaborating,External,OpenStack149310,11647,"Patch Set 8: Code-Review-1

I don't understand: why do you need this plug_ovs in nova ?

You could plug your vhost socket in the ovs bridge directly in the ovs dpdk agent, don't you?
(i.e. https://github.com/stackforge/networking-ovs-dpdk )

Does it mean that we'll have to define a new constant (like VIF_DETAILS_VHOSTUSER_OVS_PLUG) in network model for each new L2 brige ?
(i.e. like VIF_DETAILS_VHOSTUSER_SNABB_PLUG, or other VIF_DETAILS_VHOSTUSER_MYNEWBRIDGE_PLUG ...)

The real solution is to use the vif_plug mechanism: it had been agreed with Daniel:
  http://lists.openstack.org/pipermail/openstack-dev/2014-December/052744.html

I think we need to work on it to be implemented for the L. release.",13869,https://github.com/stackforge/networking-ovs-dpdk,github.com,Software homepage,Elaborating,External,OpenStack398359,18940,"Patch Set 2: Code-Review-1

(2 comments)

@Gyorgy,

Thanks for fixing this bug. I deployed your patchset in my development system. Please see my in-line comments where I share my discoveries.

If you want to test the patchset yourself, you can use this environment: https://github.com/miguellavalle/allinonevagrant. It has Designate and the Neutron integration with it configured and ready to go. Under user / tenant demo, you have a network named 'external'. If you create a port on this network specifying --dns-name, a record will be created for it in Designate in zone my-domain.org.. Also, PTR records will be created under zones 251.31.172.in-addr.arpa. and 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.2.6.a.1.b.6.a.7.e.5.d.f.ip6.arpa. under user neutron tenant service",4694,https://github.com/miguellavalle/allinonevagrant,github.com,Software homepage,Elaborating,External,OpenStack65209,6610,"Patch Set 5:

sorry, didn't notice that the link https://pypi.python.org/simple/psutil/ only hosts the version of psutil from 1.1.0 to 1.2.1, while the verison neutron required is psutil>=0.6.1,<1.0.
just want to know if we can let psutil>=1.1.0 as an alternative to deliver Henry's concern.",2711,https://pypi.python.org/simple/psutil/,pypi.python.org,Software homepage,Elaborating,External,OpenStack1563,1981,"Patch Set 1: I would prefer that you didn't submit this

These changes are excellent, but the nova.sh is script is not really being actively maintained anymore, and I don't think that it should be included in contrib.  I think we should actually remove it.  I am more than happy to include these changes if you make a pull request to https://github.com/vishvananda/novascript
but as you can see from the readme there, we are encouraging people to use devstack (http://devstack.org) to run things instead of nova.sh, since devstack actually runs all of the components.",67,https://github.com/vishvananda/novascript,github.com,Software homepage,Elaborating,External,OpenStack3762,2383,"Patch Set 6:

Maru, I would refer you to what the documentation for google's c++ testing framework says on testing private interfaces: http://code.google.com/p/googletest/wiki/AdvancedGuide#Testing_Private_Code

I do not expect to change your mind, but at least it might give you a new perspective :)",998,http://code.google.com/p/googletest/wiki/AdvancedGuide#Testing_Private_Code,code.google.com,Software homepage,Elaborating,External,OpenStack2956,2245,"Patch Set 1:

Hey Hengqing,

Since you are adding a feature by changing the interface,
I you're going to have to provide test scripts
with your patch.

PS. By the way, the project name is Murder. https://github.com/lg/murder",1994,https://github.com/lg/murder,github.com,Software homepage,Elaborating,External,OpenStack143570,2243,"Patch Set 5: Code-Review+1

For what it's worth, as the driver author I do approve of these changes, although I'd like to test them on an actual StorPool cluster here - this should be possible within a couple of days.  But thanks for doing the work, and sorry for the breakage!  Though see below for another option...

Now if I were to have to explain the unconditional import, the main reason it is done this way is that, well, people told me to do so :)  In several of the intermediate versions of this driver while being reviewed here it actually had this check, right up until https://review.openstack.org/#/c/139711/5/cinder/volume/drivers/sp.py where Avishay Traeger said that it shouldn't really have to be like that.  At the time I didn't think of another use for this check except for the test suite - generating the sample config hadn't come to my mind - so I agreed, changed the unit tests to create mock modules and, well, there we are now.

So, yes, what you're doing here sounds good.  Of course, less than an hour ago another option came up - we (StorPool) released the Python bindings in question to PyPI:

https://pypi.python.org/pypi/storpool/1.0.2
https://pypi.python.org/pypi/storpool.spopenstack/1.0.0

And their corresponding GitHub repositories:

https://github.com/storpool/python-storpool
https://github.com/storpool/python-storpool-spopenstack

So I guess it might be possible to keep the unconditional imports if storpool.spopenstack is added to the requirements; do you guys think that there is a chance to do that instead?  Or is that too presumtuous for a meager third-party storage driver? :)  Note that the Python bindings do NOT require any libraries and do not have any external dependencies - they are pretty much a pass-through interface to an HTTP API.

As to not registering the configuration options, well, I have no excuse for that :)",12988,https://pypi.python.org/pypi/storpool/1.0.2,pypi.python.org,Software homepage,Elaborating,External,OpenStack148805,2031,"Patch Set 7:

Hi Nachi,

> I agree with you we may consolidate a couple of vif code using your
> proposal, I'm not sure your proposal suit for Kilo time. our vif
> driver bp is approved, and code submission deadline is already pass,
> so I'm also not sure changing code structure is good idea now.

Well, the code for VIF_TYPE_TAP is already submitted
(https://review.openstack.org/#/c/146914/) and (as far as I
understand) only waiting now for review and approval by core
reviewers.  I'm hoping that will happen in the next 2 days.

> I'm not sure how contrail agent can get vif plugging event. could you
> explain it more?

In Project Calico (http://www.projectcalico.org/) what happens is that
the mechanism driver's create_port_postcommit hook is called, and
sends the details for the port/VIF to an agent running on the compute
host.  Then that agent waits for the TAP device to appear, and sets up
the required connectivity for it using the port/VIF details
communicated by the mechanism driver.

Probably there are other possible variations on this - but do you
think that this could work for Contrail?  The advantage IMO, as I
think I said earlier, is that this can all be done without any
upstream OpenStack change except for VIF_TYPE_TAP.

Best wishes - Neil",13734,http://www.projectcalico.org/,www.projectcalico.org,Software homepage,Elaborating,External,OpenStack19008,1711,"Patch Set 8:

I've done a fair amount of testing with evzookeeper and it's a great start to a library, but as you know it exists to cover up problems with the interactions of the zookeeper python library and the underlying c library and how threads are managed.

In response to this, there is a project called kazoo (https://github.com/python-zk/kazoo) that is a pure python implementation of the zookeeper binary protocol.  

I would highly recommend changing this implementation to use kazoo instead of evzookeeper.",357,https://github.com/python-zk/kazoo,github.com,Software homepage,Elaborating,External,OpenStack43793,8583,"Patch Set 11:

One more comment, having a github fork of devstack support is not really having devstack support, I am referring to this link that you sent before:
https://github.com/dsetia/devstack
You should create a BP in devstack project to add support for this plugin as well.
I also support Yong's comments. Having a wiki or a document describing how to test the plugin will be very helpful.
About having this plugin as ML2 driver, I do believe that there is a plan to extend any of the vrouter functionality as plugin-specific extension, during the summit we decided that we will not migrate or request plugins to be drivers in ML2 until we have in place a proper mechanism to migrate all plugins extensions. So, I personally believe that we should accept it as plugin.
Finally, I do agree with Eugene, there is still more code to be reviewed, I will spent some time during the week to provide more feedback on that area.",704,https://github.com/dsetia/devstack,github.com,Software homepage,Elaborating,External,OpenStack625216,6962,"Patch Set 4: Code-Review+1

(1 comment)

I have one question inline and it seems that the bp hasn't been approved yet. But the patch itself looks good.

Also there is a nice documentation about the prerequisite configuration of this feature in [1] that would be nice to add to the nova documentation in a follow up patch.

cheers,
gibi

[1] https://kashyapc.fedorapeople.org/Native-TLS/Setup-for-NBD-and-migration-streams-over-TLS.rst.txt",9708,https://kashyapc.fedorapeople.org/Native-TLS/Setup-for-NBD-and-migration-streams-over-TLS.rst.txt,kashyapc.fedorapeople.org,Specification,Elaborating,External,OpenStack625216,6962,"Patch Set 4:

[...]

 > Also there is a nice documentation about the prerequisite
 > configuration of this feature in [1] that would be nice to add to
 > the nova documentation in a follow up patch.

Yeah, Nova documentation patch will be added as well; that's part of the reason I spent a lot of time writing that doc. :-)

Thanks for reviewing!

[...]

 > [1] https://kashyapc.fedorapeople.org/Native-TLS/Setup-for-NBD-and-migration-streams-over-TLS.rst.txt",6962,https://kashyapc.fedorapeople.org/Native-TLS/Setup-for-NBD-and-migration-streams-over-TLS.rst.txt,kashyapc.fedorapeople.org,Specification,Elaborating,External,OpenStack425165,8655,"Patch Set 7:

> (1 comment)
 > 
 > I believe the patch is still needed, because we don't want to hit a
 > similar instability issue in the future. Of course, pinning the
 > image will require from us to bump its version from time to time. I
 > think that's a reasonable price to pay.
 > 
 > That's of course assuming Ubuntu will not scrap the image we pin at
 > in several months. Can we check with Ubuntu folks on how persistent
 > the storage is?

Looking at the archives, they keep EOL image versions back to 8.04 which is almost 9 years old [1]. That may give us some space as long as they don't change the storage URL.

[1] http://cloud-images.ubuntu.com/releases/",8655,http://cloud-images.ubuntu.com/releases/,cloud-images.ubuntu.com,Specification,Elaborating,External,OpenStack93520,6873,"Patch Set 2:

Yuck, so I think I've seen this before with json on python 2.6 and that's due to ensure_ascii with loads/dumps is not the same between 2.6 and 2.7, i.e.:

http://stackoverflow.com/questions/9883464/simple-json-dumps-function-with-unicode

So it seems that the change in jsonutils in oslo-incubator breaks compatibility since it should also be checking what version of python it's on and then use ensure_ascii explicitly.",6873,http://stackoverflow.com/questions/9883464/simple-json-dumps-function-with-unicode,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack13903,1669,"Patch Set 2: Do not merge

Julien: Two issues with the current patch:

-Mutable (like {} or []) default arguments for optional parameters are a bad idea.  See the following link for why: http://stackoverflow.com/questions/1132941/least-astonishment-in-python-the-mutable-default-argument

-There is no good reason why this change has to touch so much code.  As per the bug, fix _filter_nets_l3 is the problem and the logical fix is the following (plus a test to prevent regressions):

-vals = filters.get('router:external', [])
+vals = filters and filters.get('router:external', []) or []",2035,http://stackoverflow.com/questions/1132941/least-astonishment-in-python-the-mutable-default-argument,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack54198,2537,"Patch Set 9:

Jenkins was failing on earlier patches due to issue similar to one described in http://stackoverflow.com/questions/16346107/python-import-as-global-name-not-defined .

So, the import unit_test_utils had to be modified to not use ""as"" in it.

These tests were failing on Jenkins however, they do pass on PS 7 on local dev boxes (Ubuntu py27 and py26 and Fedora19 py27)",2537,http://stackoverflow.com/questions/16346107/python-import-as-global-name-not-defined,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack314301,4523,"Patch Set 1: -Code-Review

OK I'm confused.  I was thinking that decorators wrap and therefore execute order is inside out, as explained e.g. at http://stackoverflow.com/questions/27342149/decorator-execution-order",9003,http://stackoverflow.com/questions/27342149/decorator-execution-order,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack198535,12171,"Patch Set 2: Code-Review-1

Please see http://stackoverflow.com/questions/9949533/python-eval-vs-ast-literal-eval-vs-json-decode",1653,http://stackoverflow.com/questions/9949533/python-eval-vs-ast-literal-eval-vs-json-decode,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack55700,7996,"Patch Set 2: (11 inline comments)

Thanks for pointing out that Mark, I noted down the places where it formatting could be avoided at the string level and passed down to the logger.

Also, some interesting points can be seen here http://stackoverflow.com/questions/5082452/python-string-formatting-vs-format. Firstly, the style 

""str %s"" % var can cause type errors on tuples. And down near the bottom (3rd last comment as of 2013-11-11) they ask to use advanced string (beneficial while switching to python 3 as well)

As Mark says, these changes are not necessary. (So don't have a -1) However, if we include certain changes to this patch we might as well include as per some of the observations above.",2537,http://stackoverflow.com/questions/5082452/python-string-formatting-vs-format,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack129784,11279,"Patch Set 1: Code-Review-1

(1 comment)

While I appreciate the effort, I'd like to point out that this isn't a bug (since the 'else' statement after both 'for's happen in case the 'if' never goes in), but more a welcome feature and convention IMO. See [1] for more detail on this. Still, a welcome addition :)

Nit inline (must be fixed IMO).

[1]: http://stackoverflow.com/questions/9979970/why-does-python-use-else-after-for-and-while-loops",12444,http://stackoverflow.com/questions/9979970/why-does-python-use-else-after-for-and-while-loops,stackoverflow.com,Stack Overflow,Elaborating,External,OpenStack271848,11215,"Patch Set 3:

(2 comments)

Hi Michal, I've tested this patch with cinder single backend(default lvm in devstack
https://github.com/vivekdhayaal/cinder-HA/blob/master/how-tos/c-mq-ha-how-to.txt).
I'll look into the multi-backend case and documentation as part of the blueprint:
https://blueprints.launchpad.net/cinder/+spec/cinder-zeromq-support",11215,https://github.com/vivekdhayaal/cinder-HA/blob/master/how-tos/c-mq-ha-how-to.txt,github.com,Tutorial or article,Elaborating,External,OpenStack19906,1653,"Patch Set 10:

Hi Chris,
Thanks for the review. A couple of points:
1. At a recent nova meeting it was decided to implement a scheduler hint and filter that would allow group anti affinity. This has been implemented in https://review.openstack.org/#/c/21070/.
2. Once the aforementioned patch is in this one will need to be rebased - that is, we no longer want to support the chance scheduler with this and need to update to support the filter for the group anti-affinity
3. The document https://docs.google.com/document/d/1bAMtkaIFn4ZSMqqsXjs_riXofuRvApa--qo4UTwsmhw/edit?usp=sharing contains the definition of the proposed API. I hope to try and get an initial patch set of this as an extension some time soon.
Thanks
Gary",1653,https://docs.google.com/document/d/1bAMtkaIFn4ZSMqqsXjs_riXofuRvApa--qo4UTwsmhw/edit?usp=sharing,docs.google.com,Tutorial or article,Elaborating,External,OpenStack72252,7183,"Patch Set 13:

Interesting patch.

Do you thought to drop RA directly from the egress traffic of the port if it should not send RA (like a RA guard)?

I think the RA case is not the only one security problem we should care with IPv6.
We can inspire from what's done with physical equipment.
For example, Cisco defined a list of first hop security rules for IPv6 (FHS [1]) on their equipment.

[1] http://www.cisco.com/c/dam/en/us/products/collateral/ios-nx-os-software/enterprise-ipv6-solution/aag_c45-707354.pdf",55,http://www.cisco.com/c/dam/en/us/products/collateral/ios-nx-os-software/enterprise-ipv6-solution/aag_c45-707354.pdf,www.cisco.com,Tutorial or article,Elaborating,External,OpenStack101982,8124,"Patch Set 8: Code-Review-1

I tested this patch with mysql and postgresql with relatively small vxlan vni ranges (50 000) in case when the ml2_vxlan_allocations table was empty and several transactions tried to insert the same rows there.


For my I always got DBDeadlock: http://paste.openstack.org/show/87594/


And for postgresql - DBAPIError: http://paste.openstack.org/show/87595/


In case of mysql the problem was connected with lock which are set by the INSERT statement (see the INSERT section here: http://dev.mysql.com/doc/refman/5.0/en/innodb-locks-set.html)


I'm not so sure about postgresql, but I think it should be something similar.",7293,http://dev.mysql.com/doc/refman/5.0/en/innodb-locks-set.html,dev.mysql.com,Tutorial or article,Elaborating,External,OpenStack116239,12395,"Patch Set 9:

When I'm checking this bug I found that there is no already appropriate places where we need to use save_and_reraise exception. But I found that in patch code there is redundant usage. Why? Because there is no code, except assigning message variable, between re-raising and try block. You may read more detail about python exception handling techniques by link http://doughellmann.com/2009/06/19/python-exception-handling-techniques.html

So we can use here simple error handling technique. And It allows us to extract redundant importing, because we don't need to use 'excutils' module in this file!",12395,http://doughellmann.com/2009/06/19/python-exception-handling-techniques.html,doughellmann.com,Tutorial or article,Elaborating,External,OpenStack39720,1653,"Patch Set 2: (1 inline comment)

Regarding inaccessibleReason - this is relevant per host and not per cluster. Please see http://pubs.vmware.com/vi3/sdk/ReferenceGuide/vim.Folder.html#createVm. The placement of the VM's should select a host that has access to the datasource.
Thanks
Gary",1653,http://pubs.vmware.com/vi3/sdk/ReferenceGuide/vim.Folder.html#createVm,pubs.vmware.com,Tutorial or article,Elaborating,External,OpenStack16654,1561,"Patch Set 3: Looks good to me, but someone else must approve

github links the CONTRIBUTING file ""when a contributor creates an Issue or opens a Pull Request"" (https://github.com/blog/1184-contributing-guidelines)  but we do not have issue tracking enabled for nova.   So the only time this would be used is when someone tries to do a pull request, but it looks like we have a bot that closes those issues:
https://github.com/openstack/nova/pull/17

with 17 pull requests in two years, this doesn't appear to be a common mistake",1849,https://github.com/blog/1184-contributing-guidelines,github.com,Tutorial or article,Elaborating,External,OpenStack45180,6835,"Patch Set 3:

@Armando I read that, and this (https://github.com/jcrocholl/pep8/blob/master/docs/developer.rst#id4) too.

Now I think I already let that function work but there're something wrong with calling that function.",6835,https://github.com/jcrocholl/pep8/blob/master/docs/developer.rst#id4,github.com,Tutorial or article,Elaborating,External,OpenStack206249,1063,"Patch Set 3: -Code-Review

Non-negative is on Wikipedia: https://en.wikipedia.org/wiki/Sign_(mathematics)#non-negative_and_non-positive

I could go with Unsigned but it has field width connotations that don't apply in this case.

Removing my +1 to avoid any dodginess as I'm co-author.",8688,https://en.wikipedia.org/wiki/Sign_,en.wikipedia.org,Tutorial or article,Elaborating,External,OpenStack625610,14749,"Patch Set 1:

OPNFV Functest (https://wiki.opnfv.org/display/functest/Opnfv+Functional+Testing) uses Rally and utilizes this task file in one of its test scenarios.",14749,https://wiki.opnfv.org/display/functest/Opnfv+Functional+Testing,wiki.opnfv.org,Tutorial or article,Elaborating,External,OpenStack563926,6962,"Patch Set 5: Code-Review+1

this looks good to me.
thanks for shareing 
https://kashyapc.fedorapeople.org/CPU-flags-and-host-passthrough/readme.txt, invtsc is a good example of why you might want this for host-passthough which i had not considered before so expanding this to all three modes seams correct.",11604,https://kashyapc.fedorapeople.org/CPU-flags-and-host-passthrough/readme.txt,kashyapc.fedorapeople.org,Tutorial or article,Elaborating,External,OpenStack365080,2243,"Patch Set 1: Code-Review-1

Couple of things:

- This warning can be suppressed by setting an env variable ""LVM_SUPPRESS_FD_WARNINGS=1"" when calling LVM CLI tools.  This would be the clean way to handle this.  You can just stuff it in LVM_CMD_PREFIX.

- This will affect commands other than just ""vgs"", that may just be the common place to see it.

- I don't understand why this causes failures in Cinder and not just annoying messages, it looks like this warning being printed doesn't cause LVM commands to fail.    (Discussion on IRC indicated that the actual failure was elsewhere in an occurrence where the VG wasn't found, so I think this patch is not really needed to fix any serious problems.  We can hide the FD warnings if needed, but it would be better to just fix Kolla to not leak FDs.)


Env var:  https://git.fedorahosted.org/cgit/lvm2.git/tree/tools/lvmcmdline.c?id=be85c22f659#n1967

Warning itself:  https://git.fedorahosted.org/cgit/lvm2.git/tree/tools/lvmcmdline.c?id=be85c22f659#n1933",4523,https://git.fedorahosted.org/cgit/lvm2.git/tree/tools/lvmcmdline.c?id=be85c22f659#n1967,git.fedorahosted.org,Tutorial or article,Elaborating,External,OpenStack657219,20190,"Patch Set 1: Code-Review-1

(3 comments)

I wanted someone to do this for so long, however i still see places where \ exists and can be replaced by brackets instead as the pep8 docs suggest[1].

[1] https://www.python.org/dev/peps/pep-0008/#maximum-line-length",27615,https://www.python.org/dev/peps/pep-0008/#maximum-line-length,www.python.org,Tutorial or article,Elaborating,External,OpenStack29680,7598,"Patch Set 2: (1 inline comment)

Hello Mark

I have actually done a v2 of the patch that includes both unit and functional tests and all the comments addressed. This  v2 patch is ready for glance so I'll create a v2 branch just waiting for your approval after the blue-print discussion meeting

Sheepdog integration of Cinder was done earlier. And you can go to http://www.slideshare.net/multics/overview-of-sheepdog to get an overview of Sheepdog in minutes.

and our wiki page
https://github.com/collie/sheepdog/wiki

Sheepdog community will keep contiguous effort to integrate more closely  into Openstack system. Support of Swift API is planned.",7598,https://github.com/collie/sheepdog/wiki,github.com,Tutorial or article,Elaborating,External,OpenStack459753,20676,"Patch Set 14:

There one more flag that needs to be set to hide the hypervisor for Windows VMs in order to make the NVidia driver happy (not necessary for Linux where <hidden state='on|off'/> is sufficient). 

<hyperv>
  <vendor_id state=""on"" value=""FakeID""/>
</hyperv>

Where `FakeID` just needs to be a random string different from the default. https://lists.gnu.org/archive/html/qemu-devel/2015-10/msg00662.html (libvirt 1.3.3/qemu 2.5) see also https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#.22Error_43:_Driver_failed_to_load.22_on_Nvidia_GPUs_passed_to_Windows_VMs

I was working on a very similar patch to the one proposed here and was pointed to this review from IRC (see https://gist.github.com/claudiok/5dd9fd01b9628e35f0b48884471e58cf for my version in case it clarifies this).

I assume ""hyperv"" settings could also be configured using a separate per-flavor setting in order to make this patch as simple as possible.",26029,https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#.22Error_43:_Driver_failed_to_load.22_on_Nvidia_GPUs_passed_to_Windows_VMs,wiki.archlinux.org,Tutorial or article,Elaborating,External,OpenStack33639,7872,"Patch Set 2:

@Duncan Thomas:
So far I understand the http standard (http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html) a PUT request must have a CONTENT_LENGTH field. So it's not a Radosgw specific fix.",7872,http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html,www.w3.org,Tutorial or article,Elaborating,External,OpenStack201500,10674,"Patch Set 11:

(1 comment)

please again read ""https://www.python.org/dev/peps/pep-0008/#indentation""
for ""closing brace/bracket/parenthesis on multi-line constructs"".",16258,https://www.python.org/dev/peps/pep-0008/#indentation,www.python.org,Tutorial or article,Elaborating,External,OpenStack22983,2750,"Patch Set 2:

Maybe it can query the pg_locks table and checks if there is any pending lock and wait until the lock is released.

http://www.postgresql.org/docs/current/static/view-pg-locks.html",4601,http://www.postgresql.org/docs/current/static/view-pg-locks.html,www.postgresql.org,Tutorial or article,Elaborating,External,OpenStack155184,15038,"Patch Set 7:

Hi Nha!

Here you can find information about commit splitting http://www.mediawiki.org/wiki/Gerrit/split_a_submitted_change.
On the other side you can create new two patches instead of splitting you current commit. here you can find information about it http://www.mediawiki.org/wiki/Gerrit/Advanced_usage#Create_a_dependency

Here my own example of creating dependencies:

 git checkout master
 git pull
 git checkout -b first_branch ##or some other branch name if you will

Do some changes for example in nova/db/sqlalchemy/api.py

 git add nova/db/sqlalchemy/api.py
 git commit

By this actions we created your first commit with your changes. Lets create your second commit, based on your first commit

You must use branch with your first commit ('first_branch' in this example)
Than we need to checkout to a new branch from our 'first_branch'

 git checkout -b second_branch ## or some other branch name if you will

Do some changes for example in nova/db/sqlalchemy/api.py

 git add nova/db/sqlalchemy/api.py
 git commit

Here we have branch master, branch 'first_branch' depends on master,and branch 'second_branch' depends on 'first_branch'. to ensure that you patch depends on anouther patch you can use command ""git log"".
it sould return following information:

 commit 116bc01dfddbd1e554388d78aeb2bf57d7c651e5 
 Author: Nha Pham 
 Date:   Thu Feb 19 10:44:51
    Some second commit message!!!
    Change-Id: Ia6a2bf5f47f15334cf9d90a5fd13e295420cfa32

 commit aa4ce82ee3ce07e369b3de0b55889151e7ea11f5
 Author: Nha Pham
 Date:   Thu Feb 19 10:43:40
    Some first commit message!!!
    Change-Id: I5fd0b022b8871a1204582b60d5eed5004d9f05cf

## This is the last commit from master
 commit 46ea0b328f0aa1ca82794abc3c0eed29d6bb3289
 Merge: 6a48de3 7b5cff7
 Author: Jenkins <jenkins@review.openstack.org>
 Date:   Wed Feb 18 07:09:54 2015 +0000
    Merge ""Remove redundant tearDown from ArchiveTestCase""

than you just do

 git review


For example here my patches with dependencies:
* first https://review.openstack.org/#/c/148227/5
* second, depends on first https://review.openstack.org/#/c/148189/ (see 'Dependencies')

@garik, about blueprint - I dont understand why we need it. We allready have a bug. I agree with you that we need a discussion on how to work with shared storage. But I think a blueprint is unnecessary",9569,http://www.mediawiki.org/wiki/Gerrit/Advanced_usage#Create_a_dependency,www.mediawiki.org,Tutorial or article,Elaborating,External,OpenStack225024,10674,"Patch Set 6:

Hello Ivan Kolodyazhny, I submit path similar to previous patch you commented because check with python if-condition (not query solution) is not cool but solves this bug surely, sorry. I tried some way referencing the following MySQL doc for case sensitive search, but some way has no compatibility between mysql and sqlite (*1), and other way has no compatibility for python3.4 (*2).

https://dev.mysql.com/doc/refman/5.0/en/case-sensitivity.html

(*1) filter_by(host = func.binary(host) 
(=> extract 'where host = binary host', this is valid in mysql, but this is invalid in sqlite)

(*2) filter(cast(host, binary) == cast(host, binary))
(=> it fails in python3.4 (for more detail, please refer patch-set 5)",10674,https://dev.mysql.com/doc/refman/5.0/en/case-sensitivity.html,dev.mysql.com,Tutorial or article,Elaborating,External,OpenStack93430,5202,"Patch Set 4:

Is using the .invalid domain an option here? (We use that in some places in the client tests.)

http://en.wikipedia.org/wiki/.invalid",455,http://en.wikipedia.org/wiki/.invalid,en.wikipedia.org,Tutorial or article,Elaborating,External,OpenStack207794,15888,"Patch Set 8:

(6 comments)

The formatting in here is pretty inconsistent. Please see PEP8 https://www.python.org/dev/peps/pep-0008/#indentation",4690,https://www.python.org/dev/peps/pep-0008/#indentation,www.python.org,Tutorial or article,Elaborating,External,OpenStack151677,11057,"Patch Set 31: Code-Review-1

(39 comments)

Mostly distracting style problems, please consult the guidelines:

http://docs.openstack.org/developer/hacking/

https://www.python.org/dev/peps/pep-0008/#code-lay-out",4690,https://www.python.org/dev/peps/pep-0008/#code-lay-out,www.python.org,Tutorial or article,Elaborating,External,OpenStack55076,7494,"Patch Set 2: I would prefer that you didn't merge this

Qin and Jay,

As Avishay recommends, I believe that you are looking for the volume type functionality.  Here is some documentation that helps to explain it:  https://docs.google.com/document/d/1UJO7CvqiqgD1GdXgLLspC8TGG_YxuhH5QXExK2oEL30/edit  https://wiki.openstack.org/wiki/Cinder-multi-backend

You create volume types for the different hosts and then you are able to use those to specify the desired host.",7198,https://docs.google.com/document/d/1UJO7CvqiqgD1GdXgLLspC8TGG_YxuhH5QXExK2oEL30/edit,docs.google.com,Tutorial or article,Elaborating,External,OpenStack70228,8623,"Patch Set 7:

Daniel,

I am certainly not an expert on block device performance w.r.t. virtualization or at all. I have tried
to quantify the peformance hit resulting from using the loop device layer by running an I/O benchmark (I chose Bonnie++) in the same VM booted directly from an image file and booted from the same image file mapped through a loop device. Here are the results

                                        Direct

Version  1.97       ------Sequential Output------ --Sequential Input- --Random-
Concurrency   1     -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
compute0      1000M  1480  99 90807   4 36857   6  2053  33 99300   8 301.7  12
Latency             17745us    3647ms    4864ms     390ms   81468us     603ms

Version  1.97       ------Sequential Create------ --------Random Create--------
compute0            -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                  1 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
Latency               116us      50us     272us      40us      18us      26us


                                        Through loop device

Version  1.97       ------Sequential Output------ --Sequential Input- --Random-
Concurrency   1     -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
compute0      1000M    47  99 34538  38 30268  36   255  99 124411  59  1297 234
Latency               210ms    3068ms    3604ms   47976us    5540us     102ms

Version  1.97       ------Sequential Create------ --------Random Create--------
compute0            -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                  1 +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++ +++++ +++
Latency               509us     576us    2640us    2645us    1024us    1239us


++++ indicates a test that completed in less than 500ms, which does not permit an accurate speed estimate.

The largest discrepancy (a factor of 31) in performance appears in sequential write using putc(), which incurs the overhead from stdio as well as allocating additional file blocks. Detailed description of the tests can be found here http://www.coker.com.au/bonnie++/readme.html

While there is certainly a significant performance penalty, let me try to argue in favor of supporting encryption for Raw at the price of I/O performance.

1. The most important point, in my view, is that for some applications security is more important than peformance. The harm resulting from loss of confidential data can dwarf any performance gains derived from using faster but insecure ephemeral storage. In the end, the choice between performance and security is best left to the customer, who knows what performance and security risk trade-offs are acceptable to her specific needs.

2. Raw is a widely used ephemeral storage backend and leaving out encryption for Raw will significantly limit the options available to Openstack users seeking secure cloud solutions.

3. As you have pointed out prospects for revamping encryption in Qemu are highly uncertain and may take a non-trivial length of time. There is no effort under way nor plans in the foreseeable future to upgrade Qemu encryption implementation. (I am basing these conclusions on what Peter Hamilton relayed to me from his correspondence with you.)

4. The new Qemu encryption implementation will most likely require a significant rewriting of all aspects of libvirt driver and image backends dealing with encryption. So, if the concern is about having to maintain legacy code then the same argument applies to all existing encryption solutions.

Fundamentally, this is an argument about a ""good enough"" intermediate solution vs. the ""right"" long term solution. I agree that sub-optimal performance by design is a poor way to proceed but the vulnerability of existing cloud infrastructure, which is rapidly becoming basic enterprise infrastructure, requires that security issues be addressed now.

Dan",7746,http://www.coker.com.au/bonnie++/readme.html,www.coker.com.au,Tutorial or article,Elaborating,External,OpenStack194616,8543,"Patch Set 1: Code-Review+1

Trivial bugfix. Hyper-V CI passed.

Behaviour for v2 namespace remains the same. [1]

There is no AddressOnParent attribute on the ResourceAllocationSettingData v1 class [2], only on v2 [3]

[1] https://github.com/openstack/nova/blob/master/nova/virt/hyperv/vmutilsv2.py#L198

[2] https://msdn.microsoft.com/en-us/library/cc136877%28v=vs.85%29.aspx

[3] https://msdn.microsoft.com/en-us/library/hh850200%28v=vs.85%29.aspx

LGTM!",8213,https://msdn.microsoft.com/en-us/library/hh850200%28v=vs.85%29.aspx,msdn.microsoft.com,Tutorial or article,Elaborating,External,OpenStack32248,6593,"Patch Set 2: Looks good to me, but someone else must approve

Rafi,
""The BDFL [3] recommends inserting a blank line between the last paragraph in a multi-line docstring and its closing quotes, placing the closing quotes on a line by themselves. This way, Emacs' fill-paragraph command can be used on it.""
http://www.python.org/dev/peps/pep-0257/

Furthermore, concern over merge conflicts hardly seems like a good reason not to merge something.  If there is a merge conflict it can be resolved.

While I am fine with removing this requirement altogether (I don't use emacs), If we keep this around as part of the style guide I prefer to enforce it automatically instead of manually.

http://arstechnica.com/information-technology/2013/06/is-it-a-good-idea-to-impose-uniform-code-format-for-all-developers/ 

Note: only giving this a +1, to wait for more consensus.",1849,http://www.python.org/dev/peps/pep-0257/,www.python.org,Tutorial or article,Elaborating,External,OpenStack65465,7730,"Patch Set 2: (2 inline comments)

Actually this adds lines of code because there is a new test for the method: get_hash_str()
The patchset remove 7 lines of code and try to use DRY (http://en.wikipedia.org/wiki/Don't_repeat_yourself)

The most important on this patch is: the two times defined method get_hash_str in nova/virt/libvirt/volume.py

I'm waiting for you to know what I have to do :)",7730,http://en.wikipedia.org/wiki/Don,en.wikipedia.org,Tutorial or article,Elaborating,External,OpenStack103593,7021,"Patch Set 3:

Document to assist code reviewers:
https://docs.google.com/document/d/1IbplI1TViLUVUZZmx9xFOTmk5ItdhDOjK91VGFtvpS0/edit#",7021,https://docs.google.com/document/d/1IbplI1TViLUVUZZmx9xFOTmk5ItdhDOjK91VGFtvpS0/edit#,docs.google.com,Tutorial or article,Elaborating,External,OpenStack492533,2750,"Patch Set 2:

It looks like I got my terminology backwards...the ""host"" is the place where nova-compute runs, while the ""compute node"" is where the instances run.

Stephen: ""fencing"" is the usual term used in the high-availability space.  (See https://en.wikipedia.org/wiki/Fencing_%28computing%29 for example)

The spec could use something like ""isolated from the rest of the system"" instead of ""fenced"" if we want to avoid jargon.",8768,https://en.wikipedia.org/wiki/Fencing_%28computing%29,en.wikipedia.org,Tutorial or article,Elaborating,External,OpenStack138659,14039,"Patch Set 33:

Seems like the gate fail is due to a system error, but not due to neutron, nor this fix.

/tmp/ansible/local/lib/python2.7/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.",14039,https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning,urllib3.readthedocs.org,Tutorial or article,Elaborating,External,OpenStack101002,162,"Patch Set 11:

A brief google doc that provide an overview of the code can be found here:
https://docs.google.com/document/d/1hazXImTaRNqwcOhSVHQ9XsS5ioRVN3b64JtIhBO5OxU/edit?usp=sharing",162,https://docs.google.com/document/d/1hazXImTaRNqwcOhSVHQ9XsS5ioRVN3b64JtIhBO5OxU/edit?usp=sharing,docs.google.com,Tutorial or article,Elaborating,External,OpenStack1926,904,"Patch Set 2:

@Kevin

The style issue has been fixed.

In relation to your comment regarding transactions...
The lack of explicit transactions certainly isn't ideal. From what I can see every statement executed on the database happens within the context of an implicit transaction (autocommit is turned on). Generally speaking this isn't a good idea (or recommended http://www.sqlalchemy.org/docs/orm/session.html#autocommit-mode). If we were to introduce explicit transactions then presumably it would mean decorating each public facing API with a transaction begin/commit/rollback decorator?",904,http://www.sqlalchemy.org/docs/orm/session.html#autocommit-mode,www.sqlalchemy.org,Tutorial or article,Explaining Necessity,External,OpenStack101548,1669,"Patch Set 8:

Weird, why is glance restricting itself to poll and select hubs. Is that really needed anymore?

Seems odd to have that restriction when https://github.com/eventlet/eventlet/blob/master/eventlet/hubs/__init__.py#L20 seems like it should work fine...",1297,https://github.com/eventlet/eventlet/blob/master/eventlet/hubs/__init__.py#L20,github.com,Code,Explaining Necessity,External,OpenStack33395,7239,"Patch Set 3: Do not merge

This is only deprecated in python 3 which we don't use yet. Also we have tons of these. Does not seem worth changing just a few.

If we want to add this to the style guidelines and auto enforce that is another story.

http://stackoverflow.com/questions/930995/assertequals-vs-assertequal-in-python",1849,http://stackoverflow.com/questions/930995/assertequals-vs-assertequal-in-python,stackoverflow.com,Communication channel,Explaining Necessity,External,OpenStack64429,9796,"Patch Set 3:

@John
About the third character ""B"", I think it is redundant according to http://en.wikipedia.org/wiki/Byte",9796,http://en.wikipedia.org/wiki/Byte,en.wikipedia.org,Tutorial or article,Explaining Necessity,External,OpenStack431773,7787,"Patch Set 3: Code-Review+1

Nice and easy solution to the bug I think :)
Looks like this was done by default in firewalld [0]
[0] https://github.com/t-woerner/firewalld/commit/e431283d70287c064defa02a2d3b01d1de0a5f38",23804,https://github.com/t-woerner/firewalld/commit/e431283d70287c064defa02a2d3b01d1de0a5f38,github.com,Github activity,Others,External,OpenStack425924,12021,"Patch Set 2:

https://imgflip.com/i/1itfif",8655,https://imgflip.com/i/1itfif,imgflip.com,Others,Others,External,OpenStack34801,4463,"Patch Set 60: I would prefer that you didn't merge this

(1 inline comment)

1.glance image-create --name locc --location swift+http://ref2/glance/ad8cf3ce-55b8-4f60-af63-2981017fd875 
HTTPInternalServerError (HTTP 500)

This could be handled more gracefully

2.

iccha@iccha-dev:~/devstack$ glance image-create --name locc --location swift+http://ref1/glance/3f778cc2-961b-4835-8742-e9d31c307c7e --disk-format raw --container-format bare
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | None                                 |
| container_format | bare                                 |
| created_at       | 2014-02-11T20:04:54                  |
| deleted          | False                                |
| deleted_at       | None                                 |
| disk_format      | raw                                  |
| id               | 0e4a574c-ed66-4ff8-9ac6-6057eacae449 |
| is_public        | False                                |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | locc                                 |
| owner            | aca4ea2325744b1e85fd84b18c434222     |
| protected        | False                                |
| size             | 25165824                             |
| status           | active                               |
| updated_at       | 2014-02-11T20:05:12                  |
+------------------+--------------------------------------+
iccha@iccha-dev:~/devstack$ glance image-show 3f778cc2-961b-4835-8742-e9d31c307c7e
+-----------------------+--------------------------------------+
| Property              | Value                                |
+-----------------------+--------------------------------------+
| Property 'kernel_id'  | bd9ef3aa-f2f8-4185-920e-cd0517ef70d8 |
| Property 'ramdisk_id' | ad8cf3ce-55b8-4f60-af63-2981017fd875 |
| checksum              | f8a2eeee2dc65b3d9b6e63678955bd83     |
| container_format      | ami                                  |
| created_at            | 2014-02-05T18:24:29                  |
| deleted               | False                                |
| disk_format           | ami                                  |
| id                    | 3f778cc2-961b-4835-8742-e9d31c307c7e |
| is_public             | True                                 |
| min_disk              | 0                                    |
| min_ram               | 0                                    |
| name                  | cirros-0.3.1-x86_64-uec              |
| owner                 | 3928ad4d15af471d9bd20717827753df     |
| protected             | False                                |
| size                  | 25165824                             |
| status                | active                               |
| updated_at            | 2014-02-05T18:24:29                  |
+-----------------------+--------------------------------------+
iccha@iccha-dev:~/devstack$ 


We are able to ""steal"" other users images this way.",4463,http://ref1/glance/3f778cc2-961b-4835-8742-e9d31c307c7e,ref1,Others,Others,External,OpenStack171098,2888,"Patch Set 1: Code-Review-1

The commit message can do with more explanation and context of _why_ this is needed.

Eerily enough, I was actually discussing this issue with libvirt upstream folks on #virt, OFTC with Michal Privoznik, and this patch was posted a minute right after that.

    11:23< kashyap> mprivozn: Hello, when you're around, I'm looking at this upstream commit of yours in libvirt git -- http://libvirt.org/git/?p=libvirt.git;h=5de58d87c (qemu_migration: Don't error on tunelled migration with --copy-storage)
    11:24< mprivozn> kashyap: hey, what abut it?                                                         
    11:24< kashyap> mprivozn: OpenStack Nova enables the TUNNELLED flag by default for block migration. Since support for it is not present completely, I'm planning to disable the default of           TUNNELLED for live block migration
    11:25< kashyap> mprivozn: Does that sound sensible?
    11:25< mprivozn> kashyap: yes it does


Since I have been researching on the underlying details for the last couple of days for this, I have a half-drafted local patch with more detailed context, let me post that too.",6962,http://libvirt.org/git/?p=libvirt.git,libvirt.org,Software homepage,Others,External,OpenStack308361,15518,"Patch Set 1: Code-Review+1

They do look beautiful :) 

List comprehension makes for better performance. 
https://wiki.python.org/moin/PythonSpeed/PerformanceTips#Loops",20378,https://wiki.python.org/moin/PythonSpeed/PerformanceTips#Loops,wiki.python.org,API documentation,Proposing Improvement,External,OpenStack136080,1849,"Patch Set 1: Code-Review-1

This also mean operator has to share the same ssh key between hosts? it is not really safe too.

Compute nodes are using a private network.

I guess it would be better to describe a good how to configure it to be safe or a link in this great documentation: http://libvirt.org/remote.html

Changing the default url will probably provide nothing better.",7730,http://libvirt.org/remote.html,libvirt.org,API documentation,Proposing Improvement,External,OpenStack27697,6849,"Patch Set 2: I would prefer that you didn't merge this

I'm not sure why we're doing this work.  Why not leverage SQLAlchemy's builtin support for this?  We should be able to update the model definitions to get the gains we desire.


http://docs.sqlalchemy.org/en/rel_0_7/orm/relationships.html#configuring-self-referential-eager-loading",2592,http://docs.sqlalchemy.org/en/rel_0_7/orm/relationships.html#configuring-self-referential-eager-loading,docs.sqlalchemy.org,API documentation,Proposing Improvement,External,OpenStack50184,4393,"Patch Set 1: I would prefer that you didn't merge this

There's no need to define a new protocol for properly copying python objects. Define __copy__() or __deepcopy__() as needed.

http://docs.python.org/2/library/copy.html",2472,http://docs.python.org/2/library/copy.html,docs.python.org,API documentation,Proposing Improvement,External,OpenStack510161,8655,"Patch Set 1:

After some search on the internet, some other suggestions
[1] https://pypi.python.org/pypi/timeout-decorator
@timeout_decorator.timeout(5, use_signals=False) (uses multiprocessing)
[2] using socket.setdefaulttimeout
https://www.saltycrane.com/blog/2010/04/using-python-timeout-decorator-uploading-s3/
import socket
socket.setdefaulttimeout(30)

@John(nice to see your message after a long time :) )",10267,https://www.saltycrane.com/blog/2010/04/using-python-timeout-decorator-uploading-s3/,www.saltycrane.com,Blog post,Proposing Improvement,External,OpenStack143843,9796,"Patch Set 4:

Additionally we can provide a shorten variant with the description nearby, using which users could find in google all the necessary information, even if the link would change.

[2]http://goo.gl/X5o1oz The Performance Impact of Using dict() Instead of {} in CPython 2.7 by Doug Hellman",11391,http://goo.gl/X5o1oz,goo.gl,Blog post,Proposing Improvement,External,OpenStack34345,261,"Patch Set 1:

This change basically rebuilds the snat table each time.
Note that this is done however by the iptables manager.
If you prefer an approach where only the rules that needs to be changed are touched, it's here: https://github.com/salv-orlando/quantum/tree/bug1192610

But I think this one is more maintainable.",261,https://github.com/salv-orlando/quantum/tree/bug1192610,github.com,Bug report,Proposing Improvement,External,OpenStack9592,1812,"Patch Set 1: Looks good to me, but someone else must approve

This is a correct workaround for the problem.

The analysis of what's going on is here:
https://bugzilla.redhat.com/show_bug.cgi?id=835466#c9",1914,https://bugzilla.redhat.com/show_bug.cgi?id=835466#c9,bugzilla.redhat.com,Bug report,Proposing Improvement,External,OpenStack234941,8873,"Patch Set 5:

The current proposed solution includes putting the (ovsdb-server, ovs-vswitchd) pair of processes in a dedicated namespace. However, ovs developers implied to me that support for this will be dropped in the next version so we're not going to go this way.

They are working on adding proper support for this [1], but until this is done this should be held back.

[1]: https://bugzilla.redhat.com/show_bug.cgi?id=1285005",12444,https://bugzilla.redhat.com/show_bug.cgi?id=1285005,bugzilla.redhat.com,Bug report,Proposing Improvement,External,OpenStack533813,4523,"Patch Set 1:

(1 comment)

TBH, I personally don't use pdb to debug things. So I don't really have a recommended path for doing this. That being said the historical issue here is that (s)testr eats stdout from the worker subprocess to multiplex the result streams. (I have a long term solution for this, which I started at: https://github.com/mtreinish/stestr/commit/050e1a7baf726a1060215cd38730ec370fe5815f but that's a ways away) All ostestr is doing with the --pdb flag is calling subunit.run instead of stestr:

https://github.com/openstack/os-testr/blob/master/os_testr/ostestr.py#L185-L210

the stestr --no-discover option does essentially the same thing:

https://github.com/mtreinish/stestr/blob/master/stestr/commands/run.py#L267-L286

so my assumption is that it will work the same way for pdb. (but I've not confirmed this) Since the long term plan is to eventually deprecate the ostestr.py script from the os-testr repo so my preference/recommendation would be to document using stestr here. (after confirming it does work)

If stestr doesn't work for this I actually already have an open bug about adding a --pdb flag: https://github.com/mtreinish/stestr/issues/14 which we should prioritize.",5196,https://github.com/mtreinish/stestr/blob/master/stestr/commands/run.py#L267-L286,github.com,Code,Proposing Improvement,External,OpenStack323707,20229,"Patch Set 7:

After looking at your proposed API change, I spent all morning thinking about how to make this API match up better with the underlying ovs lib's register_table/columns. For example, register_columns upstream recently added the read_only option. Instead of chasing features as they add them, I had the idea that we should instead just use their API more directly. PoC code here: https://gist.github.com/otherwiseguy/3bdc5566f3896bfffb9d5ab34d7e2736

I explain a bit more in the gist: what do you think?",5756,https://gist.github.com/otherwiseguy/3bdc5566f3896bfffb9d5ab34d7e2736,gist.github.com,Code,Proposing Improvement,External,OpenStack120455,4523,"Patch Set 1:

Walter, Eric


OK let me describe this from very begging. With all possible solutions, and why keeping it in requirements is best one. 


1) (osprofiler optimal) Put a lot of try/finally and if condtions

If Osprofiler is optional we are not able to use with ""profile.Trace()"", and decortas ""profiler.trace_cls()"" and ""profiler.trace()"".
And we will need to put a lot of  ""try/finally/if"" stuff in code, which will make reading code really hard. 
To understand how bad it will be take a look at this gist:
 https://gist.github.com/boris-42/e5ffbe1077e4f8f3da09

We are expecting to have a lot of profiling ""points"" in code, so in such case we will produce real mess (mixing business logic and profiling is really bad practice) 


2) (osprofiler optimal) Create a fake cinder.utils.profiler that will have similiar API to osprofiler. 
And if osprofiler is presented it will use it, if not nothing will happen. 

This makes code very clean (like in case of osprofiler in requirements). 
But it produce a lot of issues. As we all know OpenStack is not only Cinder (there are > 10 projects, that will have osprofiler).
So we will need to repeat this code in 10 places.
Such kind of copy pasting is very bad, that's why people create oslo-incubator, but experience from oslo-incubator, showed that it is still
bad to copy-paste code even if this operation is automated. So currently everything from oslo-incubator is moving to separated lib, wich means
that fake osprofiler api will be moved to separated lib. So we are coming back to adding one more dependency in requirements.  


3) (osprofiler in requirments). Everything works out of box, easy to use, easy to maintain, unified across different projects",6172,https://gist.github.com/boris-42/e5ffbe1077e4f8f3da09,gist.github.com,Code,Proposing Improvement,External,OpenStack241227,10267,"Patch Set 9:

I took a close look at the bug, and there seems to be a simpler fix for it. Refer to
http://pastebin.com/Y5XhY5Q9 (Note that it's just to verify the idea, and not a complete fix).

Both fixes have a similar issue: it can't differentiate if the call is from the user or from PD update. If it's from the user, then probably it should be prevented by raising an exception.",6685,http://pastebin.com/Y5XhY5Q9,pastebin.com,Code,Proposing Improvement,External,OpenStack34137,6593,"Patch Set 1: I would prefer that you didn't merge this

LGTM, but can you include a link to the source for the header in the commit msg

http://www.apache.org/licenses/LICENSE-2.0.html",1849,http://www.apache.org/licenses/LICENSE-2.0.html,www.apache.org,Licence,Proposing Improvement,External,OpenStack402589,6159,"Patch Set 1: Code-Review-1

Two comments (though probably both issues need to be addressed in the governance repo, not here, and you may already have addressed them):

(1) There's no ""alt"" text for the image; when the svg of the tags is generated, it would be good to generate a text list of the tags to supply as the :alt: parameter to the RST image tag

(2) The SVG image of the tags doesn't seem to display completely.  When I request this URL directly in a browser, I see everything:

http://governance.openstack.org/badges/glance.svg

but when I look at the sample (or use the RST in an online editor), I only see part of the SVG image.  Compare these:

(current code): http://rst.ninjs.org/?n=f4f235068830bd35b9420d39d3c38777&theme=basic

(added :width: parameter): http://rst.ninjs.org/?n=fd9757e5781f9570cc375226b94dcee4&theme=basic

You could add the :width: parameter, but I think it would be better to generate the SVG to have at most two columns of tags so you don't have to scroll to the right to see them.  (And you may need a combination of the two techniques if one of the tags in the first column turns out to be a really wide one.)",5314,http://rst.ninjs.org/?n=f4f235068830bd35b9420d39d3c38777&theme=basic,rst.ninjs.org,Others,Proposing Improvement,External,OpenStack33088,7400,"Patch Set 1:

whoops I missed Dan's comments:

I looked into this a while ago and found if you put &logging=debug in the URL for the novnc window you'll see the vnc protocol decoded in the javascript debug console. The only difference between ESX and KVM (vnc debug) is that that the security_type is set to 2. Which requires a password to be passed in. Oddly though if you use a vncviewer that ignores that it will work fine if no password is set. This works with http://sourceforge.net/projects/cotvnc/ without a password but novnc will prompt you.",4395,http://sourceforge.net/projects/cotvnc/,sourceforge.net,Software homepage,Proposing Improvement,External,OpenStack5762,2759,"Patch Set 1:

What does this offer over just using apache + multi-processes there?

Then u don't have to deal with or recreate children management.

http://code.google.com/p/modwsgi/

http://httpd.apache.org/docs/2.0/mpm.html",1297,http://httpd.apache.org/docs/2.0/mpm.html,httpd.apache.org,Software homepage,Proposing Improvement,External,OpenStack34345,261,"Patch Set 3:

Re-posting this comment in case it went lost in the history of this patch:

This change basically rebuilds the snat table each time. Note that this is done however by the iptables manager. 

If you prefer an approach where only the rules that needs to be changed are touched, it's here: https://github.com/salv-orlando/quantum/tree/bug1192610


But I think this one is more maintainable.",261,https://github.com/salv-orlando/quantum/tree/bug1192610,github.com,Software homepage,Proposing Improvement,External,OpenStack301747,21228,"Patch Set 9: Code-Review-1

You need to indicate what version of dnsmasq where this utility is now available, in both the commit message and the relnote.

http://www.thekelleys.org.uk/dnsmasq/CHANGELOG",4656,http://www.thekelleys.org.uk/dnsmasq/CHANGELOG,www.thekelleys.org.uk,Specification,Proposing Improvement,External,OpenStack262774,18494,"Patch Set 2: Code-Review-1

Honestly, for something like this can we switch it over to using mock_open instead - http://stackoverflow.com/questions/21760803/how-can-i-make-mock-mock-open-raise-an-ioerror 

monkeypatch of builtins for tests should just be avoided anyway, and using mock_open is the pattern we would want people to copy.",2750,http://stackoverflow.com/questions/21760803/how-can-i-make-mock-mock-open-raise-an-ioerror,stackoverflow.com,Stack Overflow,Proposing Improvement,External,OpenStack117418,11279,"Patch Set 2:

Maybe the x should actually be named dummy due to that being the standard way to refer to unsued variables that you want pylint to not flag.

see: http://stackoverflow.com/questions/10107350/how-to-handle-the-pylint-message-idw0612-unused-variable",5164,http://stackoverflow.com/questions/10107350/how-to-handle-the-pylint-message-idw0612-unused-variable,stackoverflow.com,Stack Overflow,Proposing Improvement,External,OpenStack6262,2883,"Patch Set 2:

Hmm, I guess this would fix the problem, but perhaps it would be possible to share the _base dir between hosts?

I wonder could you just define --lock_path to a shared nfs directory, and use external=True for the locks?

This suggests it (lockfile) might work with that:
http://en.wikipedia.org/wiki/Wikipedia:Reference_desk/Archives/Computing/2009_April_2#Atomic_operations_on_NFS
Note utils.cleanup_file_locks() only does so for each host,
so it should work as long as each hostname is unique.

Though a shared scheme could introduce large latencies
between systems, especially as we're dealing with the
processing of large files. So it would be safer and
less invasive to use _base_$HOSTNAME/",1812,http://en.wikipedia.org/wiki/Wikipedia:Reference_desk/Archives/Computing/2009_April_2#Atomic_operations_on_NFS,en.wikipedia.org,Tutorial or article,Proposing Improvement,External,OpenStack51202,3068,"Patch Set 3: I would prefer that you didn't merge this

(2 inline comments)

Please to follow ""The standard (IEEE 802) format for printing MAC-48 addresses"" - http://en.wikipedia.org/wiki/MAC_address, we should support the MAC digits separated by hyphens also.",8106,http://en.wikipedia.org/wiki/MAC_address,en.wikipedia.org,Tutorial or article,Proposing Improvement,External,OpenStack34685,1313,"Patch Set 4: I would prefer that you didn't merge this

(2 inline comments)

Version numbers in vSphere is a non-trivial discussion. The version ""numbers"" are not constrained to always compute to an ever increasing number. If you want to use an ever increasing number, consider using build from...

http://pubs.vmware.com/vsphere-50/index.jsp#com.vmware.wssdk.apiref.doc_50/vim.AboutInfo.html

... in the form x.y.z-num , the -num component is an ever increasing integer.

However, I would still prefer that you lobbied for the hypervisor_version attribute to be a string value instead.",7629,http://pubs.vmware.com/vsphere-50/index.jsp#com.vmware.wssdk.apiref.doc_50/vim.AboutInfo.html,pubs.vmware.com,Tutorial or article,Proposing Improvement,External,OpenStack15871,6167,"Patch Set 3:

I'm actually going to side with Dan here

http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.1

On a 400 error:

""The request could not be understood by the server due to malformed syntax. The client SHOULD NOT repeat the request without modifications.""

Vish - if you don't like 404, then maybe the 422 is appropriate here?

https://tools.ietf.org/html/rfc4918#section-11.2",642,https://tools.ietf.org/html/rfc4918#section-11.2,tools.ietf.org,Tutorial or article,Proposing Improvement,External,OpenStack263404,4523,"Patch Set 2: Code-Review-1

(2 comments)

Most of these should just use assertIsNone.

https://docs.python.org/2/library/unittest.html#unittest.TestCase.assertIsNone

Good changes though. If you can switch those, I think it would be good to get this through.",11904,https://docs.python.org/2/library/unittest.html#unittest.TestCase.assertIsNone,docs.python.org,Tutorial or article,Proposing Improvement,External,OpenStack104556,7166,"Patch Set 6: Code-Review-1

(1 comment)

I don't like the circular dependency, I have a possible fix, use this:
http://en.wikipedia.org/wiki/Interface_segregation_principle",782,http://en.wikipedia.org/wiki/Interface_segregation_principle,en.wikipedia.org,Tutorial or article,Proposing Improvement,External,OpenStack596497,14070,"Patch Set 2: Code-Review+2 Workflow+1

> Note to reviewers: I locally rebased the whole reshaper series on
 > top of this and ran all the tests. Everything passed.
 > 
 > I don't know if it's really expensive to do it this way because we
 > have to calculate the hash every time; or if we can wind up with
 > duplicates somehow (same provider, but with a different subset of
 > fields filled in?); or if we care about any of that. If so I
 > suppose the alternative would be to create a separate dict with the
 > objects and pass it in as an additional arg.

As I see there are no explicit hash function is defined for ovos. So based on the python doc [1], the hash of the ovos will be based on the id of the ovo. So every ResourceProvider instance will have different hash value. This means if the same RP is read from the db by rpuuid twice the hash of the resulting ResourceProvider objects would different.

Fortunately the inventory part of the schema is built in a way that every RP mentioned there only once. Therefore the handler code will create one ResourceProvider object for every rpuuid. So there won't be duplicates in the dict passed forward.

As hashing only depends on the id() of the object by default calculating hash is not expensive.

[1] https://docs.python.org/3/glossary.html#term-hashable",9708,https://docs.python.org/3/glossary.html#term-hashable,docs.python.org,API documentation,Providing Context,External,OpenStack41751,6717,"Patch Set 5:

I can't because there is no such thing. Only docs about this I'm aware of are http://docs.aws.amazon.com/AWSEC2/latest/APIReference/api-error-codes.html which only have brief descriptions of errors. To mimic the API, reproducing the errors in Amazon EC2 and checking the response would be required.

I believe all these cases are OpenStack specific, so there is no clear mapping to EC2 error codes because EC2 simply doesn't encounter these problems at all.

I've arbitrarily chosen UnsupportedOperation for all OpenStack specific occasions for now but it could be Resource.AlreadyAssociated here and ResourceLimitExceeded there. Or we could use our own error code since these errors are OpenStack specific and thus incompatible by nature.

As of Resource.AlreadyAssociated specifically, it says ""The specified gateway is already attached, or specified subnet is already associated with another object."" which isn't exactly fitting FloatingIpAssociated, or is it?",6717,http://docs.aws.amazon.com/AWSEC2/latest/APIReference/api-error-codes.html,docs.aws.amazon.com,API documentation,Providing Context,External,OpenStack209110,6509,"Patch Set 3: Code-Review-1

as we discussed in libvirt irc this issue should be solve in newer libvirt version according to Laine Stump
I think this is the bug he was referring: 
https://bugzilla.redhat.com/show_bug.cgi?id=1211758

Did you try it? any way I think the solution should be in libvirt.",12171,https://bugzilla.redhat.com/show_bug.cgi?id=1211758,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack161381,6637,"Patch Set 6:

Note that if we are concerned that e.g. dibbler is not available in distribution repositories and that blocks gate testing, then the right thing would be to reach those distributions to package it.

For Fedora and EPEL7, I did the work, and it will be in F20+ and EPEL7 repos in a week or so, so we'll be able to gate against it: https://bugzilla.redhat.com/show_bug.cgi?id=1206639",9656,https://bugzilla.redhat.com/show_bug.cgi?id=1206639,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack329031,20229,"Patch Set 4: Workflow-1

Will update the API based on https://gist.github.com/otherwiseguy/3bdc5566f3896bfffb9d5ab34d7e2736 .",20229,https://gist.github.com/otherwiseguy/3bdc5566f3896bfffb9d5ab34d7e2736,gist.github.com,Code,Providing Context,External,OpenStack493231,5196,"Patch Set 2:

Yeah, it was just to see if it works, and also to save where my experiments are before I called it EOD. The trick here is gonna be mapping the req.body object to something webob will understand. From what I could see image data is only accessed from the webob Request body_file property: 

https://github.com/Pylons/webob/blob/master/src/webob/request.py#L246

Which should give us the hints we need to make sure we're translating the chunked_read() calls into something glance can use.",5196,https://github.com/Pylons/webob/blob/master/src/webob/request.py#L246,github.com,Code,Providing Context,External,OpenStack148339,6072,"Patch Set 2:

Hi enikanorov -

For context, I think what one has to appreciate when using SQLAlchemy is that it is a fairly large and modularized system.  When one wishes to perform various lower level SQL tasks such as manipulating transaction isolation level, this in ""Core"", which exists separate from the ORM so that the library can be an effective SQL toolkit without the burden of using an ORM.  When using the ORM we have to be willing to familiarize with the integration points, for which I can add some more top level documentation, but these integration points are essentially session.connection() http://docs.sqlalchemy.org/en/rel_0_9/orm/session_api.html#sqlalchemy.orm.session.Session.connection and the ""bind"" attribute of starting up a session, which can be any connectable: http://docs.sqlalchemy.org/en/rel_0_9/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites.

Another thing to note with Openstack is that I work for openstack now.  So please ask me first :)  I am zzzeek on irc.

> For instance, it's not clear how execute_options should be used. Especially in the kind of work with sessions that we do in neutron (we don't use connections directly).

This is not a clear-cut question, as the isolation level setting cannot, by definition, take effect for the current transaction.  As DBAPI connections are already in progress on a transaction, it is not typically possible for this setting to be changed mid-transaction.  Looking at MySQL's documentation here:
http://dev.mysql.com/doc/refman/5.0/en/set-transaction.html, this is indeed the case.  All three variants of SET TRANSACTION ISOLATION LEVEL do *not* impact the current transaction.    Looking at the source to psycopg2, I have determined that in their case, if you set the transaction isolation level mid-transaction, it implicitly **resets** the existing transaction, e.g. it is an implicitly destructive operation.   I'd note that psycopg2 does not document this behavior on their end either, I had to read the source.

With that in mind, a single Session is an object that may be already proceeding within a transaction.   This would suggest that the appropriate approach, given a Session that has already been used, is really to begin a second Session that is bound to this new connection with a new isolation level, as we see in http://docs.sqlalchemy.org/en/rel_0_9/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites.   However this means that the objects which are present in this new session aren't the same objects as that of the original session.   This is again necessary however, as the objects in the session are really proxies for rows within the transaction; a ""row proxy"" in one isolation level is definitely not the same as a ""row proxy"" in another.

What I'm getting at here is that while it would be nice for there to be a Session.set_isolation_level() setting with a big giant document pointing to it, things are just not that simple; Sessions often represent in-progress database transactions which typically cannot have their isolation level changed mid-stream; and the objects contained within represent proxies to those rows.  Sessions also can represent any number of *multiple* connections at the same time (though Openstack does not make use of this feature).

> Another question may arise - why is sqlalchemy issues COMMIT statement when changing transaction isolation?

I hadn't looked at this code in some years, but this should be apparent now which is because the isolation level otherwise does not take any effect until the next transaction.   Given that on the Postgresql side, the driver does an implicit ROLLBACK and not a COMMIT, there should be some degree of warning provided by the Connection object if these settings are used while a Transaction object is already in effect; I can make these changes as warnings for 0.9 and exceptions for 1.0.  https://bitbucket.org/zzzeek/sqlalchemy/issue/3296/raise-if-isolation_level-execution-option is added.   When there is no Transaction present, the Connection works in so-called ""autocommit"" mode so COMMIT or ROLLBACK is safe to call at such a point.

In short, transaction isolation level is something that can't be changed mid-stream in any case.  SQLAlchemy's isolation level APIs have to date been in the state such that access to these DBAPI-level facilities has been provided for those users that needed comprehensive access to them, but without the level
of use-case protections and documentation notes that would be sufficient for users unfamiliar with the backend-specific behavior of these features; ticket 3296 serves to begin adding more of these.

Note that I have also updated documentation for raw_connection, and added new accessors Connection.isolation_level and Connection.default_isolation_level with much new inter-linkages for 0.9.9:

https://github.com/zzzeek/sqlalchemy/commit/4032aaf097a9268bc331e4b4815d77b19ba3febb

https://github.com/zzzeek/sqlalchemy/commit/c3d898e8d06c7e549bb273fc8654f5d24fab2204",11816,https://github.com/zzzeek/sqlalchemy/commit/c3d898e8d06c7e549bb273fc8654f5d24fab2204,github.com,Github activity,Providing Context,External,OpenStack98722,7701,"Patch Set 3:

Added some inline review notes / questions:

https://github.com/CrashenX/glance/commit/ae9603a9cf128f10e6cb6aacd2bc7b664fc4cc90


I got these failures:

======================================================================
FAIL: glance.tests.functional.v1.test_multiprocessing.TestMultiprocessing.test_interrupt_avoids_respawn_storm
----------------------------------------------------------------------
Traceback (most recent call last):
_StringException: Traceback (most recent call last):
  File ""glance/tests/functional/v1/test_multiprocessing.py"", line 60, in test_interrupt_avoids_respawn_storm
    children = self._get_children()
  File ""glance/tests/functional/v1/test_multiprocessing.py"", line 48, in _get_children
    children = process.children()
AttributeError: 'Process' object has no attribute 'children'


======================================================================
FAIL: glance.tests.unit.v1.test_api.TestGlanceAPI.test_add_copy_from_image_authorized_upload_image_authorized
----------------------------------------------------------------------
Traceback (most recent call last):
_StringException: Traceback (most recent call last):
  File ""glance/tests/unit/v1/test_api.py"", line 905, in test_add_copy_from_image_authorized_upload_image_authorized
    self.assertEqual(res.status_int, 201)
  File ""/home/jesse/src/rackspace/openstack/glance/.venv/local/lib/python2.7/site-packages/testtools/testcase.py"", line 321, in assertEqual
    self.assertThat(observed, matcher, message)
  File ""/home/jesse/src/rackspace/openstack/glance/.venv/local/lib/python2.7/site-packages/testtools/testcase.py"", line 406, in assertThat
    raise mismatch_error
MismatchError: 400 != 201


Ran 2268 tests in 686.225s

FAILED (failures=2)",11642,https://github.com/CrashenX/glance/commit/ae9603a9cf128f10e6cb6aacd2bc7b664fc4cc90,github.com,Github activity,Providing Context,External,OpenStack110434,1297,"Patch Set 15:

New image @ http://i.imgur.com/8NGzlIx.jpg",1297,http://i.imgur.com/8NGzlIx.jpg,i.imgur.com,Media,Providing Context,External,OpenStack431211,16627,"Patch Set 1:

In 2015 I provided the initial patch to add consisgroup/cgsnap support in the SolidFire driver with this change -> https://github.com/openstack/cinder/commit/d55541c4dae2f36025ea73bc63242a8bf3c592d0.

Unfortunately due to my lack of experience I didn't think about creating a single volume from a single snapshot from a cgsnap. Oops.

Verified the failure here -> https://gist.github.com/gomeler/0e0eb8f53c0180b167f043ff7395383b

Verified the fix here -> https://gist.github.com/gomeler/b6f792c98ebd841450d1e85c2d08d6e5

In short, you can successfully create a consisgroup from a cgsnap, create a consisgroup from another consisgroup, and you can create a volume from a snapshot that resulted from a cgsnap.

Also not sure if I needed to submit a bug report in launchpad for this issue. Ideally I'd like to backport this, assuming it gets through peer review.",16627,https://gist.github.com/gomeler/b6f792c98ebd841450d1e85c2d08d6e5,gist.github.com,Memo,Providing Context,External,OpenStack219977,2243,"Patch Set 6:

BTW, notice that the auto-generated version seems to be missing quite a few entries that are in this output after a rebase on both:

http://pastebin.com/DFxmQ0eP",2243,http://pastebin.com/DFxmQ0eP,pastebin.com,Memo,Providing Context,External,OpenStack25515,2284,"Patch Set 3:

Hmm, test failures from Jenkins look real, if confusing:

https://gist.github.com/markwash/5258234",616,https://gist.github.com/markwash/5258234,gist.github.com,Memo,Providing Context,External,OpenStack78092,8645,"Patch Set 19:

(1 comment)

Hi Kyle-

For every CI comment, click on ""Freescale-ML2-Mechanism-Driver"" link. This redirect the end user to our Log Repository server http://115.249.211.42/?dir=78092/19 where the logs are stored for public review.

For setting this CI I have followed the blog of jaypipes.

Please see http://115.249.211.42/README.html for information on the our CI testing system.

The following files are posted to the FTP server for public review with respect to change and patch set.
[*] crd_server.log ‰ÛÒ Cloud Resource Discovery server log file.
[*] devstack.log ‰ÛÒ Devstack log file.
[*] localrc.txt ‰ÛÒ the ‰Û÷localrc‰Ûª file used with devstack to bring up the openstack environment.
[*] screen-neutron-svc.log ‰ÛÒ the Openstack Neutron server log file.
[*] tempest.conf ‰ÛÒ the tempest configuration file
[*] tempest.log ‰ÛÒ the tempest log file
[*] testr_results.html ‰ÛÒ HTML formatted Unit test report showcasing the complete status of the testcases run for this particular patchset.",8645,http://115.249.211.42/?dir=78092/19,115.249.211.42,Others,Providing Context,External,OpenStack432511,18335,"Patch Set 1:

It looks like the problem with tests failing after deleting the 'config_drive' column is caused by SQLAlchemy auto-adding CHECK constraints if a booleans is generated as a int/smallint.  And deleting the column is not deleting the check.
http://docs.sqlalchemy.org/en/latest/core/type_basics.html#sqlalchemy.types.Boolean",18335,http://docs.sqlalchemy.org/en/latest/core/type_basics.html#sqlalchemy.types.Boolean,docs.sqlalchemy.org,API documentation,Providing Context,External,OpenStack410076,24552,"Patch Set 2: Code-Review+1

Right. spicevmc is required [1]. Looks like this line was accidentally missed [2], whereas it was known that spicevmc was required [3]

 [1] https://libvirt.org/formatdomain.html#elementCharChannel
 [2] https://review.openstack.org/#/c/18306/12/nova/virt/libvirt/driver.py@1810
 [3] https://review.openstack.org/#/c/18305/11/nova/tests/test_libvirt_config.py@545",10224,https://libvirt.org/formatdomain.html#elementCharChannel,libvirt.org,API documentation,Providing Context,External,OpenStack443745,6873,"Patch Set 3:

> Your todo seems to be saying ""this test currently only passes
 > because we assert the current reality, which is _wrong_"". When the
 > bug is fixed this test will fail and should be fixed. Is that
 > right?
 
Yes, that's right.

 > A different way of having the same thing is marked the test as an
 > 'xfail' or expected fail. The unit test way of doing that is
 > https://docs.python.org/2/library/unittest.html#skipping-tests-and-expected-failures
 > 
 > When we first started adding gabbi tests to telemetry it exposed
 > all sorts of bad http behavior so rather than not adding tests
 > until they were fixed, we made a bunch of failing tests and used
 > 'xfail: true' to say ""yeah, we know."" and made bugs that were
 > linked directly from the test's yaml.
 > 
 > If my understanding of what you're trying to do with the test here
 > is wrong, then none of this matters...

I think we could do as you describe and use for example:

 @test.testtools.skip(""bug 1670627"")

on this test and remove the skip alongside in the fix patch.

I think probably the reason for doing it the way we've been doing it is to verify that the test is currently working by running it and not skipping it. The only part we would really want to skip is the last assert on the usage, so I guess a better way might be to create a local function with the assert in it and decorate it with @unittest.expectedFailure.",4690,https://docs.python.org/2/library/unittest.html#skipping-tests-and-expected-failures,docs.python.org,API documentation,Providing Context,External,OpenStack5220,2634,"Patch Set 5: I would prefer that you didn't submit this

This code is deprecated on the new versions of sqlalchemy:
http://docs.sqlalchemy.org/en/latest/core/interfaces.html

The new way to implement it:
http://docs.sqlalchemy.org/en/latest/core/event.html",2350,http://docs.sqlalchemy.org/en/latest/core/interfaces.html,docs.sqlalchemy.org,API documentation,Providing Context,External,OpenStack240593,15334,"Patch Set 1: Workflow-1

> That said, I like a combination of both of our approaches:
> isoformat when it's safe, and an explicit '%Y-%m-%dT%H:%M:%S.%f' 
> in the production code path when there's some doubt about
> remaining backwards compatible. I'll update my patch to combine
> both approaches and add you as an additional author.

Yup, I had worked on this earlier in the week but abandoned it because isoformat() caused a handful of unit tests to fail. This was due to the missing millisecond format, which is expected behavior:

    https://docs.python.org/2/library/datetime.html#datetime.datetime.isoformat

The approach I've taken is horribly verbose so if you're certain using standard isotime() is not going to affect things then go for it. Just keep an eye out for unintended side effects of the missing millsecond count please: there isn't 100% test coverage, after all :)",15334,https://docs.python.org/2/library/datetime.html#datetime.datetime.isoformat,docs.python.org,API documentation,Providing Context,External,OpenStack62042,8449,"Patch Set 20:

OK, thanks for the reviews. I guess there are then 3 issues remaining:

1. method refactoring. 

==> As suggested I will rebase ontop of v 19 (pre-refactoring) and make a dependent review for that purpose.

2. Whether with_lockmode('update')) is necessary
""Is it ok to allocate from old pools, and then have those allocation as out-of-pool once the pools are updated?""

==> It has already been decided from the progression of this patch that pre-existing allocations are OK (i.e. i have IP 1 on vm 1, but the updated pool no longer has 1 within its available_ranges), in the sense that we stopped searching for conflict allocations and doing something about them (log, error, whatever). The main reasoning was that neutron already supports out-of-pool allocations. That being said, won't the lockmode(update) here at least prevent any *new* allocations from a given subnet's allocation_pools? Or is that not even a problem, just let them happen? So far it seems the vote is to remove the lock altogether - thoughts?

3. ""We don't want available_ranges to somehow be rebuilt from the old pools after they are deleted.""

==> OK, for the record this is what the relevant db model definitions look like:

class IPAvailabilityRange(model_base.BASEV2):                                     
                                                                                 
    allocation_pool_id = sa.Column(sa.String(36),                                 
                                   sa.ForeignKey('ipallocationpools.id',          
                                                 ondelete=""CASCADE""),             
                                   nullable=False,                                
                                   primary_key=True)                              
    first_ip = sa.Column(sa.String(64), nullable=False, primary_key=True)         
    last_ip = sa.Column(sa.String(64), nullable=False, primary_key=True)          
                                                                                  
    def __repr__(self):                                                           
        return ""%s - %s"" % (self.first_ip, self.last_ip)                          
                                                                                  
                                                                                  
class IPAllocationPool(model_base.BASEV2, HasId):                                 
    """"""Representation of an allocation pool in a Neutron subnet.""""""               
                                                                                  
    subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id',              
                                                       ondelete=""CASCADE""),       
                          nullable=True)                                          
    first_ip = sa.Column(sa.String(64), nullable=False)                           
    last_ip = sa.Column(sa.String(64), nullable=False)                            
    available_ranges = orm.relationship(IPAvailabilityRange,                      
                                        backref='ipallocationpool',               
                                        lazy=""joined"",                            
                                        cascade='delete') 


One suggestion I can make (included in next v) is to alter the ""cascade='delete'"" on the available_ranges of IPAllocationPool to (all, delete-orphan). The 'all' [1] icludes delete but also save-update, which means that the IPAvailabilityRange db rows are loaded into the session as well. The 'delete-orphan' should guard against the situation you describe about orphan availability ranges being re-used.

thanks for your time, marios


[1] http://docs.sqlalchemy.org/en/rel_0_9/orm/session.html#unitofwork-cascades",8449,http://docs.sqlalchemy.org/en/rel_0_9/orm/session.html#unitofwork-cascades,docs.sqlalchemy.org,API documentation,Providing Context,External,OpenStack123957,12898,"Patch Set 8:

RHEL (Centos etc.) bug numbers:

    qemu-kvm
      7.0 https://bugzilla.redhat.com/1166605
      7.1 https://bugzilla.redhat.com/1160237
    qemu-kvm-rhev
      7.0 https://bugzilla.redhat.com/1167224
      7.1 https://bugzilla.redhat.com/1142331

Fedora 21 will get updated qemu-img soonish
(though it's not even released yet so that's kinda moot)

p.s. Upstream qemu also reworked the SEEK_HOLE logic
to avoid various problems with it which are now brought
to the forefront given it's now the default method.
I didn't hightlight these specifically as they're edge cases,
though the RHEL and Fedora updates will have the latest
SEEK code in place",1812,https://bugzilla.redhat.com/1142331,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack244489,5511,"Patch Set 46: Code-Review-1

(4 comments)

I tested the macvtap live migration and it is not working.
we will need a follow up patch.
The problem is basically that in the pre_live_migration will vif.plug
https://github.com/openstack/nova/blob/bc34c0a8b209de772588d9a6770e33b026d4c8ed/nova/virt/libvirt/driver.py#L6684-L6687  
but the instance and the neutron port has the old pci device in it.
so we will get exception in here https://github.com/openstack/nova/blob/bc34c0a8b209de772588d9a6770e33b026d4c8ed/nova/virt/libvirt/vif.py#L631-L636

by the newer libvirt version has problem with macvtap and setting the correct mac on the macvtap net device see this commit https://review.openstack.org/#/c/364121/ and this issue Bugzilla issue https://bugzilla.redhat.com/show_bug.cgi?id=1372944.",12171,https://bugzilla.redhat.com/show_bug.cgi?id=1372944,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack128657,12395,"Patch Set 2:

Oh, the reason is to not import _. 
See http://code.google.com/p/python-nose/issues/detail?id=373",12363,http://code.google.com/p/python-nose/issues/detail?id=373,code.google.com,Bug report,Providing Context,External,OpenStack123957,12898,"Patch Set 5:

RHEL/Centos et. al. will be getting the fix in a couple of weeks:
https://bugzilla.redhat.com/1142331

I also worry that fixing it here in nova is incomplete.
There are other uses of qemu-img convert in nova,
and in cinder and probably in many other places throughout openstack",1812,https://bugzilla.redhat.com/1142331,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack626952,10135,"Patch Set 3: -Code-Review

I just got direct access to a reproducer system and this fix *does* address the issue. Documented here:

https://bugzilla.redhat.com/show_bug.cgi?id=1686817

I have no idea what's going on in the gate test.",9555,https://bugzilla.redhat.com/show_bug.cgi?id=1686817,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack464711,5756,"Patch Set 8:

recheck

https://bugzilla.redhat.com/show_bug.cgi?id=1312188 looks similar to the tempest failure and it involves a libvirt update.",5756,https://bugzilla.redhat.com/show_bug.cgi?id=1312188,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack40222,12071,"Patch Set 4:

Joe: There were some issues with some version of libvirt/libguestfs outlined in this ticket: https://bugzilla.redhat.com/show_bug.cgi?id=913345",360,https://bugzilla.redhat.com/show_bug.cgi?id=913345,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack633855,2394,"Patch Set 5:

And libvirt seems to have at least one issue here:

https://bugzilla.redhat.com/show_bug.cgi?id=1683471",2394,https://bugzilla.redhat.com/show_bug.cgi?id=1683471,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack411936,13734,"Patch Set 4:

https://bugzilla.redhat.com/show_bug.cgi?id=1412834",6772,https://bugzilla.redhat.com/show_bug.cgi?id=1412834,bugzilla.redhat.com,Bug report,Providing Context,External,OpenStack4473,616,"Patch Set 2: Looks good to me (core reviewer)

This seems reasonable to me. The link to the http://bugs.python.org helps give context around the original issue we hit too.",360,http://bugs.python.org,bugs.python.org,Bug report,Providing Context,External,OpenStack411936,13734,"Patch Set 3:

Neil, maybe adding some context such as (thanks to libvirt developer Michal Privoznik for the below context, and for the `git bisect` analysis) the below to the commit message:

---
Previously, libvirt merely just appended 'script=' onto QEMU cmd line according to what <script path=''/> contained letting QEMU execute the script. That was flawed from security POV (you don't want QEMU to be allowed to execute anything) thus libvirt is executing the script now. However, this corner case (of allowing empty path) was missed.

The first commit in libvirt that introduced this bug is: http://libvirt.org/git/?p=libvirt.git;a=commitdiff;h=9c17d66 (autocreate tap device for ethernet network type)
---

And that it happened to work by accident with the old implementation.

I know you've linked to the bug.  Personally, I'm a fan of providing the context in the commit message itself, as it allows people to access it when offline.",6962,http://libvirt.org/git/?p=libvirt.git,libvirt.org,Bug report,Providing Context,External,OpenStack466607,22059,"Patch Set 5: Code-Review-1

> > The pylint test failure is pointing out some valid issues:
 > >
 > > http://logs.openstack.org/07/466607/5/check/gate-cinder-pylint-ubuntu-xenial/cff86ea/console.html#_2017-05-25_02_48_43_619823
 > 
 > I use ""from eventlet.green.subprocess import PIPE"", it is ok and it
 > has no SyntaxError, so eventlet.green.subprocess has a PIPE member.
 > Thanks.

there isn't really PIPE in eventlet.
https://github.com/eventlet/eventlet/blob/v0.21.0/eventlet/green/subprocess.py",22752,https://github.com/eventlet/eventlet/blob/v0.21.0/eventlet/green/subprocess.py,github.com,Code,Providing Context,External,OpenStack259398,5948,"Patch Set 5:

(6 comments)

@amuller +1 for some sort of test that spawns a proxy, makes a few requests, and gathers memory usage (PSS ideally [1])

[1] https://github.com/mangelajo/memexplore/blob/master/memexplore.py#L8",8788,https://github.com/mangelajo/memexplore/blob/master/memexplore.py#L8,github.com,Code,Providing Context,External,OpenStack37199,7808,"Patch Set 2:

There is a test for that in ParseTransportURLTestCase.test_query_string which is failing with python 2.7.5 but not with 2.7.3.

The thing is that between those two versions python changed urlparse's behavior and started to parse the query for all the schemes and not just the predefined ones in the library (See http://hg.python.org/cpython/rev/79e6ff3d9afd).

I think the fix is fine and that we can keep both checks.",7808,http://hg.python.org/cpython/rev/79e6ff3d9afd,hg.python.org,Code,Providing Context,External,OpenStack588226,28452,"Patch Set 3:

There are other places this is called in the code. Should they all add these checks?

Really too bad the Ceph code doesn't just return success if you ask to unprotect and already unprotected snap, but that doesn't appear to be the case:

https://github.com/ceph/ceph/blob/7b5dce63c4b7ae2f5ebe0d0205b845a3f7cf0e26/src/librbd/Operations.cc#L1179-L1186

https://github.com/ceph/ceph/blob/760e4718dbf55003f4bb67ada0b5a38954a214dc/src/pybind/rbd/rbd.pyx#L2665-L2667",11904,https://github.com/ceph/ceph/blob/7b5dce63c4b7ae2f5ebe0d0205b845a3f7cf0e26/src/librbd/Operations.cc#L1179-L1186,github.com,Code,Providing Context,External,OpenStack434327,6849,"Patch Set 2:

Fix to eventlet merged - https://github.com/eventlet/eventlet/commit/f92b49f77e073dad40a71858ef9149b543e07d67  , but we still need this one before a new release of eventlet is cut and we bump the min version in g-r",6849,https://github.com/eventlet/eventlet/commit/f92b49f77e073dad40a71858ef9149b543e07d67,github.com,Code,Providing Context,External,OpenStack228422,7293,"Patch Set 5:

Grenade failure is unrelated - there is a problem with https://bootstrap.pypa.io/get-pip.py , it is unavailable.",7293,https://bootstrap.pypa.io/get-pip.py,bootstrap.pypa.io,Code,Providing Context,External,OpenStack347188,20671,"Patch Set 12:

(7 comments)

I played this evening with test_create_server_failed_port_allocation_negative to find out why you cannot delete the routed network created there. It seems to my that you are using the same segmentation id the vagrant environment uses for the routed network is is created with. Please see my in line comments. I modified test_create_server_failed_port_allocation_negative. See the result here: https://gist.github.com/miguellavalle/b57085988f100ac9d6a80229e73bbf92. This version execute successfully, as you can see here: http://paste.openstack.org/show/564373/",4694,https://gist.github.com/miguellavalle/b57085988f100ac9d6a80229e73bbf92,gist.github.com,Code,Providing Context,External,OpenStack557958,1063,"Patch Set 28:

For posterity's sake, here's the email I sent Mike this evening about the func test failures and what I think might be the issue...

=== start email ===

Hi Mike!

Hoping you might be able to have a gander at a patch we're working on. You've seen the patch before :)

Reference:

https://review.openstack.org/#/c/557958/

The test_models_sync functional test is failing, like so:

Traceback (most recent call last):
  File ""/home/zuul/src/git.openstack.org/openstack/nova/.tox/functional/local/lib/python2.7/site-packages/oslo_db/sqlalchemy/test_migrations.py"", line 621, in test_models_sync
    ""Models and migration scripts aren't in sync:\n%s"" % msg)
  File ""/home/zuul/src/git.openstack.org/openstack/nova/.tox/functional/local/lib/python2.7/site-packages/unittest2/case.py"", line 690, in fail
    raise self.failureException(msg)
AssertionError: Models and migration scripts aren't in sync:
[ [ ( 'modify_default',
      None,
      'consumers',
      'generation',
      { 'existing_nullable': False,
        'existing_type': INTEGER(display_width=11)},
      DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7fb0b1cbdf50>, for_update=False),
      DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7fb0b9c88290>, for_update=False))]]

Looking back on the conversation with you on PS4 and PS5, it seems we added the server_default=Text(""0"") in order to get past an issue where we were seeing failures in the test_models_sync due to mismatched default types (Integer vs Text).

However, the test now seems to be failing due to the sqlalchemy.sql.elements.TextClause objects being different.

After tracing through oslo.db.sqlalchemy.test_migrations as well as the Nova codebase, I don't believe the issue is actually with any of those projects.

Unless I'm mistaken, I believe the bug may be in Alembic itself -- specifically in the MySQL DDL impl's compare_server_default() [1]:

 def compare_server_default(self, inspector_column,
                            metadata_column,
                            rendered_metadata_default,
                            rendered_inspector_default):
     ...
     if metadata_column.type._type_affinity is sqltypes.Integer and \
         inspector_column.primary_key and \
             not inspector_column.autoincrement and \
             not rendered_metadata_default and \
             rendered_inspector_default == ""'0'"":
     ....
     else:
         return rendered_inspector_default != rendered_metadata_default

I'm wondering if the above is going to return False when the rendered_inspector_default and rendered_metadata_default values are different, but only in the object hash of the sqlalchemy.sql.elements.TextClause object that is created for the inspected and expected server default values. If so, I think a simple fix would be to ignore whether the TextClause objects are different (which they almost certainly would be) and instead examine the TextClause.text attribute's value [2].

Thoughts?

Best,
-jay

[1] https://github.com/zzzeek/alembic/blob/b702e057aeaa640c03232c77405dc5415ac8a670/alembic/ddl/mysql.py#L85-L114

Note that the same implementation occurs for the default DDL impl as well:

https://github.com/zzzeek/alembic/blob/b702e057aeaa640c03232c77405dc5415ac8a670/alembic/ddl/impl.py#L265-L269

[2] https://github.com/zzzeek/sqlalchemy/blob/2e286dad303a94df092af9e104ed4036cb3c77aa/lib/sqlalchemy/sql/elements.py#L1264

=== end email ===",7,https://github.com/zzzeek/alembic/blob/b702e057aeaa640c03232c77405dc5415ac8a670/alembic/ddl/mysql.py#L85-L114,github.com,Code,Providing Context,External,OpenStack466607,22059,"Patch Set 5:

> > > The pylint test failure is pointing out some valid issues:
 > > >
 > > > http://logs.openstack.org/07/466607/5/check/gate-cinder-pylint-ubuntu-xenial/cff86ea/console.html#_2017-05-25_02_48_43_619823
 > >
 > > I use ""from eventlet.green.subprocess import PIPE"", it is ok and
 > it
 > > has no SyntaxError, so eventlet.green.subprocess has a PIPE
 > member.
 > > Thanks.
 > 
 > there isn't really PIPE in eventlet.
 > https://github.com/eventlet/eventlet/blob/v0.21.0/eventlet/green/subprocess.py

yes, it doesn't have PIPE and my file /usr/lib/python2.7/site-packages/eventlet/green/subprocess.py also doesn't have PIPE, but I can ""from eventlet.green.subprocess import PIPE"". Maybe PIPE is implicit.thanks",22059,https://github.com/eventlet/eventlet/blob/v0.21.0/eventlet/green/subprocess.py,github.com,Code,Providing Context,External,OpenStack14806,5638,"Patch Set 1: I would prefer that you didn't merge this

So shouldn't you be updating the disk check too as per:
https://github.com/ntt-pf-lab/nova/commit/61a0ca2",1812,https://github.com/ntt-pf-lab/nova/commit/61a0ca2,github.com,Code,Providing Context,External,OpenStack384621,18602,"Patch Set 10:

@Gabor - I prepared a change on one possible way of refactoring here:
https://github.com/matelakat/nova/commit/5ad36d7a0f39c819c7694a105d80c34ebbbeee91

Feel free to use it in any ways.

Cheers,
Mate",5044,https://github.com/matelakat/nova/commit/5ad36d7a0f39c819c7694a105d80c34ebbbeee91,github.com,Code,Providing Context,External,OpenStack130834,9303,"Patch Set 5:

Hi John,

It's tested in eventlet library.


https://github.com/eventlet/eventlet/blob/master/tests/wsgi_test.py#L1458


https://github.com/eventlet/eventlet/blob/master/tests/wsgi_test.py#L308


Hi Assaf,

I have tried to test that _run method is getting called with socket_timeout and keepalive option, but as _run method is called from different thread not able to mock it in the unit tests.

Please let me know your suggestions.

Thank You for review.",9303,https://github.com/eventlet/eventlet/blob/master/tests/wsgi_test.py#L1458,github.com,Code,Providing Context,External,OpenStack483994,15334,"Patch Set 6:

> Adding this comment for information purpose:
 > If I use v1.0.0-testing.2 released on 5th Oct (https://github.com/novnc/noVNC/archive/v1.0.0-testing.2.zip),
 > then it's unable to get token from the URL in nova-novncproxy
 > service.
 > 
 > I had reported this issue (https://github.com/novnc/noVNC/issues/967)
 > in noVNC and the noVNC community suggested to use path query
 > parameter to retreive token.
 > 
 > This requires changes in nova, mainly nova-compute and
 > nova-novncproxy services.

Looks like 'websockify.ProxyRequestHandler' [1] provides functionality to do this for us.

[1] https://github.com/novnc/websockify/blob/v0.8.0/websockify/websocketproxy.py#L101-L123",15334,https://github.com/novnc/websockify/blob/v0.8.0/websockify/websocketproxy.py#L101-L123,github.com,Code,Providing Context,External,OpenStack70776,8910,"Patch Set 1: I would prefer that you didn't merge this

I think this is the wrong architectural approach.

SPICE has the ability to transport arbitrary QEMU character devices over its data stream. ie you can connect QEMU serial ports to the SPICE service. The SPICE client can then access the data stream associated with the serial device with bi-directional I/O supported. Now SPICE is traditionally thought of as a GUI system, but that is by convention only - the core protocol allows you to create a plain client that only uses text based console streams, and ignores the GUI display part. The fat client library for spice is actually split into GObject and GTK parts specifically to allow this.

The QEMU server side already exists

  http://lists.freedesktop.org/archives/spice-devel/2014-January/015919.html

The libvirt config part is being developed and nearing completion

  https://www.redhat.com/archives/libvir-list/2014-February/msg00487.html

That leaves the SPICE HTML5 client work as the only remaining piece blocking openstack usage, and optionally a SPICE fat client if we need one.

The advantages of doing this in SPICE are multiple

- OpenStack merely has to configure the serial port to use SPICE. No major new infrastructure or many 1000's of lines of code to support, as this change is proposing

- No extra services for an administrator deploying openstack to deal with 

- Consistent end user experience - the one client gives them access to all resources associated with their VM - its graphical display, sound card output/input, USB device redirection, smartcard integration, and serial ports.


One might be tempted to say we should support both at the same time, but I don't think that's a good idea. For a start we still have the downsides mentioned above - 1000's more lines of code to support, new services for admins to deal with. Second, you can only configure QEMU serial ports to have one backend. If we use SPICE, then there's no way for this proposed text console service to use the QEMU serial port. If we use this new serial service, then you're preventing SPICE from offering a seemless experience across all VM resources.

In summary, IMHO, we should exclusively use SPICE for text serial console, not spend effort writing & maintaining a load of new code",1779,http://lists.freedesktop.org/archives/spice-devel/2014-January/015919.html,lists.freedesktop.org,Communication channel,Providing Context,External,OpenStack469360,841,"Patch Set 1:

Seems to be an issue in pyroute2 at the moment, there is a patch on openstack/requirements.
Issue: https://github.com/svinota/pyroute2/issues/365
Patch: https://review.openstack.org/#/c/469296",18051,https://github.com/svinota/pyroute2/issues/365,github.com,Github activity,Providing Context,External,OpenStack333164,8846,"Patch Set 20: Code-Review-1 Workflow+1

(2 comments)

There is still something wrong with this patch. I've run this code and made manage request explode in the scheduler. Then I've removed the leftover volume. The result - -1 on volumes quota. See the logs [1]. Please try to reproduce the error.

[1] http://pastebin.com/nDRNt8b9",11600,http://pastebin.com/nDRNt8b9,pastebin.com,Memo,Providing Context,External,OpenStack74832,4393,"Patch Set 18:

nonlinewrapped exception: http://codepad.org/uQrno5Dr",4395,http://codepad.org/uQrno5Dr,codepad.org,Memo,Providing Context,External,OpenStack115719,8574,"Patch Set 5:

Hmm, it could be interesting to handle this before going into refactor.

I have been profiling this method with rook, and it seems to be our new bottleneck for security groups. A big regression from Havana, which is limiting nova/neutron interaction.

Timeout nova->neutron creating ports.
https://gist.githubusercontent.com/anonymous/e5b666fdb98a27554833/raw/de47e31ca24102c6e3361b6c8f5e2de79bece4e6/gistfile1.txt

And the slow parts in openvswitch agent which make this go slow:

https://gist.githubusercontent.com/anonymous/e3250001212ea8e40e1d/raw/029d09197049b206c5eeadf70fcb177a80027b99/gistfile1.txt",8788,https://gist.githubusercontent.com/anonymous/e5b666fdb98a27554833/raw/de47e31ca24102c6e3361b6c8f5e2de79bece4e6/gistfile1.txt,gist.githubusercontent.com,Memo,Providing Context,External,OpenStack201812,2243,"Patch Set 6: Code-Review-1

Hi John, IMHO we need a spec for this. There is already a BP approved to port the driver to VD classes (and several people are doing work on it). So instead of simply reverting mainly the ABC feature I am absolute fine to remove many classes if there are common enough. See https://docs.google.com/spreadsheets/d/1L_GuUCs-NMVbhbOj8Jtt8vjMQ23zhJ1yagSH4zSKWEw/edit#gid=0",7872,https://docs.google.com/spreadsheets/d/1L_GuUCs-NMVbhbOj8Jtt8vjMQ23zhJ1yagSH4zSKWEw/edit#gid=0,docs.google.com,Memo,Providing Context,External,OpenStack257059,7249,"Patch Set 14: Code-Review-1

Running the rally test 'test_create_and_delete_routers' seem to cause a lot of errors in the server side specifically http://pastebin.com/bimK64cG
This error has been described in https://bugs.launchpad.net/neutron/+bug/1533460 by Liu. I'm changing my vote to -1 as I look deeper into the code.",12444,http://pastebin.com/bimK64cG,pastebin.com,Memo,Providing Context,External,OpenStack625216,6962,"Patch Set 5:

> LGTM, but I'm holding my +2 until the tripleo integration problem
 > is resolved or explained.

Hi Gibi, What Martin posted is the test evidence of what commands libvirt is sending to QEMU, so that we can truly see that ""native TLS"" is being used all the way at the hypervisor level.

I have reviewed the the log content from Martin, and it looks correct — as in: ""native TLS"" is being used correctly for live migration without shared storage (i.e. ""live block migration"").

It matches my own test evidence, that I posted here:

https://kashyapc.fedorapeople.org/Native-TLS/Test-Evidence/
https://kashyapc.fedorapeople.org/Native-TLS/Test-Evidence/GREP-tls-creds-on-SRC-guestHyp1.txt
https://kashyapc.fedorapeople.org/Native-TLS/Test-Evidence/GREP-tls-creds-on-DEST-guestHyp2.txt",6962,https://kashyapc.fedorapeople.org/Native-TLS/Test-Evidence/GREP-tls-creds-on-DEST-guestHyp2.txt,kashyapc.fedorapeople.org,Memo,Providing Context,External,OpenStack514442,4523,"Patch Set 1: Workflow+1 Code-Review+2

Pushing this through to see if it gets us past our gate blockage.

I don't think this is it, and I think we are going to run into failures elsewhere. A quick search shows others have run into this same signature, and it seems to be a connection string problem.

TonyB also noted there was an ubuntu package update around the time this started failing.

http://changelogs.ubuntu.com/changelogs/pool/main/m/mysql-5.7/mysql-5.7_5.7.20-0ubuntu0.16.04.1/changelog

Running for a test, but I am hoping we can revert this revert and find a better fix.",11904,http://changelogs.ubuntu.com/changelogs/pool/main/m/mysql-5.7/mysql-5.7_5.7.20-0ubuntu0.16.04.1/changelog,changelogs.ubuntu.com,Memo,Providing Context,External,OpenStack7381,4200,"Patch Set 1: (1 inline comment)

the bash-completion command is not supported and not needed. glance prints all possible commands, when an unknown command is issued. see http://pastebin.com/s0h2FWXH",4200,http://pastebin.com/s0h2FWXH,pastebin.com,Memo,Providing Context,External,OpenStack191148,8655,"Patch Set 12: -Code-Review

Here is the captured output from a few of my tox runs.  Let me know if there are other logs I should get too.

http://paste.ubuntu.com/12344109/
http://paste.ubuntu.com/12344237/",14957,http://paste.ubuntu.com/12344237/,paste.ubuntu.com,Memo,Providing Context,External,OpenStack109660,67,"Patch Set 7:

Hmm, I tested with DB2 and the upgrade was fine but the downgrade blew up:

https://gist.github.com/mriedem/19d737ab5ad43eba9ca0

Looks like an ibm-db-sa issue, I'm testing with sqlalchemy 0.8.4, ibm-db 2.0.5 and ibm-db-sa 0.3.1.",6873,https://gist.github.com/mriedem/19d737ab5ad43eba9ca0,gist.github.com,Memo,Providing Context,External,OpenStack3516,2284,"Patch Set 4:

Hi Soren,

As requested, here's a minimal script reproducing the hang in the test utility logic.

$ wget https://s3.amazonaws.com/eglynn-tests/hung_pipe.tar.gz
$ tar xzf hung_pipe.tar.gz
$ python a.py      # ... runs to completion
$ python a.py hang # ... hangs on read from pipe

Using strace, you can clearly see the ERESTARTED behaviour refered to in previous comments, e.g.:

Non-hanging case where the child death leads to the read on the stdout pipe in a.py to be closed:

read(5, ""exiting\n"", 8192)              = 8
read(5, """", 8184)                       = 0
--- SIGCHLD (Child exited) @ 0 (0) ---
close(5)                                = 0
wait4(11815, [{WIFEXITED(s) && WEXITSTATUS(s) == 0}], 0, NULL) = 11815
...etc.

Hanging case where read is restarted just as the SIGCHLD is received to indicate the piped process has died:

read(5, ""exiting\n"", 8192)              = 8
read(5, 0x288b6ec, 8184)                = ? ERESTARTSYS (To be restarted)
--- SIGCHLD (Child exited) @ 0 (0) ---
read(5, 

Intestingly with this stripped-down test case, I can reproduce the hang on both Ubuntu 10.04 and Fedora 16.",2284,https://s3.amazonaws.com/eglynn-tests/hung_pipe.tar.gz,s3.amazonaws.com,Others,Providing Context,External,OpenStack111876,8976,"Patch Set 26:

I tested the full matrix and it worked in all cases,
agent logs linked:

New neutron-srv, new agent enhanced ... http://ur1.ca/i2kih
New neutron-srv, new agent not enhanced http://ur1.ca/i2kk0  
New neutron-srv, old agent ............ http://ur1.ca/i2kjo
Old neutron-srv, new agent enhanced ... http://ur1.ca/i2kiu
Old neutron-srv, new agent not enhanced http://ur1.ca/i2kjf",8788,http://ur1.ca/i2kih,ur1.ca,Others,Providing Context,External,OpenStack38230,4395,"Patch Set 8:

BTW, I've tested this functionality on all-in-one devstack installation, and it works well.

A detailed description of the test is here - https://www.dropbox.com/s/021gfjps6gtu79q/allowed-address-pairs-test.pdf",7562,https://www.dropbox.com/s/021gfjps6gtu79q/allowed-address-pairs-test.pdf,www.dropbox.com,Others,Providing Context,External,OpenStack111876,8976,"Patch Set 26:

I tried this change to the exception capture, http://ur1.ca/i2kqa and all  tox -epy27 neutron.tests.unit.test_security_groups_rpc
pass (4 of those failed in patchset 22).

Looking at other patchsets now",8788,http://ur1.ca/i2kqa,ur1.ca,Others,Providing Context,External,OpenStack65070,9461,"Patch Set 3: Looks good to me, but someone else must approve

LBaaS API testing PASSED with NetScaler providing LBaaS. Please find logs at https://citrix.sharefile.com/d/sf09bd782d0f4ee18",9461,https://citrix.sharefile.com/d/sf09bd782d0f4ee18,citrix.sharefile.com,Others,Providing Context,External,OpenStack550173,15334,"Patch Set 4:

> As discussed this needs to wait until the underlying distros update
 > novnc to >=1.0.0 that hasn't happened yet AFAIK, for example Fedora
 > is still using v0.6.1: https://src.fedoraproject.org/rpms/novnc/blob/f28/f/sources

Ubuntu are currently shipping 0.4.0 FWIW:

https://packages.ubuntu.com/search?keywords=novnc",10135,https://src.fedoraproject.org/rpms/novnc/blob/f28/f/sources,src.fedoraproject.org,Others,Providing Context,External,OpenStack22098,67,"Patch Set 1:

Note the file list for ubuntu:

http://packages.ubuntu.com/oneiric/all/python-pastedeploy/filelist

no __init__.py in the top level directory",67,http://packages.ubuntu.com/oneiric/all/python-pastedeploy/filelist,packages.ubuntu.com,Software homepage,Providing Context,External,OpenStack254339,8302,"Patch Set 2:

* test http://google.com/ : SUCCESS",8302,http://google.com/,google.com,Software homepage,Providing Context,External,OpenStack93706,8207,"Patch Set 2: Code-Review+1

@ Jenkins                9:52 AM
""Patch Set 2: Verified-1""
I check devstack.log.gz & found the error in the build process (not because of my code):
""...
2014-05-16 01:52:51.336 | Get:1 http://mirror.rackspace.com/ubuntu/ precise/universe python-qpid all 0.12-2 [263 kB]
2014-05-16 01:52:51.341 | Err http://mirror.rackspace.com/ubuntu/ precise-security/main libxml2 amd64 2.7.8.dfsg-5.1ubuntu4.7
2014-05-16 01:52:51.345 |   404  Not Found
2014-05-16 01:52:51.349 | Err http://mirror.rackspace.com/ubuntu/ precise-security/main libxml2-dev amd64 2.7.8.dfsg-5.1ubuntu4.7
2014-05-16 01:52:51.353 |   404  Not Found
2014-05-16 01:52:51.357 | Err http://mirror.rackspace.com/ubuntu/ precise-security/main python-libxml2 amd64 2.7.8.dfsg-5.1ubuntu4.7
2014-05-16 01:52:51.361 |   404  Not Found
2014-05-16 01:52:51.365 | Failed to fetch http://mirror.rackspace.com/ubuntu/pool/main/libx/libxml2/libxml2_2.7.8.dfsg-5.1ubuntu4.7_amd64.deb  404  Not Found
2014-05-16 01:52:51.370 | Failed to fetch http://mirror.rackspace.com/ubuntu/pool/main/libx/libxml2/libxml2-dev_2.7.8.dfsg-5.1ubuntu4.7_amd64.deb  404  Not Found
2014-05-16 01:52:51.374 | Failed to fetch http://mirror.rackspace.com/ubuntu/pool/main/libx/libxml2/python-libxml2_2.7.8.dfsg-5.1ubuntu4.7_amd64.deb  404  Not Found
2014-05-16 01:52:51.378 | Fetched 263 kB in 0s (414 kB/s)
2014-05-16 01:52:51.382 | E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?
...""",8207,http://mirror.rackspace.com/ubuntu/,mirror.rackspace.com,Software homepage,Providing Context,External,OpenStack61273,5217,"Patch Set 1:

test review message <http://www.google.com>",5217,http://www.google.com,www.google.com,Software homepage,Providing Context,External,OpenStack110503,7069,"Patch Set 1: Code-Review-1

The whl file for it is on PyPI and on our mirror... https://pypi.python.org/simple/oslo.config/ http://pypi.openstack.org/simple/oslo.config/",5263,https://pypi.python.org/simple/oslo.config/,pypi.python.org,Software homepage,Providing Context,External,OpenStack124114,9970,"Patch Set 4:

Failing for me:

https://gist.github.com/mriedem/ade76aaa063357c940cd",6873,https://gist.github.com/mriedem/ade76aaa063357c940cd,gist.github.com,Specification,Providing Context,External,OpenStack87563,8556,"Patch Set 6: Do not merge

I think we're on the wrong track here. I've done a little poking around and we have a bunch of different formats in our API output: https://gist.github.com/markmc/11295100

we sometimes have timezone info in the form of 'Z' (for UTC) or +/-00:00 or even a non-UTC offset ... and sometimes we don't have any timezone info

sometimes we have a 'T' separating date from time, and sometimes we don't. The iso8601 format requires this even if the is08601 library makes it optional

and, finally, sometimes we have subsecond timestamp resolution and other times we don't

Personally, I'm thinking our default should be to (a) have everything in UTC timezone and indicate this with a trailing 'Z', (b) always include the 'T' separator and (c) only have subsecond time resolution where we think there's a real use case for it


Now ... this patch strips off the timezone and subsecond resolution, but only for the keypairs API. That's a totally random approach to cleaning this up.


IMHO, we should allow Ghanshyam merge his useful new unit test (i.e. If695a23cf95862b7bec6fbc5bdf7fc1733d08d4a) including a change to the timestamp regexp to allow the combination of timezone info and subsecond time resolution ... that combination really isn't any more weird than some of the other formats we currently use


This is something that should be properly cleaned up across Nova and I'm going to do a bit more digging into it ... but we shouldn't add an arbitrary workaround like this.",1247,https://gist.github.com/markmc/11295100,gist.github.com,Specification,Providing Context,External,OpenStack39929,1247,"Patch Set 70:

Ok, rebased onto Dan's DB compaction so the 200 migration issue is no more

I've dumped some notes on the rebase here: https://gist.github.com/markmc/8472575

This will fail the requirements check because we need >=1.3.0a3 to be pushed to pypi - see I87eaefb37fa52142d47b4aba4f3f76452771f74e",1247,https://gist.github.com/markmc/8472575,gist.github.com,Specification,Providing Context,External,OpenStack619061,6873,"Patch Set 1:

(1 comment)

> does the error message give you the full SQL qeury itself also?

It's in the logs yeah:

http://logs.openstack.org/periodic/git.openstack.org/openstack/neutron/master/neutron-tempest-postgres-full/1de7427/logs/screen-n-api.txt.gz?level=ERROR#_Nov_20_06_34_20_559245

Nov 20 06:34:20.559245 ubuntu-xenial-inap-mtl01-0000583998 devstack@n-api.service[24452]:  [SQL: 'SELECT instance_mappings.created_at AS instance_mappings_created_at, instance_mappings.updated_at AS instance_mappings_updated_at, instance_mappings.id AS instance_mappings_id, instance_mappings.instance_uuid AS instance_mappings_instance_uuid, instance_mappings.cell_id AS instance_mappings_cell_id, instance_mappings.project_id AS instance_mappings_project_id, instance_mappings.queued_for_delete AS instance_mappings_queued_for_delete, cell_mappings_1.created_at AS cell_mappings_1_created_at, cell_mappings_1.updated_at AS cell_mappings_1_updated_at, cell_mappings_1.id AS cell_mappings_1_id, cell_mappings_1.uuid AS cell_mappings_1_uuid, cell_mappings_1.name AS cell_mappings_1_name, cell_mappings_1.transport_url AS cell_mappings_1_transport_url, cell_mappings_1.database_connection AS cell_mappings_1_database_connection, cell_mappings_1.disabled AS cell_mappings_1_disabled \nFROM instance_mappings JOIN cell_mappings AS cell_mappings_1 ON instance_mappings.cell_id = cell_mappings_1.id \nWHERE instance_mappings.project_id = %(project_id_1)s GROUP BY instance_mappings.cell_id'] [parameters: {'project_id_1': u'2f61e587be55446c95e3e235f0550e7e'}] (Background on this error at: http://sqlalche.me/e/f405): ProgrammingError: column ""instance_mappings.created_at"" must appear in the GROUP BY clause or be used in an aggregate function",6873,http://sqlalche.me/e/f405,sqlalche.me,Tutorial or article,Providing Context,External,OpenStack15871,6167,"Patch Set 3:

I'm actually going to side with Dan here

http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.1

On a 400 error:

""The request could not be understood by the server due to malformed syntax. The client SHOULD NOT repeat the request without modifications.""

Vish - if you don't like 404, then maybe the 422 is appropriate here?

https://tools.ietf.org/html/rfc4918#section-11.2",642,http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.1,www.w3.org,Tutorial or article,Providing Context,External,OpenStack25358,6167,"Patch Set 34:

I have asked dhellmann to review this, as he works on wsme (http://pythonhosted.org/WSME/changes.html)",1849,http://pythonhosted.org/WSME/changes.html,pythonhosted.org,Others,Suggesting Experts,External,OpenStack